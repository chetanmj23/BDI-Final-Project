{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybUsUGb9Ca0n"
   },
   "source": [
    "\n",
    "\n",
    "<center><font color=darkblue><h1>*Language Translation Using LSTM and GRU*</h1></font></center>\n",
    "***\n",
    "\n",
    "![Music](https://mondrian.mashable.com/2012%252F12%252F04%252F46%252F7languagetr.bTr.jpg%252F950x534__filters%253Aquality%252890%2529.jpg?signature=sBWpGjGRzxhm5G6BGJBqALyuLKY=)\n",
    "<div>\n",
    "<center><font color=darkblue>\n",
    "    <h3>A PROJECT BY:</h3></font>\n",
    "        <h2><a href='https://www.linkedin.com/in/chetanmjadhav/'> Chetan M Jadhav (001836501)</a></h2>\n",
    "    ![test116](https://upload.wikimedia.org/wikipedia/en/thumb/b/bd/Northeastern_University_seal.svg/586px-Northeastern_University_seal.svg.png)\n",
    "    <h3>Under the guidance of</h3></font>\n",
    "        <h2>Nick Bear Brown</h2>\n",
    "\n",
    " </center>\n",
    "</div>\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Euiet_xCa0p"
   },
   "source": [
    "<div>\n",
    "    <h2>&#10024; Table of Content: </h2>\n",
    "        <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#10163; [Introduction](#Introduction) </h3>\n",
    "        <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#10163; [Imports](#Imports)</h3>\n",
    "        <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#10163; [Data Processing](#Data_Processing)</h3>\n",
    "        <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#10163; [Tokenization](#Tokenization)</h3>\n",
    "        <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#10163; [Build the Model](#Build_The_Model)</h3>\n",
    "        <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#10163; [Train the Model](#Model_Train)</h3>\n",
    "        <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#10163; [Prediction](#Prediction)</h3>\n",
    "        <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#10163; [Evaluation](#Merging)</h3>\n",
    "        <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#10163; [Conclusion](#Conclusion)</h3>\n",
    "        <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#10163; [Contribution](#Contribution)</h3>\n",
    "        <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#10163; [References](#References)</h3>\n",
    "        <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#10163; [Licence](#Licence)</h3>\n",
    "</div>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5D4-u2DCa0q"
   },
   "source": [
    "<h3><a id=\"Introduction\">&#9997; Introduction</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPO59WBFCa0r"
   },
   "source": [
    "Recurrent Neural Networks (RNN) have revealed promising outcomes in several machine learning tasks, specifically when input or output are of flexible length. More recently its been stated that recurrent neural networks can accomplish well in building the machine translation model.\n",
    "As we know that recurrent neural networks are doing well in machine translation field. We are more concerned in building a machine translation model using two closely related variants which are LSTM and GRU. These two variants of works well with seq2seq framework where the input is fed sequentially, and output is led out sequentially. The draw back which vanilla recurrent neural network had of vanishing gradient problem is resolved by using these two variants of RNN as these two can memorize more and can omit if the data is not needed in its memory and can work on longer sentences which was an issue using vanilla RNN.\n",
    "Based on our couple of experiments we can say that LSTM and GRU performs well in translating the language but GRU’s efficiency is little bit more compared to that of LSTM, but training time is much more than that of LSTM.\n",
    "\n",
    "**Recurrent Neural Network:**\n",
    "\n",
    "A recurrent neural network (RNN) is an extension of the conventional feedforward neural network, which can handle variable length sequence input. The core idea behind the RNN is to make use of sequential data. In traditional neural network we adopt that all the inputs are autonomous of each other. But many of tasks doesn’t work this way and the traditional neural network was of no use when the model must forecast what’s going to come next in the sentence as it needs to remember the previous couple of words, that’s when the Recurrent Neural Network came to existence. This is called recurrent because of the network achieves the same task for every element of a sequence, with output depending on the previous calculations. Further way of explaining the recurrent term is remembering the old computation in the memory.\n",
    "![test](http://www.wildml.com/wp-content/uploads/2015/09/rnn.jpg)\n",
    "\n",
    "Traditional Recurrent Neural Network\n",
    "\n",
    "The above picture shows an RNN being unfolded into a full network where the network will be unfolded the times of the input. For example, if there is 3 words input then the RNN will unfold 3 times to train the model and to provide the output i.e., one layer for each word.\n",
    "While using RNN, they came across the issue called vanishing gradients as the RNN is very old and this issue emerged as the major issue to recurrent neural network’s performance. For recurrent neural networks we want to have extended memories so that system can join data relationships at significance at times but as we had more time steps, the more chance we have back-propogation gradients either hoarding and exploding or vanishing down to nothing. \n",
    "The above obstacle of vanishing gradients is solved by the long short term memory and the gated recurrent unit, we will discuss about them in our next section.\n",
    "\n",
    "**Long Short Term Memory**\n",
    "\n",
    "Long short term memory was developed as the solution to the traditional recurrent neural network and this work and have internal gates that regulates the data flow to the next layer. These gates can learn which data in a sequence is important to keep or to forget, by this it can keep only the data which is relevant and which is helpful in predecting the next word. And about the LSTM gates we going to discuss in brief in this section so we have better understanding on the same.\n",
    " \n",
    "![test2](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/12/10131302/13-768x295.png)\n",
    "\n",
    "\n",
    "The typical LSTM network have different memory blocks which is termed by the name “Cells” and there are two states that are being shifted to the next cell called cell state and the hidden state. The memory blocks are accountable for remembering things and operations to this memory and is done through the mechanism called gates.\n",
    "\n",
    "**Forget Gate:**\n",
    "Forget gate is accountable for removing or throwing away the information that is not needed and this gate have two inputs ht-1 and xt, ht-1 is the hidden state from the previus cell and xt is the input of the current time step.\n",
    "\n",
    "![test3](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/12/10131319/14.png)\n",
    "\n",
    "Both the inputs ht-1 and xt are multipied before passing to the sigmoid function where the sigmoid function outputs vector of 0 to 1. Basically its sigmoid who decides whether to keep the data which is there in this gate or to throw away. For example, if the sigmoid output is 0 then it means the data which is passed to the gate needs to be forgotten and if the value of sigmoid is 1 then the information is passed to the next layer.\n",
    "\n",
    "**Input Gate:**\n",
    "\n",
    "The input gate is accountable for addition of the information to the cell state and the process is expained with the diagram below\n",
    "\n",
    "![test4](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/12/10131330/16.png)\n",
    "\n",
    "Input gate takes the two inputs hidden state from previous cell ht-1 and current input xt .\n",
    "Both the inputs multiplied and passed it to the sigmoid and tanh function before again passing it to the multiplier where tanh function outputs in the range of -1 to 1 this value passes the useful information to the cell state.\n",
    "\n",
    "\n",
    "**Output Gate:**\n",
    "\n",
    "The output gate is accountable for the selecting the useful information from the current cell state and showing it as an output to the next layer.\n",
    "\n",
    "![test5](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/12/10131340/18.png)\n",
    " \n",
    "\n",
    "Output gate  takes the two inputs hidden state from previous cell ht-1 and current input xt .\n",
    "Both the inputs multiplied and passed it to the sigmoid function and passing it to the tanh function where the tanh function sacles the output in the range of -1 to 1 and multiplying the value of this filet to the vector created by tanh function will be the oupput to the next layer which acts as ht-1 to the next layer.\n",
    "\n",
    "LSTM’s are very promising but its very difficult in training them and lot of computation is needed to train the model.\n",
    "\n",
    "**Gated Recurrent Unit:**\n",
    "\n",
    "Gated Recurrent Unit was introduced by the K.Cho in 2014 and this is almost similar to LSTM and can be called enhanced LSTM. As LSTM even GRU has the gate concept and has 2 gates instead of 3 which we will discuss in detail in this section. Below is the diagram of the GRU.\n",
    "\n",
    "![test6](https://cdn-images-1.medium.com/max/1400/1*6eNTqLzQ08AABo-STFNiBw.png)\n",
    "\n",
    "And the notations are as mentioned below which will help to understand the equation\n",
    "\n",
    "![test7](https://cdn-images-1.medium.com/max/800/1*qx5uUSVgL_QCvsJ_yM2pMA.png)\n",
    "\n",
    "**Update Gate:**\n",
    "\n",
    "The Update gate has two inputs hidden state from previous cell ht-1 and current input xt . and this gate is accountable to check the piece of information and decide if it needs to update the cell\n",
    "\n",
    "![test8](https://cdn-images-1.medium.com/max/800/1*gSlR_JLNeuZBSCAKyjmAdA.png)\n",
    " \n",
    "Both the inputs will be passed to the plus operation which again will be passed to the sigmoid function which vectors the output in the range of 0 to 1 and each inputs carries its own weight and can be defined by the below formula\n",
    "\n",
    "Zt = σ(W(z)xt + U(z)ht-1)\n",
    "\n",
    "The input xt is multiplied by its own weight W(z) and input ht-1 is mulitplied by its own weight U(z) .\n",
    "This update gate helps th ecell to determine how much of the information needs to be passed along and which information needs to be dropped and not to passed to the next layer.\n",
    "\n",
    "**Reset Gate:**\n",
    "\n",
    "Reset gate is accountable for deciding what piece information needs to be forgotten and reset gate also takes two inputs hidden state from previous cell ht-1 and current input xt .\n",
    " \n",
    "![test9](https://cdn-images-1.medium.com/max/800/1*5M6LYj544UKKHkFkDmDQ8A.png)\n",
    "\n",
    "Both the inputs multiplied with their own weight and added together before passing it to the sigmoid function which vectors the output in the range of 0 to 1 and can be defined by the below formula\n",
    "\n",
    " ![test10](https://cdn-images-1.medium.com/max/800/1*j1j1mLIyTm97hCay4GRC_Q.png)\n",
    " \n",
    " The output of the sigmoid function determines if the information is passed or forgotten. for example, if the output is 1 then the data is passed and if the output is 0 then the piece of information is dropped.\n",
    " \n",
    "**Current Memory Content:**\n",
    "\n",
    "By making use of the reset gate’s output which will store the relevant information from the past and can be calculated by the below mentioned formula\n",
    "\n",
    "![test11](https://cdn-images-1.medium.com/max/800/1*CxQBMqy8dvgJNjeJcur6pQ.png)\n",
    " \n",
    "The input xt is multiplied by its own weight W and ht-1 with its own weight U. and compute the Hadamard product between reset gate’s output rt and Uht-1 and add it with the input Wxt before passing it to the nonlinear tanh function which will vector the output in the range of -1 to 1\n",
    "\n",
    " \n",
    "![test12](https://cdn-images-1.medium.com/max/800/1*AZObvZ2GXSDYkJ2iv28MaQ.png)\n",
    "\n",
    "\n",
    "**Final memory at current time step:**\n",
    "\n",
    "In this step, at the end it will hold the information which we pass to the next layer ht-1, so to do this we require the update gate’s output zt and the output can be computed by the below formula\n",
    "\n",
    "![test13](https://cdn-images-1.medium.com/max/800/1*zxSTnqedwLRoicgHKYKsVQ.png)\n",
    " \n",
    "Here we will multiply by Hadamard product function the hidden input with the update gate’s output and then Hadamard multiplier on (1-zt) and ht before passing it to the plus operator.\n",
    "\n",
    "![test14](https://cdn-images-1.medium.com/max/800/1*UxZ0pTQW8kofL9bzPVYV1w.png)\n",
    " \n",
    "\n",
    "This is how GRUs can store and update using reset and update gates which eliminates vanishing gradient problem.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2sXARuTCa0t"
   },
   "source": [
    "<h3><a id=\"Imports\">&#9997; Imports</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peVWzSaSCa0u"
   },
   "source": [
    "**Import All the neccessary Libraries which we will be requiring to run this notebook and the project**\n",
    "\n",
    "I will be using seq2seq model with the LSTM so all the libraries related to it should be installed and also Keras's tokenizer function which is essential to the tekenize the text\n",
    "\n",
    "All the basic libraries such as numpy, pandas, string, matplotlib and etc also imported along with other helper libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5qKpyB8Ca0v"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#Make plots bigger\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from sklearn.model_selection import train_test_split\n",
    "#print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eurTnOhfCa03"
   },
   "source": [
    "Creating a function which will read the file, encode it and save it and then the funtion to_lines wil  split the data into Italian & English part seperately by '\\n' and build it in the form of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCpIwTOzCa04"
   },
   "outputs": [],
   "source": [
    "def Read_TextFile(filename):\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def to_lines(text):\n",
    "    sentences = text.strip().split('\\n')\n",
    "    sentences = [i.split('\\t') for i in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ld5yk1mACa08"
   },
   "source": [
    "By using the function we wrote the text file is imported to the jupyter notebook. \n",
    "\n",
    "Once the notebook is opened and read using the function Read_TextFile we will pass it to the to_lines to split and to build the sentences of the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96XiD6XFCa09"
   },
   "outputs": [],
   "source": [
    "data = Read_TextFile(\"ita.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17034
    },
    "colab_type": "code",
    "id": "6DS1FYmQCa1A",
    "outputId": "9c036746-469f-4b35-d2f9-cfd5df6972bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hi.', 'Ciao!'],\n",
       " ['Run!', 'Corri!'],\n",
       " ['Run!', 'Corra!'],\n",
       " ['Run!', 'Correte!'],\n",
       " ['Who?', 'Chi?'],\n",
       " ['Wow!', 'Wow!'],\n",
       " ['Jump!', 'Salta!'],\n",
       " ['Jump!', 'Salti!'],\n",
       " ['Jump!', 'Saltate!'],\n",
       " ['Jump.', 'Salta.'],\n",
       " ['Jump.', 'Salti.'],\n",
       " ['Jump.', 'Saltate.'],\n",
       " ['Stop!', 'Fermati!'],\n",
       " ['Stop!', 'Fermatevi!'],\n",
       " ['Stop!', 'Stop!'],\n",
       " ['Stop!', 'Si fermi!'],\n",
       " ['Wait!', 'Aspetta!'],\n",
       " ['Wait!', 'Aspettate!'],\n",
       " ['Wait!', 'Aspetti!'],\n",
       " ['Wait.', 'Aspetta.'],\n",
       " ['Wait.', 'Aspetti.'],\n",
       " ['Wait.', 'Aspettate.'],\n",
       " ['Do it.', 'Fallo.'],\n",
       " ['Do it.', 'Falla.'],\n",
       " ['Do it.', 'Lo faccia.'],\n",
       " ['Do it.', 'La faccia.'],\n",
       " ['Do it.', 'Fatelo.'],\n",
       " ['Do it.', 'Fatela.'],\n",
       " ['Go on.', 'Vai avanti.'],\n",
       " ['Go on.', 'Continua.'],\n",
       " ['Go on.', 'Continui.'],\n",
       " ['Go on.', 'Continuate.'],\n",
       " ['Go on.', 'Vada avanti.'],\n",
       " ['Go on.', 'Andate avanti.'],\n",
       " ['Hello!', 'Buongiorno!'],\n",
       " ['Hello!', 'Ciao!'],\n",
       " ['Hello!', 'Salve.'],\n",
       " ['I ran.', 'Ho corso.'],\n",
       " ['I ran.', 'Corsi.'],\n",
       " ['I see.', 'Capisco.'],\n",
       " ['I see.', 'Io capisco.'],\n",
       " ['I try.', 'Provo.'],\n",
       " ['I try.', 'Io provo.'],\n",
       " ['I won!', 'Ho vinto!'],\n",
       " ['I won.', 'Vinsi.'],\n",
       " ['Oh no!', 'Oh no!'],\n",
       " ['Relax.', 'Rilassati.'],\n",
       " ['Relax.', 'Si rilassi.'],\n",
       " ['Relax.', 'Rilassatevi.'],\n",
       " ['Shoot!', 'Spara!'],\n",
       " ['Shoot!', 'Spari!'],\n",
       " ['Shoot!', 'Sparate!'],\n",
       " ['Smile.', 'Sorridi.'],\n",
       " ['Smile.', 'Sorrida.'],\n",
       " ['Smile.', 'Sorridete.'],\n",
       " ['Attack!', 'Attacca!'],\n",
       " ['Attack!', 'Attaccate!'],\n",
       " ['Attack!', 'Attacchi!'],\n",
       " ['Cheers!', 'Alla vostra!'],\n",
       " ['Cheers!', 'Salute!'],\n",
       " ['Cheers!', 'Alla tua!'],\n",
       " ['Cheers!', 'Alla sua!'],\n",
       " ['Eat it.', 'Mangialo.'],\n",
       " ['Eat it.', 'Mangiala.'],\n",
       " ['Eat it.', 'Lo mangi.'],\n",
       " ['Eat it.', 'La mangi.'],\n",
       " ['Eat it.', 'Mangiatelo.'],\n",
       " ['Eat it.', 'Mangiatela.'],\n",
       " ['Eat up.', 'Finisci di mangiare.'],\n",
       " ['Eat up.', 'Finisca di mangiare.'],\n",
       " ['Eat up.', 'Finite di mangiare.'],\n",
       " ['Freeze!', 'Fermo!'],\n",
       " ['Freeze!', 'Ferma!'],\n",
       " ['Freeze!', 'Fermi!'],\n",
       " ['Freeze!', 'Ferme!'],\n",
       " ['Freeze!', 'Che nessuno si muova!'],\n",
       " ['Get up.', 'Alzati.'],\n",
       " ['Go now.', 'Vai ora.'],\n",
       " ['Go now.', 'Vai adesso.'],\n",
       " ['Go now.', 'Vada ora.'],\n",
       " ['Go now.', 'Vada adesso.'],\n",
       " ['Go now.', 'Andate ora.'],\n",
       " ['Go now.', 'Andate adesso.'],\n",
       " ['Got it!', 'Capito!'],\n",
       " ['Got it!', 'Capita!'],\n",
       " ['He ran.', 'Corse.'],\n",
       " ['Hop in.', 'Salta su.'],\n",
       " ['Hop in.', 'Saltate su.'],\n",
       " ['Hop in.', 'Salti su.'],\n",
       " ['Hug me.', 'Abbracciami.'],\n",
       " ['Hug me.', 'Mi abbracci.'],\n",
       " ['Hug me.', 'Abbracciatemi.'],\n",
       " ['I fell.', 'Sono caduta.'],\n",
       " ['I fell.', 'Sono caduto.'],\n",
       " ['I fell.', 'Io sono caduto.'],\n",
       " ['I fell.', 'Io sono caduta.'],\n",
       " ['I fell.', 'Caddi.'],\n",
       " ['I fell.', 'Io caddi.'],\n",
       " ['I knit.', 'Lavoro a maglia.'],\n",
       " ['I knit.', 'Io lavoro a maglia.'],\n",
       " ['I knit.', 'Lavoro ai ferri.'],\n",
       " ['I knit.', 'Io lavoro ai ferri.'],\n",
       " ['I know.', 'Lo so.'],\n",
       " ['I know.', 'Io lo so.'],\n",
       " ['I left.', 'Sono partito.'],\n",
       " ['I left.', 'Io sono partito.'],\n",
       " ['I left.', 'Sono partita.'],\n",
       " ['I left.', 'Io sono partita.'],\n",
       " ['I left.', 'Partii.'],\n",
       " ['I left.', 'Io partii.'],\n",
       " ['I left.', 'Me ne sono andato.'],\n",
       " ['I left.', 'Io me ne sono andato.'],\n",
       " ['I left.', 'Me ne sono andata.'],\n",
       " ['I left.', 'Io me ne sono andata.'],\n",
       " ['I left.', 'Me ne andai.'],\n",
       " ['I left.', 'Io me ne andai.'],\n",
       " ['I lied.', 'Ho mentito.'],\n",
       " ['I lied.', 'Io ho mentito.'],\n",
       " ['I lied.', 'Mentii.'],\n",
       " ['I lied.', 'Io mentii.'],\n",
       " ['I lost.', 'Ho perso.'],\n",
       " ['I lost.', 'Io ho perso.'],\n",
       " ['I lost.', 'Persi.'],\n",
       " ['I lost.', 'Io persi.'],\n",
       " ['I paid.', 'Ho pagato.'],\n",
       " ['I paid.', 'Pagai.'],\n",
       " ['I quit.', 'Mi licenzio.'],\n",
       " ['I swim.', 'Nuoto.'],\n",
       " ['I work.', 'Io lavoro.'],\n",
       " ['I work.', 'Lavoro.'],\n",
       " [\"I'm 19.\", 'Ho diciannove anni.'],\n",
       " [\"I'm 19.\", 'Ho 19 anni.'],\n",
       " [\"I'm OK.\", 'Sto bene.'],\n",
       " ['Listen.', 'Ascolta!'],\n",
       " ['Listen.', 'Ascoltate!'],\n",
       " ['Listen.', 'Ascolti!'],\n",
       " ['No way!', 'È impossibile.'],\n",
       " ['Really?', 'Veramente?'],\n",
       " ['Really?', 'Davvero?'],\n",
       " ['Thanks.', 'Grazie!'],\n",
       " ['Try it.', 'Provalo.'],\n",
       " ['Try it.', 'Provala.'],\n",
       " ['Try it.', 'Lo provi.'],\n",
       " ['Try it.', 'La provi.'],\n",
       " ['Try it.', 'Provatelo.'],\n",
       " ['Try it.', 'Provatela.'],\n",
       " ['We ate.', 'Abbiamo mangiato.'],\n",
       " ['We ate.', 'Noi abbiamo mangiato.'],\n",
       " ['We ate.', 'Mangiammo.'],\n",
       " ['We ate.', 'Noi mangiammo.'],\n",
       " ['We try.', 'Proviamo.'],\n",
       " ['We try.', 'Ci proviamo.'],\n",
       " ['We try.', 'Noi proviamo.'],\n",
       " ['We won.', 'Abbiamo vinto.'],\n",
       " ['We won.', 'Noi abbiamo vinto.'],\n",
       " ['We won.', 'Vincemmo.'],\n",
       " ['We won.', 'Noi vincemmo.'],\n",
       " ['Why me?', 'Perché io?'],\n",
       " ['Ask Tom.', 'Chiedi a Tom.'],\n",
       " ['Ask Tom.', 'Chiedete a Tom.'],\n",
       " ['Ask Tom.', 'Chieda a Tom.'],\n",
       " ['Ask Tom.', 'Chiedilo a Tom.'],\n",
       " ['Ask Tom.', 'Chiedetelo a Tom.'],\n",
       " ['Ask Tom.', 'Lo chieda a Tom.'],\n",
       " ['Awesome!', 'Fantastico!'],\n",
       " ['Awesome!', 'Spettacolare!'],\n",
       " ['Be calm.', 'Sii calmo.'],\n",
       " ['Be calm.', 'Sii calma.'],\n",
       " ['Be calm.', 'Sia calmo.'],\n",
       " ['Be calm.', 'Sia calma.'],\n",
       " ['Be calm.', 'Siate calmi.'],\n",
       " ['Be calm.', 'Siate calme.'],\n",
       " ['Be cool.', 'Atteggiati.'],\n",
       " ['Be fair.', 'Sii imparziale.'],\n",
       " ['Be fair.', 'Sia imparziale.'],\n",
       " ['Be fair.', 'Siate imparziali.'],\n",
       " ['Be kind.', 'Sii gentile.'],\n",
       " ['Be kind.', 'Sia gentile.'],\n",
       " ['Be kind.', 'Siate gentili.'],\n",
       " ['Be nice.', 'Sii gentile.'],\n",
       " ['Be nice.', 'Sia gentile.'],\n",
       " ['Be nice.', 'Siate gentili.'],\n",
       " ['Beat it.', 'Sparisci.'],\n",
       " ['Burn it.', 'Brucialo.'],\n",
       " ['Burn it.', 'Bruciala.'],\n",
       " ['Burn it.', 'Lo bruci.'],\n",
       " ['Burn it.', 'La bruci.'],\n",
       " ['Burn it.', 'Bruciatelo.'],\n",
       " ['Burn it.', 'Bruciatela.'],\n",
       " ['Call me.', 'Chiamami.'],\n",
       " ['Call me.', 'Chiamatemi.'],\n",
       " ['Call me.', 'Mi chiami.'],\n",
       " ['Call us.', 'Chiamaci.'],\n",
       " ['Call us.', 'Ci chiami.'],\n",
       " ['Call us.', 'Chiamateci.'],\n",
       " ['Come in.', 'Entrate!'],\n",
       " ['Come in.', 'Entra!'],\n",
       " ['Come in.', 'Entri!'],\n",
       " ['Come in.', 'Vieni dentro.'],\n",
       " ['Come in.', 'Venite dentro.'],\n",
       " ['Come in.', 'Venga dentro.'],\n",
       " ['Come in.', 'Entrate.'],\n",
       " ['Come on!', 'Forza!'],\n",
       " ['Come on!', 'Vada!'],\n",
       " ['Come on!', 'Andate!'],\n",
       " ['Drop it!', 'Mollalo!'],\n",
       " ['Drop it!', 'Mollala!'],\n",
       " ['Drop it!', 'Lo molli!'],\n",
       " ['Drop it!', 'La molli!'],\n",
       " ['Drop it!', 'Mollatelo!'],\n",
       " ['Drop it!', 'Mollatela!'],\n",
       " ['Get Tom.', 'Prendi Tom.'],\n",
       " ['Get Tom.', 'Prenda Tom.'],\n",
       " ['Get Tom.', 'Prendete Tom.'],\n",
       " ['Get out!', 'Vattene!'],\n",
       " ['Get out!', 'Andatevene!'],\n",
       " ['Get out!', 'Esci!'],\n",
       " ['Get out!', 'Se ne vada!'],\n",
       " ['Get out!', 'Vattene fuori!'],\n",
       " ['Get out!', 'Se ne vada fuori!'],\n",
       " ['Get out!', 'Andatevene fuori!'],\n",
       " ['Get out!', 'Uscite!'],\n",
       " ['Get out!', 'Esca!'],\n",
       " ['Get out.', 'Esci.'],\n",
       " ['Get out.', 'Vattene.'],\n",
       " ['Get out.', 'Uscite.'],\n",
       " ['Get out.', 'Esca.'],\n",
       " ['Go away!', 'Vattene!'],\n",
       " ['Go away!', 'Andatevene!'],\n",
       " ['Go away!', 'Vai via!'],\n",
       " ['Go away!', 'Se ne vada!'],\n",
       " ['Go away!', 'Vada via!'],\n",
       " ['Go away!', 'Andate via!'],\n",
       " ['Go away.', 'Vattene.'],\n",
       " ['Go away.', 'Se ne vada.'],\n",
       " ['Go away.', 'Andatevene.'],\n",
       " ['Go away.', 'Vai via.'],\n",
       " ['Go away.', 'Andate via.'],\n",
       " ['Go away.', 'Vada via.'],\n",
       " ['Go home.', 'Vai a casa.'],\n",
       " ['Go home.', 'Vada a casa.'],\n",
       " ['Go home.', 'Andate a casa.'],\n",
       " ['Go slow.', 'Vai lentamente.'],\n",
       " ['Go slow.', 'Vada lentamente.'],\n",
       " ['Go slow.', 'Andate lentamente.'],\n",
       " ['Goodbye!', 'Arrivederci.'],\n",
       " ['Goodbye!', 'Ciao!'],\n",
       " ['Hang on!', 'Aspetta!'],\n",
       " ['Hang on!', 'Aspettate!'],\n",
       " ['Hang on!', 'Aspetti!'],\n",
       " ['Hang on!', 'Attendi!'],\n",
       " ['Hang on!', 'Attenda!'],\n",
       " ['Hang on!', 'Attendete!'],\n",
       " ['Hang on.', 'Aspetta!'],\n",
       " ['Hang on.', 'Aspettate!'],\n",
       " ['Hang on.', 'Aspetti!'],\n",
       " ['Hang on.', 'Attendi!'],\n",
       " ['Hang on.', 'Attenda!'],\n",
       " ['Hang on.', 'Attendete!'],\n",
       " ['He came.', 'È venuto.'],\n",
       " ['He came.', 'Lui è venuto.'],\n",
       " ['He quit.', 'Ha rinunciato.'],\n",
       " ['He quit.', 'Lui ha rinunciato.'],\n",
       " ['He quit.', 'Rinunciò.'],\n",
       " ['He quit.', 'Lui rinunciò.'],\n",
       " ['He runs.', 'Corre.'],\n",
       " ['He runs.', 'Lui corre.'],\n",
       " ['Help me!', 'Aiutatemi!'],\n",
       " ['Help me!', 'Mi aiuti!'],\n",
       " ['Help me.', 'Aiutami.'],\n",
       " ['Help me.', 'Mi aiuti.'],\n",
       " ['Help me.', 'Aiutatemi.'],\n",
       " ['Help us.', 'Aiutateci.'],\n",
       " ['Help us.', 'Aiutaci.'],\n",
       " ['Help us.', 'Ci aiuti.'],\n",
       " ['Hit Tom.', 'Colpisci Tom.'],\n",
       " ['Hit Tom.', 'Colpisca Tom.'],\n",
       " ['Hit Tom.', 'Colpite Tom.'],\n",
       " ['Hold it!', 'Aspetta!'],\n",
       " ['Hold it!', 'Aspettate!'],\n",
       " ['Hold it!', 'Aspetti!'],\n",
       " ['Hold it!', 'Aspetta un attimo!'],\n",
       " ['Hold it!', 'Aspetti un attimo!'],\n",
       " ['Hold it!', 'Aspettate un attimo!'],\n",
       " ['Hold it!', 'Un attimo!'],\n",
       " ['Hug Tom.', 'Abbraccia Tom.'],\n",
       " ['Hug Tom.', 'Abbracci Tom.'],\n",
       " ['Hug Tom.', 'Abbracciate Tom.'],\n",
       " ['I agree.', \"Io sono d'accordo.\"],\n",
       " ['I bowed.', 'Mi sono inchinato.'],\n",
       " ['I bowed.', 'Mi sono inchinata.'],\n",
       " ['I bowed.', 'Mi inchinai.'],\n",
       " ['I cried.', 'Ho pianto.'],\n",
       " ['I cried.', 'Piansi.'],\n",
       " ['I dozed.', 'Ho dormicchiato.'],\n",
       " ['I dozed.', 'Dormicchiai.'],\n",
       " ['I dozed.', 'Ho sonnecchiato.'],\n",
       " ['I dozed.', 'Sonnecchiai.'],\n",
       " ['I drive.', 'Guido.'],\n",
       " ['I drive.', 'Io guido.'],\n",
       " ['I drove.', 'Ho guidato.'],\n",
       " ['I drove.', 'Guidai.'],\n",
       " ['I moved.', 'Mi sono mosso.'],\n",
       " ['I moved.', 'Mi sono mossa.'],\n",
       " ['I moved.', 'Mi sono trasferito.'],\n",
       " ['I moved.', 'Mi sono trasferita.'],\n",
       " ['I moved.', 'Mi mossi.'],\n",
       " ['I moved.', 'Mi trasferii.'],\n",
       " ['I slept.', 'Ho dormito.'],\n",
       " ['I slept.', 'Io ho dormito.'],\n",
       " ['I slept.', 'Dormii.'],\n",
       " ['I slept.', 'Io dormii.'],\n",
       " ['I smoke.', 'Io fumo.'],\n",
       " ['I smoke.', 'Fumo.'],\n",
       " ['I snore.', 'Russo.'],\n",
       " ['I snore.', 'Io russo.'],\n",
       " ['I stink.', 'Puzzo.'],\n",
       " ['I stink.', 'Io puzzo.'],\n",
       " ['I swore.', 'Ho giurato.'],\n",
       " ['I swore.', 'Giurai.'],\n",
       " [\"I'll go.\", 'Andrò.'],\n",
       " [\"I'll go.\", 'Io andrò.'],\n",
       " [\"I'm Tom.\", 'Sono Tom.'],\n",
       " [\"I'm Tom.\", 'Io sono Tom.'],\n",
       " [\"I'm fat.\", 'Sono grasso.'],\n",
       " [\"I'm fat.\", 'Io sono grasso.'],\n",
       " [\"I'm fat.\", 'Sono grassa.'],\n",
       " [\"I'm fat.\", 'Io sono grassa.'],\n",
       " [\"I'm fit.\", 'Sono in forma.'],\n",
       " [\"I'm fit.\", 'Io sono in forma.'],\n",
       " [\"I'm hit!\", 'Sono stato colpito!'],\n",
       " [\"I'm hit!\", 'Sono stata colpita!'],\n",
       " [\"I'm hot.\", 'Ho caldo.'],\n",
       " [\"I'm hot.\", 'Io ho caldo.'],\n",
       " [\"I'm ill.\", 'Sono malato.'],\n",
       " [\"I'm ill.\", 'Sono malata.'],\n",
       " [\"I'm ill.\", 'Sto male.'],\n",
       " [\"I'm ill.\", 'Sono ammalato.'],\n",
       " [\"I'm old.\", 'Sono vecchio.'],\n",
       " [\"I'm old.\", 'Sono vecchia.'],\n",
       " [\"I'm old.\", 'Io sono vecchio.'],\n",
       " [\"I'm old.\", 'Io sono vecchia.'],\n",
       " [\"I'm sad.\", 'Sono triste.'],\n",
       " [\"I'm sad.\", 'Io sono triste.'],\n",
       " [\"I'm shy.\", 'Sono timido.'],\n",
       " [\"I'm shy.\", 'Io sono timido.'],\n",
       " [\"I'm shy.\", 'Sono timida.'],\n",
       " [\"I'm shy.\", 'Io sono timida.'],\n",
       " [\"It's OK.\", 'Va bene.'],\n",
       " ['Join us.', 'Unisciti a noi.'],\n",
       " ['Keep it.', 'Tienilo.'],\n",
       " ['Keep it.', 'Lo tenga.'],\n",
       " ['Keep it.', 'Tenetelo.'],\n",
       " ['Keep it.', 'Tienila.'],\n",
       " ['Keep it.', 'La tenga.'],\n",
       " ['Keep it.', 'Tenetela.'],\n",
       " ['Kick it.', 'Calcialo.'],\n",
       " ['Kick it.', 'Calciala.'],\n",
       " ['Kick it.', 'Lo calci.'],\n",
       " ['Kick it.', 'La calci.'],\n",
       " ['Kick it.', 'Calciatelo.'],\n",
       " ['Kick it.', 'Calciatela.'],\n",
       " ['Kiss me.', 'Baciami.'],\n",
       " ['Kiss me.', 'Baciatemi.'],\n",
       " ['Kiss me.', 'Mi baci.'],\n",
       " ['Lock it.', 'Chiudilo a chiave.'],\n",
       " ['Lock it.', 'Chiudila a chiave.'],\n",
       " ['Lock it.', 'Lo chiuda a chiave.'],\n",
       " ['Lock it.', 'Chiudetelo a chiave.'],\n",
       " ['Lock it.', 'La chiuda a chiave.'],\n",
       " ['Lock it.', 'Chiudetela a chiave.'],\n",
       " ['Me, too.', \"Anch'io.\"],\n",
       " ['Me, too.', 'Anche io.'],\n",
       " ['Me, too.', 'Pure io.'],\n",
       " ['Open up.', 'Apriti.'],\n",
       " ['Open up.', 'Apritevi.'],\n",
       " ['Open up.', 'Si apra.'],\n",
       " ['Open up.', 'Apri.'],\n",
       " ['Open up.', 'Apra.'],\n",
       " ['Open up.', 'Aprite.'],\n",
       " ['Open up.', 'Confidati.'],\n",
       " ['Open up.', 'Si confidi.'],\n",
       " ['Open up.', 'Confidatevi.'],\n",
       " ['Perfect!', 'Perfetto!'],\n",
       " ['Pull it.', 'Tiralo.'],\n",
       " ['Pull it.', 'Tirala.'],\n",
       " ['Pull it.', 'Lo tiri.'],\n",
       " ['Pull it.', 'La tiri.'],\n",
       " ['Pull it.', 'Tiratelo.'],\n",
       " ['Pull it.', 'Tiratela.'],\n",
       " ['Push it.', 'Spingilo.'],\n",
       " ['Push it.', 'Spingila.'],\n",
       " ['Push it.', 'Lo spinga.'],\n",
       " ['Push it.', 'La spinga.'],\n",
       " ['Push it.', 'Spingetelo.'],\n",
       " ['Push it.', 'Spingetela.'],\n",
       " ['See you!', 'Arrivederci.'],\n",
       " ['See you!', 'Ci si vede!'],\n",
       " ['See you.', 'Arrivederci.'],\n",
       " ['See you.', 'Ci si vede!'],\n",
       " ['See you.', 'Ci si vede.'],\n",
       " ['See you.', 'Ci vediamo.'],\n",
       " ['Show me.', 'Fammi vedere.'],\n",
       " ['Show me.', 'Mostrami.'],\n",
       " ['Show me.', 'Fatemi vedere.'],\n",
       " ['Show me.', 'Mi faccia vedere.'],\n",
       " ['Show me.', 'Mostratemi.'],\n",
       " ['Show me.', 'Mi mostri.'],\n",
       " ['Shut up!', 'Taci!'],\n",
       " ['Shut up!', 'Stai zitto!'],\n",
       " ['Shut up!', 'Stai zitta!'],\n",
       " ['Shut up!', 'Stia zitto!'],\n",
       " ['Shut up!', 'Stia zitta!'],\n",
       " ['Shut up!', 'State zitti!'],\n",
       " ['Shut up!', 'State zitte!'],\n",
       " ['Shut up!', 'Silenzio!'],\n",
       " ['Shut up!', 'Tacete!'],\n",
       " ['Shut up!', 'Taccia!'],\n",
       " ['Shut up!', \"Sta' zitto!\"],\n",
       " ['Skip it.', 'Saltalo.'],\n",
       " ['Skip it.', 'Saltala.'],\n",
       " ['Skip it.', 'Lo salti.'],\n",
       " ['Skip it.', 'La salti.'],\n",
       " ['Skip it.', 'Saltatelo.'],\n",
       " ['Skip it.', 'Saltatela.'],\n",
       " ['So long.', 'A tra poco!'],\n",
       " ['Stop it.', 'Smettila!'],\n",
       " ['Stop it.', 'La smetta!'],\n",
       " ['Stop it.', 'Smettetela!'],\n",
       " ['Tom ate.', 'Tom ha mangiato.'],\n",
       " ['Tom ate.', 'Tom mangiò.'],\n",
       " ['Tom ran.', 'Tom ha corso.'],\n",
       " ['Tom ran.', 'Tom corse.'],\n",
       " ['Tom won.', 'Tom ha vinto.'],\n",
       " ['Tom won.', 'Tom vinse.'],\n",
       " ['Tom won.', 'Ha vinto Tom.'],\n",
       " ['Tom won.', 'Vinse Tom.'],\n",
       " ['Wait up.', 'Aspetta.'],\n",
       " ['Wait up.', 'Aspetti.'],\n",
       " ['Wait up.', 'Aspettate.'],\n",
       " ['Wake up!', 'Sveglia!'],\n",
       " ['Wake up!', 'Svegliati!'],\n",
       " ['Wake up!', 'Svegliatevi!'],\n",
       " ['Wake up!', 'Si svegli!'],\n",
       " ['Wake up.', 'Alzati.'],\n",
       " ['Wash up.', 'Lavati.'],\n",
       " ['Wash up.', 'Lavatevi.'],\n",
       " ['Wash up.', 'Si lavi.'],\n",
       " ['We care.', 'A noi importa.'],\n",
       " ['We know.', 'Lo sappiamo.'],\n",
       " ['We know.', 'Noi lo sappiamo.'],\n",
       " ['We know.', 'Sappiamo.'],\n",
       " ['We know.', 'Noi sappiamo.'],\n",
       " ['We lost.', 'Abbiamo perso.'],\n",
       " ['We lost.', 'Noi abbiamo perso.'],\n",
       " ['We lost.', 'Perdemmo.'],\n",
       " ['We lost.', 'Noi perdemmo.'],\n",
       " ['Welcome.', 'Benvenuto!'],\n",
       " ['Welcome.', 'Benvenuta!'],\n",
       " ['Welcome.', 'Benvenuti!'],\n",
       " ['Welcome.', 'Benvenute!'],\n",
       " ['Welcome.', 'Ben arrivato!'],\n",
       " ['Who ate?', 'Chi ha mangiato?'],\n",
       " ['Who ran?', 'Chi ha corso?'],\n",
       " ['Who won?', 'Chi ha vinto?'],\n",
       " ['Why not?', 'Perché no?'],\n",
       " ['You run.', 'Corri.'],\n",
       " ['You run.', 'Correte.'],\n",
       " ['You run.', 'Corra.'],\n",
       " ['You won.', 'Hai vinto.'],\n",
       " ['You won.', 'Ha vinto.'],\n",
       " ['You won.', 'Avete vinto.'],\n",
       " ['Am I fat?', 'Sono grasso?'],\n",
       " ['Am I fat?', 'Io sono grasso?'],\n",
       " ['Am I fat?', 'Sono grassa?'],\n",
       " ['Am I fat?', 'Io sono grassa?'],\n",
       " ['Ask them.', 'Chiedilo a loro.'],\n",
       " ['Ask them.', 'Lo chieda a loro.'],\n",
       " ['Ask them.', 'Chiedetelo a loro.'],\n",
       " ['Back off!', 'Stai indietro!'],\n",
       " ['Back off!', 'Stia indietro!'],\n",
       " ['Back off!', 'State indietro!'],\n",
       " ['Back off.', 'Indietreggia.'],\n",
       " ['Back off.', 'Indietreggi.'],\n",
       " ['Back off.', 'Indietreggiate.'],\n",
       " ['Back off.', 'Tirati indietro.'],\n",
       " ['Back off.', 'Si tiri indietro.'],\n",
       " ['Back off.', 'Tiratevi indietro.'],\n",
       " ['Be brave.', 'Sii coraggioso.'],\n",
       " ['Be brave.', 'Sii coraggiosa.'],\n",
       " ['Be brave.', 'Sia coraggioso.'],\n",
       " ['Be brave.', 'Sia coraggiosa.'],\n",
       " ['Be brave.', 'Siate coraggiosi.'],\n",
       " ['Be brave.', 'Siate coraggiose.'],\n",
       " ['Be brief.', 'Siate brevi.'],\n",
       " ['Be brief.', 'Sii breve.'],\n",
       " ['Be brief.', 'Sia breve.'],\n",
       " ['Be still.', 'Stai fermo.'],\n",
       " ['Be still.', 'Stai ferma.'],\n",
       " ['Be still.', 'Stia fermo.'],\n",
       " ['Be still.', 'Stia ferma.'],\n",
       " ['Be still.', 'State fermi.'],\n",
       " ['Be still.', 'State ferme.'],\n",
       " ['Buzz off.', 'Levati dai piedi.'],\n",
       " ['Buzz off.', 'Si levi dai piedi.'],\n",
       " ['Buzz off.', 'Levatevi dai piedi.'],\n",
       " ['Bye, Tom.', 'Arrivederci, Tom.'],\n",
       " ['Bye, Tom.', 'Ci vediamo, Tom.'],\n",
       " ['Bye, Tom.', 'Ci si vede, Tom.'],\n",
       " ['Call Tom.', 'Chiama Tom.'],\n",
       " ['Call Tom.', 'Chiami Tom.'],\n",
       " ['Call Tom.', 'Chiamate Tom.'],\n",
       " ['Can I go?', 'Posso andare?'],\n",
       " ['Cheer up!', 'Coraggio!'],\n",
       " ['Cheer up!', 'Su col morale!'],\n",
       " ['Cheer up!', 'Su con la vita!'],\n",
       " ['Cool off!', 'Calmati!'],\n",
       " ['Cool off!', 'Rilassati!'],\n",
       " ['Cool off!', 'Rilassatevi!'],\n",
       " ['Cool off!', 'Si rilassi!'],\n",
       " ['Cool off!', 'Si calmi!'],\n",
       " ['Cool off!', 'Calmatevi!'],\n",
       " ['Cuff him.', 'Ammanettalo.'],\n",
       " ['Cuff him.', 'Lo ammanetti.'],\n",
       " ['Cuff him.', 'Ammanettatelo.'],\n",
       " [\"Don't go.\", 'Non andare.'],\n",
       " [\"Don't go.\", 'Non andate.'],\n",
       " [\"Don't go.\", 'Non vada.'],\n",
       " ['Drive on.', 'Continua a guidare.'],\n",
       " ['Drive on.', 'Continui a guidare.'],\n",
       " ['Drive on.', 'Continuate a guidare.'],\n",
       " ['Find Tom.', 'Trova Tom.'],\n",
       " ['Find Tom.', 'Trovate Tom.'],\n",
       " ['Find Tom.', 'Trovi Tom.'],\n",
       " ['Fix this.', 'Ripara questo.'],\n",
       " ['Fix this.', 'Riparate questo.'],\n",
       " ['Fix this.', 'Ripari questo.'],\n",
       " ['Fix this.', 'Fissa questo.'],\n",
       " ['Fix this.', 'Fissate questo.'],\n",
       " ['Fix this.', 'Fissi questo.'],\n",
       " ['Get away!', 'Vattene!'],\n",
       " ['Get away!', 'Andatevene!'],\n",
       " ['Get away!', 'Vai via!'],\n",
       " ['Get away!', 'Vattene.'],\n",
       " ['Get away!', 'Se ne vada.'],\n",
       " ['Get away!', 'Andatevene.'],\n",
       " ['Get away!', 'Vai via.'],\n",
       " ['Get away!', 'Andate via.'],\n",
       " ['Get away!', 'Vada via.'],\n",
       " ['Get away!', 'Se ne vada!'],\n",
       " ['Get away!', 'Vada via!'],\n",
       " ['Get away!', 'Andate via!'],\n",
       " ['Get down!', 'Vieni giù!'],\n",
       " ['Get down!', 'Venite giù!'],\n",
       " ['Get down!', 'Venga giù!'],\n",
       " ['Get lost!', 'Smamma!'],\n",
       " ['Get lost!', 'Smammate!'],\n",
       " ['Get lost!', 'Smammi!'],\n",
       " ['Get lost.', 'Smamma.'],\n",
       " ['Get lost.', 'Smammi.'],\n",
       " ['Get lost.', 'Smammate.'],\n",
       " ['Get lost.', 'Sgomma.'],\n",
       " ['Get lost.', 'Sgommate.'],\n",
       " ['Get lost.', 'Sgommi.'],\n",
       " ['Get lost.', 'Vai al diavolo.'],\n",
       " ['Get lost.', 'Vada al diavolo.'],\n",
       " ['Get lost.', 'Andate al diavolo.'],\n",
       " ['Get real.', 'Sii realista.'],\n",
       " ['Get real.', 'Sia realista.'],\n",
       " ['Get real.', 'Siate realisti.'],\n",
       " ['Get real.', 'Siate realiste.'],\n",
       " ['Go ahead!', 'Vai pure!'],\n",
       " ['Go ahead!', 'Vada pure!'],\n",
       " ['Go ahead!', 'Andate pure!'],\n",
       " ['Go ahead.', 'Vai pure.'],\n",
       " ['Go ahead.', 'Vai avanti.'],\n",
       " ['Good job!', 'Buon lavoro!'],\n",
       " ['Grab Tom.', 'Agguanta Tom.'],\n",
       " ['Grab Tom.', 'Agguantate Tom.'],\n",
       " ['Grab Tom.', 'Agguanti Tom.'],\n",
       " ['Grab him.', 'Afferralo.'],\n",
       " ['Grab him.', 'Afferratelo.'],\n",
       " ['Grab him.', 'Lo afferri.'],\n",
       " ['Have fun.', 'Divertiti!'],\n",
       " ['Have fun.', 'Divertitevi!'],\n",
       " ['Have fun.', 'Si diverta!'],\n",
       " ['He spoke.', 'Ha parlato.'],\n",
       " ['He spoke.', 'Lui ha parlato.'],\n",
       " ['He spoke.', 'Parlò.'],\n",
       " ['He spoke.', 'Lui parlò.'],\n",
       " ['He tried.', 'Provò.'],\n",
       " ['He tried.', 'Lui provò.'],\n",
       " ['He tries.', 'Prova.'],\n",
       " ['He tries.', 'Lui prova.'],\n",
       " [\"He's wet.\", 'È bagnato.'],\n",
       " [\"He's wet.\", 'Lui è bagnato.'],\n",
       " ['Help Tom.', 'Aiuta Tom.'],\n",
       " ['Help Tom.', 'Aiutate Tom.'],\n",
       " ['Help Tom.', 'Aiuti Tom.'],\n",
       " ['Help him.', 'Aiutatelo.'],\n",
       " ['Help him.', 'Aiutalo.'],\n",
       " ['Help him.', 'Lo aiuti.'],\n",
       " ['How cute!', 'Che carino!'],\n",
       " ['How cute!', 'Che carina!'],\n",
       " ['How cute!', 'Che carini!'],\n",
       " ['How cute!', 'Che carine!'],\n",
       " ['How deep?', 'Quanto profondo?'],\n",
       " ['How deep?', 'Quanto profonda?'],\n",
       " ['How deep?', 'Quanto profondi?'],\n",
       " ['How deep?', 'Quanto profonde?'],\n",
       " ['How nice!', 'Che bella!'],\n",
       " ['How nice!', 'Che belli!'],\n",
       " ['How nice!', 'Che belle!'],\n",
       " ['Humor me.', 'Assecondami.'],\n",
       " ['Humor me.', 'Mi assecondi.'],\n",
       " ['Humor me.', 'Assecondatemi.'],\n",
       " ['Humor me.', 'Fammi ridere.'],\n",
       " ['Humor me.', 'Mi faccia ridere.'],\n",
       " ['Humor me.', 'Fatemi ridere.'],\n",
       " ['Hurry up.', 'Svelto!'],\n",
       " ['Hurry up.', 'Sbrigati!'],\n",
       " ['Hurry up.', 'Sbrigatevi!'],\n",
       " ['Hurry up.', 'Si sbrighi!'],\n",
       " ['I agreed.', \"Ero d'accordo.\"],\n",
       " ['I agreed.', \"Io ero d'accordo.\"],\n",
       " ['I am fat.', 'Sono grasso.'],\n",
       " ['I am fat.', 'Io sono grasso.'],\n",
       " ['I am fat.', 'Sono grassa.'],\n",
       " ['I am fat.', 'Io sono grassa.'],\n",
       " ['I am hot.', 'Ho caldo.'],\n",
       " ['I am hot.', 'Io ho caldo.'],\n",
       " ['I am old.', 'Sono vecchio.'],\n",
       " ['I am old.', 'Sono vecchia.'],\n",
       " ['I ate it.', \"L'ho mangiato.\"],\n",
       " ['I ate it.', \"L'ho mangiata.\"],\n",
       " ['I burped.', 'Ruttai.'],\n",
       " ['I danced.', 'Ballai.'],\n",
       " ['I danced.', 'Danzai.'],\n",
       " ['I failed.', 'Ho fallito.'],\n",
       " ['I gasped.', 'Ho rantolato.'],\n",
       " ['I gasped.', 'Rantolai.'],\n",
       " ['I gasped.', 'Ho ansimato.'],\n",
       " ['I gasped.', 'Ansimai.'],\n",
       " ['I got it.', 'Ho capito.'],\n",
       " ['I got it.', 'Ho compreso.'],\n",
       " ['I got it.', 'Io ho capito.'],\n",
       " ['I got it.', 'Io ho compreso.'],\n",
       " ['I helped.', 'Aiutai.'],\n",
       " ['I jumped.', 'Ho saltato.'],\n",
       " ['I jumped.', 'Saltai.'],\n",
       " ['I looked.', 'Ho guardato.'],\n",
       " ['I looked.', 'Guardai.'],\n",
       " ['I moaned.', 'Ho gemuto.'],\n",
       " ['I moaned.', 'Gemetti.'],\n",
       " ['I moaned.', 'Ho frignato.'],\n",
       " ['I moaned.', 'Frignai.'],\n",
       " ['I moaned.', 'Gemettei.'],\n",
       " ['I nodded.', 'Ho annuito.'],\n",
       " ['I nodded.', 'Annuii.'],\n",
       " ['I obeyed.', 'Ho ubbidito.'],\n",
       " ['I obeyed.', 'Ho obbedito.'],\n",
       " ['I paused.', 'Mi sono fermato.'],\n",
       " ['I paused.', 'Mi sono fermata.'],\n",
       " ['I paused.', 'Mi fermai.'],\n",
       " ['I paused.', 'Mi sono interrotto.'],\n",
       " ['I paused.', 'Mi sono interrotta.'],\n",
       " ['I phoned.', 'Ho telefonato.'],\n",
       " ['I phoned.', 'Io ho telefonato.'],\n",
       " ['I phoned.', 'Telefonai.'],\n",
       " ['I phoned.', 'Io telefonai.'],\n",
       " ['I prayed.', 'Pregai.'],\n",
       " ['I refuse.', 'Mi rifiuto.'],\n",
       " ['I refuse.', 'Io mi rifiuto.'],\n",
       " ['I rested.', 'Mi sono riposato.'],\n",
       " ['I rested.', 'Mi sono riposata.'],\n",
       " ['I rested.', 'Mi riposai.'],\n",
       " ['I shaved.', 'Mi sono rasato.'],\n",
       " ['I shaved.', 'Mi sono rasata.'],\n",
       " ['I shaved.', 'Mi rasai.'],\n",
       " ['I sighed.', 'Ho sospirato.'],\n",
       " ['I sighed.', 'Sospirai.'],\n",
       " ['I smiled.', 'Ho sorriso.'],\n",
       " ['I smiled.', 'Io ho sorriso.'],\n",
       " ['I smiled.', 'Sorrisi.'],\n",
       " ['I smiled.', 'Io sorrisi.'],\n",
       " ['I stayed.', 'Sono rimasto.'],\n",
       " ['I stayed.', 'Io sono rimasto.'],\n",
       " ['I stayed.', 'Sono rimasta.'],\n",
       " ['I stayed.', 'Io sono rimasta.'],\n",
       " ['I stayed.', 'Rimasi.'],\n",
       " ['I stayed.', 'Io rimasi.'],\n",
       " ['I stayed.', 'Restai.'],\n",
       " ['I stayed.', 'Io restai.'],\n",
       " ['I stayed.', 'Sono restato.'],\n",
       " ['I stayed.', 'Io sono restato.'],\n",
       " ['I stayed.', 'Sono restata.'],\n",
       " ['I stayed.', 'Io sono restata.'],\n",
       " ['I talked.', 'Ho parlato.'],\n",
       " ['I talked.', 'Parlai.'],\n",
       " ['I use it.', 'Lo uso.'],\n",
       " ['I use it.', 'La uso.'],\n",
       " ['I use it.', 'Io lo uso.'],\n",
       " ['I use it.', 'Io la uso.'],\n",
       " ['I use it.', 'Lo utilizzo.'],\n",
       " ['I use it.', 'Io lo utilizzo.'],\n",
       " ['I use it.', 'La utilizzo.'],\n",
       " ['I use it.', 'Io la utilizzo.'],\n",
       " ['I waited.', 'Ho aspettato.'],\n",
       " ['I waited.', 'Io ho aspettato.'],\n",
       " ['I waited.', 'Aspettai.'],\n",
       " ['I waited.', 'Io aspettai.'],\n",
       " ['I waited.', 'Aspettavo.'],\n",
       " ['I waited.', 'Io aspettavo.'],\n",
       " ['I winked.', \"Ho fatto l'occhiolino.\"],\n",
       " ['I winked.', \"Feci l'occhiolino.\"],\n",
       " ['I winked.', \"Ho strizzato l'occhio.\"],\n",
       " ['I winked.', \"Strizzai l'occhio.\"],\n",
       " ['I yawned.', 'Ho sbadigliato.'],\n",
       " ['I yawned.', 'Sbadigliai.'],\n",
       " [\"I'll die.\", 'Morirò.'],\n",
       " [\"I'll die.\", 'Io morirò.'],\n",
       " [\"I'll pay.\", 'Pago io.'],\n",
       " [\"I'll pay.\", 'Pagherò io.'],\n",
       " [\"I'll win.\", 'Vincerò.'],\n",
       " [\"I'll win.\", 'Io vincerò.'],\n",
       " [\"I'm a DJ.\", 'Sono un DJ.'],\n",
       " [\"I'm a DJ.\", 'Io sono un DJ.'],\n",
       " [\"I'm a DJ.\", 'Sono una DJ.'],\n",
       " [\"I'm a DJ.\", 'Io sono una DJ.'],\n",
       " [\"I'm back.\", 'Sono tornato.'],\n",
       " [\"I'm back.\", 'Sono ritornato.'],\n",
       " [\"I'm back.\", 'Sono tornata.'],\n",
       " [\"I'm bald.\", 'Sono calvo.'],\n",
       " [\"I'm bald.\", 'Io sono calvo.'],\n",
       " [\"I'm bald.\", 'Sono calva.'],\n",
       " [\"I'm bald.\", 'Io sono calva.'],\n",
       " [\"I'm busy.\", 'Sono occupato.'],\n",
       " [\"I'm busy.\", 'Sono impegnato.'],\n",
       " [\"I'm busy.\", 'Io sono impegnato.'],\n",
       " [\"I'm busy.\", 'Sono impegnata.'],\n",
       " [\"I'm busy.\", 'Io sono impegnata.'],\n",
       " [\"I'm busy.\", 'Io sono occupato.'],\n",
       " [\"I'm busy.\", 'Sono occupata.'],\n",
       " [\"I'm busy.\", 'Io sono occupata.'],\n",
       " [\"I'm calm.\", 'Sono calmo.'],\n",
       " [\"I'm calm.\", 'Io sono calmo.'],\n",
       " [\"I'm calm.\", 'Sono calma.'],\n",
       " [\"I'm calm.\", 'Io sono calma.'],\n",
       " [\"I'm cold.\", 'Ho freddo.'],\n",
       " [\"I'm cool.\", 'Sono figo.'],\n",
       " [\"I'm cool.\", 'Io sono figo.'],\n",
       " [\"I'm cool.\", 'Sono alla moda.'],\n",
       " [\"I'm cool.\", 'Io sono alla moda.'],\n",
       " [\"I'm deaf.\", 'Sono sordo.'],\n",
       " [\"I'm deaf.\", 'Io sono sordo.'],\n",
       " [\"I'm deaf.\", 'Sono sorda.'],\n",
       " [\"I'm deaf.\", 'Io sono sorda.'],\n",
       " [\"I'm done.\", 'Ho finito.'],\n",
       " [\"I'm done.\", 'Io ho finito.'],\n",
       " [\"I'm fast.\", 'Sono veloce.'],\n",
       " [\"I'm fast.\", 'Io sono veloce.'],\n",
       " [\"I'm fine.\", 'Sto bene.'],\n",
       " [\"I'm fine.\", 'Mi sento bene.'],\n",
       " [\"I'm free!\", 'Io sono libero!'],\n",
       " [\"I'm free.\", 'Sono libero.'],\n",
       " [\"I'm free.\", 'Sono libera.'],\n",
       " [\"I'm free.\", 'Sono gratuito.'],\n",
       " [\"I'm free.\", 'Sono gratuita.'],\n",
       " [\"I'm full.\", 'Sono pieno.'],\n",
       " [\"I'm full.\", 'Sono piena.'],\n",
       " [\"I'm full.\", 'Io sono pieno.'],\n",
       " [\"I'm full.\", 'Io sono piena.'],\n",
       " [\"I'm glad.\", 'Sono felice.'],\n",
       " [\"I'm glad.\", 'Io sono felice.'],\n",
       " [\"I'm glad.\", 'Io sono contento.'],\n",
       " [\"I'm glad.\", 'Sono contenta.'],\n",
       " [\"I'm glad.\", 'Io sono contenta.'],\n",
       " [\"I'm here.\", 'Sono qua.'],\n",
       " [\"I'm here.\", 'Sono qui.'],\n",
       " [\"I'm here.\", 'Io sono qui.'],\n",
       " [\"I'm here.\", 'Io sono qua.'],\n",
       " [\"I'm home.\", 'Sono a casa.'],\n",
       " [\"I'm home.\", 'Io sono a casa.'],\n",
       " [\"I'm hurt.\", 'Sono ferito.'],\n",
       " [\"I'm hurt.\", 'Io sono ferito.'],\n",
       " [\"I'm hurt.\", 'Sono ferita.'],\n",
       " [\"I'm hurt.\", 'Io sono ferita.'],\n",
       " [\"I'm late.\", 'Sono in ritardo.'],\n",
       " [\"I'm late.\", 'Io sono in ritardo.'],\n",
       " [\"I'm lazy.\", 'Sono pigro.'],\n",
       " [\"I'm lazy.\", 'Io sono pigro.'],\n",
       " [\"I'm lazy.\", 'Sono pigra.'],\n",
       " [\"I'm lazy.\", 'Io sono pigra.'],\n",
       " [\"I'm lost.\", 'Sono perso.'],\n",
       " [\"I'm lost.\", 'Io sono perso.'],\n",
       " [\"I'm lost.\", 'Sono persa.'],\n",
       " [\"I'm lost.\", 'Io sono persa.'],\n",
       " [\"I'm mean.\", 'Sono meschino.'],\n",
       " [\"I'm mean.\", 'Io sono meschino.'],\n",
       " [\"I'm mean.\", 'Sono meschina.'],\n",
       " [\"I'm mean.\", 'Io sono meschina.'],\n",
       " [\"I'm numb.\", 'Sono insensibile.'],\n",
       " [\"I'm numb.\", 'Io sono insensibile.'],\n",
       " [\"I'm numb.\", 'Sono intorpidito.'],\n",
       " [\"I'm numb.\", 'Io sono intorpidito.'],\n",
       " [\"I'm numb.\", 'Sono intorpidita.'],\n",
       " [\"I'm numb.\", 'Io sono intorpidita.'],\n",
       " [\"I'm poor.\", 'Sono povero.'],\n",
       " [\"I'm poor.\", 'Io sono povero.'],\n",
       " [\"I'm poor.\", 'Io sono povera.'],\n",
       " [\"I'm rich.\", 'Sono ricco.'],\n",
       " [\"I'm rich.\", 'Io sono ricco.'],\n",
       " [\"I'm rich.\", 'Sono ricca.'],\n",
       " [\"I'm rich.\", 'Io sono ricca.'],\n",
       " [\"I'm safe.\", 'Sono al sicuro.'],\n",
       " [\"I'm safe.\", 'Io sono al sicuro.'],\n",
       " [\"I'm sick.\", 'Sono malato.'],\n",
       " [\"I'm sick.\", 'Sono malata.'],\n",
       " [\"I'm sick.\", 'Sto male.'],\n",
       " [\"I'm sick.\", 'Sono ammalato.'],\n",
       " [\"I'm slow.\", 'Sono lento.'],\n",
       " [\"I'm slow.\", 'Io sono lento.'],\n",
       " [\"I'm slow.\", 'Sono lenta.'],\n",
       " [\"I'm slow.\", 'Io sono lenta.'],\n",
       " [\"I'm sure.\", 'Io sono positivo.'],\n",
       " [\"I'm thin.\", 'Sono magro.'],\n",
       " [\"I'm thin.\", 'Io sono magro.'],\n",
       " [\"I'm thin.\", 'Sono magra.'],\n",
       " [\"I'm thin.\", 'Io sono magra.'],\n",
       " [\"I'm tidy.\", 'Sono ordinato.'],\n",
       " [\"I'm tidy.\", 'Io sono ordinato.'],\n",
       " [\"I'm tidy.\", 'Sono ordinata.'],\n",
       " [\"I'm tidy.\", 'Io sono ordinata.'],\n",
       " [\"I'm weak.\", 'Sono debole.'],\n",
       " [\"I'm weak.\", 'Io sono debole.'],\n",
       " [\"I'm wise.\", 'Sono saggio.'],\n",
       " [\"I'm wise.\", 'Io sono saggio.'],\n",
       " [\"I'm wise.\", 'Sono saggia.'],\n",
       " [\"I'm wise.\", 'Io sono saggia.'],\n",
       " ['It helps.', 'Aiuta.'],\n",
       " ['It hurts.', 'Fa male.'],\n",
       " ['It works.', 'Questa funziona.'],\n",
       " [\"It's Tom.\", 'È Tom.'],\n",
       " [\"It's fun.\", 'È divertente.'],\n",
       " [\"It's his.\", 'È suo.'],\n",
       " [\"It's his.\", 'È sua.'],\n",
       " [\"It's hot.\", 'Fa caldo.'],\n",
       " [\"It's hot.\", \"C'è caldo.\"],\n",
       " [\"It's new.\", 'È nuovo.'],\n",
       " [\"It's new.\", 'È nuova.'],\n",
       " [\"It's odd.\", 'È strano.'],\n",
       " [\"It's odd.\", 'È strana.'],\n",
       " [\"It's red.\", 'È rosso.'],\n",
       " [\"It's red.\", 'È rossa.'],\n",
       " [\"It's sad.\", 'È triste.'],\n",
       " ['Keep out.', 'Non entrare.'],\n",
       " ['Kill Tom.', 'Uccidi Tom.'],\n",
       " ['Kill Tom.', 'Uccida Tom.'],\n",
       " ['Kill Tom.', 'Uccidete Tom.'],\n",
       " ['Kiss Tom.', 'Bacia Tom.'],\n",
       " ['Kiss Tom.', 'Baciate Tom.'],\n",
       " ['Kiss Tom.', 'Baci Tom.'],\n",
       " ['Leave it.', 'Lascialo.'],\n",
       " ['Leave it.', 'Lasciala.'],\n",
       " ['Leave it.', 'Lo lasci.'],\n",
       " ['Leave it.', 'La lasci.'],\n",
       " ['Leave it.', 'Lasciatelo.'],\n",
       " ['Leave it.', 'Lasciatela.'],\n",
       " ['Leave me.', 'Lasciami.'],\n",
       " ['Leave me.', 'Lasciatemi.'],\n",
       " ['Leave me.', 'Mi lasci.'],\n",
       " ['Leave us.', 'Lasciaci.'],\n",
       " ['Leave us.', 'Lasciateci.'],\n",
       " ['Leave us.', 'Ci lasci.'],\n",
       " [\"Let's go!\", 'Andiamo!'],\n",
       " [\"Let's go.\", 'Andiamo!'],\n",
       " ['Look out!', 'Attenzione!'],\n",
       " ['Look out!', 'Occhio!'],\n",
       " ['Marry me.', 'Sposami.'],\n",
       " ['Marry me.', 'Sposatemi.'],\n",
       " ['Marry me.', 'Mi sposi.'],\n",
       " ['Save Tom.', 'Salva Tom.'],\n",
       " ['Save Tom.', 'Salvate Tom.'],\n",
       " ['Save Tom.', 'Salvi Tom.'],\n",
       " ['She came.', 'È venuta.'],\n",
       " ['She came.', 'Lei è venuta.'],\n",
       " ['She died.', 'È morta.'],\n",
       " ['She died.', 'Lei è morta.'],\n",
       " ['She runs.', 'Corre.'],\n",
       " ['Sit down!', 'Siediti!'],\n",
       " ['Sit down.', 'Siediti.'],\n",
       " ['Sit down.', 'Si sieda.'],\n",
       " ['Sit down.', 'Sedetevi.'],\n",
       " ['Sit here.', 'Siediti qui.'],\n",
       " ['Sit here.', 'Si sieda qui.'],\n",
       " ['Sit here.', 'Sedetevi qui.'],\n",
       " ['Speak up!', 'Parla più forte!'],\n",
       " ['Speak up!', 'Parlate più forte!'],\n",
       " ['Speak up!', 'Parli più forte!'],\n",
       " ['Stand by.', 'Resta in attesa.'],\n",
       " ['Stand by.', 'Restate in attesa.'],\n",
       " ['Stand by.', 'Resti in attesa.'],\n",
       " ['Stand by.', 'Rimani in attesa.'],\n",
       " ['Stand by.', 'Rimanga in attesa.'],\n",
       " ['Stand by.', 'Rimanete in attesa.'],\n",
       " ['Stand up!', 'In piedi!'],\n",
       " ['Stand up!', 'Alzati in piedi!'],\n",
       " ['Stand up!', 'Alzatevi in piedi!'],\n",
       " ['Stand up!', 'Si alzi in piedi!'],\n",
       " ['Stand up.', 'Alzati.'],\n",
       " ['Stand up.', 'Alzatevi.'],\n",
       " ['Stand up.', 'Si alzi.'],\n",
       " ['Stay put.', 'Stai fermo.'],\n",
       " ['Stay put.', 'Stai ferma.'],\n",
       " ['Stay put.', 'Stia fermo.'],\n",
       " ['Stay put.', 'Stia ferma.'],\n",
       " ['Stay put.', 'State fermi.'],\n",
       " ['Stay put.', 'State ferme.'],\n",
       " ['Stay put.', 'Fermo lì.'],\n",
       " ['Stay put.', 'Ferma lì.'],\n",
       " ['Stay put.', 'Fermi lì.'],\n",
       " ['Stay put.', 'Ferme lì.'],\n",
       " ['Stop Tom.', 'Ferma Tom.'],\n",
       " ['Stop Tom.', 'Fermi Tom.'],\n",
       " ['Stop Tom.', 'Fermate Tom.'],\n",
       " ['Take Tom.', 'Prendi Tom.'],\n",
       " ['Take Tom.', 'Prenda Tom.'],\n",
       " ['Take Tom.', 'Prendete Tom.'],\n",
       " ['Tell Tom.', 'Dillo a Tom.'],\n",
       " ['Tell Tom.', 'Ditelo a Tom.'],\n",
       " ['Tell Tom.', 'Lo dica a Tom.'],\n",
       " ['Terrific!', 'Formidabile!'],\n",
       " ['Tom came.', 'Tom è venuto.'],\n",
       " ['Tom came.', 'Tom venne.'],\n",
       " ['Tom came.', 'È venuto Tom.'],\n",
       " ['Tom came.', 'Venne Tom.'],\n",
       " ['Tom died.', 'Tom è morto.'],\n",
       " ['Tom died.', 'Tom morì.'],\n",
       " ['Tom fell.', 'Tom è caduto.'],\n",
       " ['Tom fell.', 'Tom cadde.'],\n",
       " ['Tom fled.', 'Tom è fuggito.'],\n",
       " ['Tom fled.', 'Tom fuggì'],\n",
       " ['Tom knew.', 'Tom lo sapeva.'],\n",
       " ['Tom left.', 'Tom è partito.'],\n",
       " ['Tom left.', \"Tom se n'è andato.\"],\n",
       " ['Tom left.', 'Tom se ne andò.'],\n",
       " ['Tom left.', 'Tom partì.'],\n",
       " ['Tom lied.', 'Tom ha mentito.'],\n",
       " ['Tom lied.', 'Tom mentì.'],\n",
       " ['Tom lies.', 'Tom mente.'],\n",
       " ['Tom lost.', 'Tom ha perso.'],\n",
       " ['Tom lost.', 'Tom perse.'],\n",
       " ['Tom paid.', 'Tom ha pagato.'],\n",
       " ['Tom paid.', 'Tom pagò.'],\n",
       " ['Tom quit.', 'Tom ha rinunciato.'],\n",
       " ['Tom swam.', 'Tom ha nuotato.'],\n",
       " ['Tom swam.', 'Tom nuotò.'],\n",
       " ['Tom wept.', 'Tom piangeva.'],\n",
       " ['Tom wept.', 'Tom pianse.'],\n",
       " ['Tom wept.', 'Tom ha pianto.'],\n",
       " [\"Tom's up.\", 'Tom è alzato.'],\n",
       " ['Too late.', 'Troppo tardi.'],\n",
       " ['Try hard.', 'Prova duramente.'],\n",
       " ['Try hard.', 'Provate duramente.'],\n",
       " ['Try hard.', 'Provi duramente.'],\n",
       " ['Try some.', \"Provane un po'.\"],\n",
       " ['Try some.', \"Provatene un po'.\"],\n",
       " ['Try some.', \"Ne provi un po'.\"],\n",
       " ['Try this.', 'Prova questo.'],\n",
       " ['Try this.', 'Provate questo.'],\n",
       " ['Try this.', 'Provi questo.'],\n",
       " ['Use this.', 'Usa questo.'],\n",
       " ['Use this.', 'Usa questa.'],\n",
       " ['Use this.', 'Utilizza questo.'],\n",
       " ['Use this.', 'Utilizza questa.'],\n",
       " ['Use this.', 'Usate questo.'],\n",
       " ['Use this.', 'Usate questa.'],\n",
       " ['Use this.', 'Utilizzi questo.'],\n",
       " ['Use this.', 'Utilizzi questa.'],\n",
       " ['Use this.', 'Utilizzate questo.'],\n",
       " ['Use this.', 'Utilizzate questa.'],\n",
       " ['Use this.', 'Usi questo.'],\n",
       " ['Use this.', 'Usi questa.'],\n",
       " ['Warn Tom.', 'Avvisa Tom.'],\n",
       " ['Warn Tom.', 'Avvisate Tom.'],\n",
       " ['Warn Tom.', 'Avvisi Tom.'],\n",
       " ['Warn Tom.', 'Avverti Tom.'],\n",
       " ['Warn Tom.', 'Avverta Tom.'],\n",
       " ['Warn Tom.', 'Avvertite Tom.'],\n",
       " ['Watch me.', 'Guardami.'],\n",
       " ['Watch me.', 'Guardatemi.'],\n",
       " ['Watch me.', 'Mi guardi.'],\n",
       " ['Watch us.', 'Guardaci.'],\n",
       " ['Watch us.', 'Ci guardi.'],\n",
       " ['Watch us.', 'Guardateci.'],\n",
       " ['We agree.', \"Siamo d'accordo.\"],\n",
       " ['We agree.', \"Noi siamo d'accordo.\"],\n",
       " ['We tried.', 'Provavamo.'],\n",
       " ['We tried.', 'Noi provavamo.'],\n",
       " [\"We'll go.\", 'Andremo.'],\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ItalianNEng = to_lines(data)\n",
    "ItalianNEng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6qLyIgg7Ca1E"
   },
   "source": [
    "The ItalianEng has the data which we just imported and then ran through a funtion is now converted to the array by using the Python's inbuilt function \"array\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "p0rnc8lzCa1F",
    "outputId": "e98170ea-8a7b-4f3f-ce37-1304ec307f84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hi.', 'Ciao!'],\n",
       "       ['Run!', 'Corri!'],\n",
       "       ['Run!', 'Corra!'],\n",
       "       ...,\n",
       "       ['If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.',\n",
       "        'Se vuoi sembrare un madrelingua, devi essere disposto a esercitarti a ripetere la stessa frase più e più volte nello stesso modo in cui i suonatori di banjo praticano ripetutamente la stessa frase fino a che non riescono a suonarla correttamente e al tempo desiderato.'],\n",
       "       [\"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\",\n",
       "        'Se qualcuno che non conosce il tuo background dice che sembri un madrelingua, significa che probabilmente ha notato qualcosa sul tuo modo di parlare che ha fatto capire che non eri un madrelingua. In altre parole, non sembri davvero un madrelingua.'],\n",
       "       ['It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning, we might be able to minimize errors.',\n",
       "        'Può essere impossibile avere un corpus completamente libero da errori per via di questo tipo di impegno collaborativo. Ciononostante, se incoraggiamo i membri a contribuire con delle frasi nelle loro lingue piuttosto che sperimentare le lingue che stanno imparando, potremmo essere in grado di minimizzare gli errori.']],\n",
       "      dtype='<U317')"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ItalianNEng = array(ItalianNEng)\n",
    "ItalianNEng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6H3O7FrHCa1J"
   },
   "source": [
    "**As our dataset is too large, we will take first 50000 to train and test the model, If the CPU and GPU permits we can load the whole dataset**\n",
    "\n",
    "\n",
    "Split the whole dataset to check how model works and it would be better to run the model once for shorter dataset and then to increase the dataset if the CPU and GPU of the system permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "499YTMdWCa1K",
    "outputId": "b4bddc1e-3867-4ec1-b3b0-c4fdd9f4c7bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hi.', 'Ciao!'],\n",
       "       ['Run!', 'Corri!'],\n",
       "       ['Run!', 'Corra!'],\n",
       "       ...,\n",
       "       [\"I'm not able to speak.\", 'Non sono in grado di parlare.'],\n",
       "       [\"I'm not able to speak.\", 'Io non sono in grado di parlare.'],\n",
       "       [\"I'm not afraid of Tom.\", 'Non ho paura di Tom.']], dtype='<U317')"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ItalianNEng = ItalianNEng[:100000,:]\n",
    "ItalianNEng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hcVH3TYvCa1P",
    "outputId": "4c64bac6-c657-4c61-d371-7c6b0c096e09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U317')"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ItalianNEng.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxr1NdWvCa1T"
   },
   "source": [
    "<h3><a id=\"Data_Processing\">&#9997; Data Processing</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zvc7gKcUCa1U"
   },
   "source": [
    "**remove all the punctuation and then change the case of every word to lower case**\n",
    "\n",
    "\n",
    "we will remove the punctuation in the below code by going through each line of the data and storing it in the same variable ItalianEng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y--B195rCa1V"
   },
   "outputs": [],
   "source": [
    "ItalianNEng[:,0] = [sent.translate(str.maketrans('', '', string.punctuation)) for sent in ItalianNEng[:,0]]\n",
    "ItalianNEng[:,1] = [sent.translate(str.maketrans('', '', string.punctuation)) for sent in ItalianNEng[:,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7w8aHSo4Ca1Y"
   },
   "source": [
    "Here all the punctuation is removed/cleaned and the data looks like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "oVN8hs8fCa1Z",
    "outputId": "b80c3246-e032-466d-ad1c-95f0744d7b16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hi', 'Ciao'],\n",
       "       ['Run', 'Corri'],\n",
       "       ['Run', 'Corra'],\n",
       "       ...,\n",
       "       ['Im not able to speak', 'Non sono in grado di parlare'],\n",
       "       ['Im not able to speak', 'Io non sono in grado di parlare'],\n",
       "       ['Im not afraid of Tom', 'Non ho paura di Tom']], dtype='<U317')"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ItalianNEng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7YB316NCa1e"
   },
   "source": [
    "Now we will convert the data into lower case by using python's inbuilt function lower() and save the data to its original variable ItalianEng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQpyBTu8Ca1f"
   },
   "outputs": [],
   "source": [
    "for i in range(len(ItalianNEng)):\n",
    "    ItalianNEng[i,0] = ItalianNEng[i,0].lower()\n",
    "    \n",
    "    ItalianNEng[i,1] = ItalianNEng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "HxGHYXZ5Ca1i",
    "outputId": "0748300c-9261-4736-ab88-487313a86675"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['hi', 'ciao'],\n",
       "       ['run', 'corri'],\n",
       "       ['run', 'corra'],\n",
       "       ...,\n",
       "       ['im not able to speak', 'non sono in grado di parlare'],\n",
       "       ['im not able to speak', 'io non sono in grado di parlare'],\n",
       "       ['im not afraid of tom', 'non ho paura di tom']], dtype='<U317')"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ItalianNEng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "43wmUl_XCa1n"
   },
   "source": [
    "**Split the Italian sentence and English sentence and check the length of the words in an sentence and store in the list**\n",
    "\n",
    "To run the seq2Seq model on the data, we need to have both input and output of the same length, so to do that we will create two empty arrays where the length of the input and output is stored for the padding and tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omb6EprwCa1o"
   },
   "outputs": [],
   "source": [
    "eng_length = []\n",
    "ita_length = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in ItalianNEng[:,0]:\n",
    "    eng_length.append(len(i.split()))\n",
    "\n",
    "for i in ItalianNEng[:,1]:\n",
    "    ita_length.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17034
    },
    "colab_type": "code",
    "id": "qoLMVEM6Ca1s",
    "outputId": "8f0a2c59-f281-465d-8429-1544b4ad931f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17034
    },
    "colab_type": "code",
    "id": "SRYGkZYSCa1y",
    "outputId": "85e6879d-f2e9-4504-9f71-95ed3facea0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1K3pKnsCa14"
   },
   "source": [
    "The below graph shows the distribution of the length of the data, which will help us to decide on how much length we will be passing to the model and which data will be padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "c1cNOfcnCa15",
    "outputId": "327473ed-70b6-470f-d030-fe2b91de4c53"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_dframe = pd.DataFrame({'Enligh':eng_length, 'Italian':ita_length})\n",
    "length_dframe.hist(bins = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JsOt8dbpCa19"
   },
   "source": [
    "<h3><a id=\"Tokenization\">&#9997; Tokenization</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_DpYPQuhCa1-"
   },
   "source": [
    "**We will create a function which will tokenize our data with the help of the Keras's tokenization function which we have imported at the beginning of this notebook**\n",
    "\n",
    "Below is the function which will help us to vectorize the data by using Keras's tokenization function. Basically Tokenization will convert the text into sentences which will be well read by the model and it will be easier to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8y9mBD_Ca1_"
   },
   "outputs": [],
   "source": [
    "def tokenization(sentences):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJGJKfEmCa2C"
   },
   "source": [
    "Here we will tokenize the english word using the funtion we wrote above and then we will check the total English Vocabulary size after tokenizing --> here we are adding the additional one to the size as the tokenizer initiates from zero\n",
    "\n",
    "and the length of the English data is set to 5 because as per the above graph we see that maximum length of English data is 5 and 6 is the maximum length of Italian data, so to make it equal we will take length as **5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UvJygSGnCa2D",
    "outputId": "91543703-5535-48a9-e95d-8b8a9b626286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size in the dataset is: 6285\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "English_tokenizer = tokenization(ItalianNEng[:, 0])\n",
    "English_Vocab_Size = len(English_tokenizer.word_index) + 1\n",
    "\n",
    "Eng_length = 5\n",
    "print('English Vocabulary Size in the dataset is: %d' % English_Vocab_Size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "shvZxVaRCa2H"
   },
   "source": [
    "Here we will tokenize the Italian word using the funtion we wrote above and then we will check the total Italian Vocabulary size after tokenizing --> here we are adding the additional one to the size as the tokenizer initiates from zero\n",
    "\n",
    "and the length of the Italian data is set to 5 because as per the above graph we see that maximum length of English data is 5 and 6 is the maximum length of Italian data, so to make it equal we will take length as **5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oTI0IKpsCa2I",
    "outputId": "6381c9e1-54f5-4c2c-b81b-3b5a21efc18e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian Vocabulary Size in the dataset is: 13760\n"
     ]
    }
   ],
   "source": [
    "Italian_tokenizer = tokenization(ItalianNEng[:, 1])\n",
    "Italian_Vocab_Size = len(Italian_tokenizer.word_index) + 1\n",
    "\n",
    "Ita_length = 5\n",
    "print('Italian Vocabulary Size in the dataset is: %d' % Italian_Vocab_Size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WG8T_1DpCa2L"
   },
   "source": [
    "**The values must be encoded from text to sequences of number and padded the sequence using Keras's function**\n",
    "\n",
    "The below function will help to build the sequences and also perform sequence padding to the data if the data length of the sentence is less than the maximum length defined which is **5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Pwmx-zlCa2M"
   },
   "outputs": [],
   "source": [
    "def encode_sequences(tokenizer, length, lines):\n",
    "    sequences = tokenizer.texts_to_sequences(lines)\n",
    "    sequences = pad_sequences(sequences, maxlen=length, padding='post')\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M2tZRCUtCa2P"
   },
   "source": [
    "**split the data into training data and test data by using Sklearn.Model_selection's train_test_split function**\n",
    "\n",
    "\n",
    "Split the whole data which we saved in the variable ItalianNEng as 80% to train and 20% to the test. Once the data is split we will run it through the encode sequence which will create sequences of the text and then performs padding sequences on the data whose length is less than the defined maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q0-T_VHwCa2Q"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(ItalianNEng, test_size=0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wcTzw8MtCa2U",
    "outputId": "ab35cafa-6b2d-452f-e881-0b88deecd181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7pns3gqHCa2X",
    "outputId": "0361613d-a926-498d-956e-105e05a060dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Kug4PHBCa2a"
   },
   "outputs": [],
   "source": [
    "x_train = encode_sequences(Italian_tokenizer, Ita_length, train[:, 1])\n",
    "y_train = encode_sequences(English_tokenizer, Eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WFnEt_u-Ca2c"
   },
   "source": [
    "So every sentence is converted into 5 digit sequence which we will be feeding it to the model and if you see there are 0s added to the array where the length of the data is less than that of the maximum defined length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "d_mh-rX7Ca2d",
    "outputId": "4843fe18-ee3d-4616-a845-c185581e9b10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  26,  250,  188,    0,    0],\n",
       "       [   3,    2,    6,   51,    0],\n",
       "       [  13,   94,   10, 1272,    0],\n",
       "       ...,\n",
       "       [   1,    2, 2590,    0,    0],\n",
       "       [  14,    2,  337,   19, 1348],\n",
       "       [   3,   40, 9728,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "hsXVwGDZCa2g",
    "outputId": "371fbc60-cefd-4e9c-9604-2f795e6196e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3,  457,  364,    0,    0],\n",
       "       [  13,   58,   50,   79,    0],\n",
       "       [   1,  109,    9,  418,    0],\n",
       "       ...,\n",
       "       [   2,    5, 1444,    0,    0],\n",
       "       [  27,    3,   28,    9,  341],\n",
       "       [   1,   38,  458,    6,  146]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ep5hRKZuCa2k"
   },
   "outputs": [],
   "source": [
    "x_test = encode_sequences(Italian_tokenizer, Ita_length, test[:, 1])\n",
    "y_test = encode_sequences(English_tokenizer, Eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "WmrphKf1Ca2n",
    "outputId": "d173da2c-0021-4520-8540-58d05e5d2f3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  11,  182,    9, 4226,    0],\n",
       "       [  23,   27, 2450,    0,    0],\n",
       "       [   1, 1291,    6,  734,    0],\n",
       "       ...,\n",
       "       [1883,    0,    0,    0,    0],\n",
       "       [  67,   65,   41,  618,    0],\n",
       "       [ 274,   81,  171,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "bekPB2S2Ca2q",
    "outputId": "f81b0127-db39-4c7c-ba55-f64ce8c3cd71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  78,   12,    4, 4030,    0],\n",
       "       [  21,   41,  471,    0,    0],\n",
       "       [   2,  878,  652,    0,    0],\n",
       "       ...,\n",
       "       [   6, 2266,    0,    0,    0],\n",
       "       [ 160,  159,   45,  140,    0],\n",
       "       [   1,  105,   10,  283,    0]], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eDPKibh7Ca2t"
   },
   "source": [
    "<h3><a id=\"Build_The_Model\">&#9997; Build the Model</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Bzdjg1_Ca2u"
   },
   "source": [
    "## LSTM Model\n",
    "\n",
    "**Build the Seq2Seq LSTM model**\n",
    "\n",
    "Build the model which will take the encoded training dataset and once trained will predict the data which will be in the array format can be decoded back to text format by running it throught the function\n",
    "\n",
    "So the model architecture will be sequential which has encoder and decoder in it, Model would be sequential, embedding with LSTM layer and at the end it will be LSTM followed by the Dense layer which will act as a decoder for thr project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYedIn_vCa2v"
   },
   "outputs": [],
   "source": [
    "def build_model(ItalianVocabSize, EnglishVocabSize, ItalianLength, EnglishLength, Units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(ItalianVocabSize, Units, input_length=ItalianLength, mask_zero=True))\n",
    "    model.add(LSTM(Units))\n",
    "    model.add(RepeatVector(EnglishLength))\n",
    "    model.add(LSTM(Units, return_sequences=True))\n",
    "    model.add(Dense(EnglishVocabSize, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQ_DyYK0Ca2x"
   },
   "source": [
    "Build the model by passing the parameters and save the model and below is the summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "b_lRF1LLCa2y",
    "outputId": "bd03bc1b-8418-4b68-983e-86bbdd232448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 5, 512)            7045120   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5, 512)            2099200   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5, 6285)           3224205   \n",
      "=================================================================\n",
      "Total params: 14,467,725\n",
      "Trainable params: 14,467,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(Italian_Vocab_Size, English_Vocab_Size, Ita_length, Eng_length, 512 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGfJuhKXCa21"
   },
   "source": [
    "We are using RMSProp as the optimizer for the model and sparse_categorical_crossentropy as the loss function.\n",
    "\n",
    "we can play around with these to see which is better suitable for our model, but to train the model we will be going with the above mentoned optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4s_RER1hCa22"
   },
   "outputs": [],
   "source": [
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HbkuQN68Ca24"
   },
   "source": [
    "<h3><a id=\"Model_Train\">&#9997; Train the Model</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ykfXcGmECa27"
   },
   "source": [
    "\n",
    "we will train the model by passing the training data which we split and passed it through the funtion. we will be saving out model on each iteration of the epochs \n",
    "\n",
    "We will be running this model with **35 Epochs**, **512 batch size**\n",
    "\n",
    "we will play around with the batch size and number of epochs to see the best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4236
    },
    "colab_type": "code",
    "id": "UR3cmySDCa29",
    "outputId": "2759c6e9-f789-48fa-82cf-fa3857c20576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 64000 samples, validate on 16000 samples\n",
      "Epoch 1/60\n",
      "64000/64000 [==============================] - 13s 206us/step - loss: 4.5864 - val_loss: 4.1088\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.10880, saving model to SavedModel_Checkpoint\n",
      "Epoch 2/60\n",
      "64000/64000 [==============================] - 10s 164us/step - loss: 3.8674 - val_loss: 3.6999\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.10880 to 3.69989, saving model to SavedModel_Checkpoint\n",
      "Epoch 3/60\n",
      "64000/64000 [==============================] - 10s 162us/step - loss: 3.4296 - val_loss: 3.2454\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.69989 to 3.24540, saving model to SavedModel_Checkpoint\n",
      "Epoch 4/60\n",
      "64000/64000 [==============================] - 10s 160us/step - loss: 2.9694 - val_loss: 2.8810\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.24540 to 2.88097, saving model to SavedModel_Checkpoint\n",
      "Epoch 5/60\n",
      "64000/64000 [==============================] - 10s 162us/step - loss: 2.5808 - val_loss: 2.5657\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.88097 to 2.56567, saving model to SavedModel_Checkpoint\n",
      "Epoch 6/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 2.2645 - val_loss: 2.3213\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.56567 to 2.32133, saving model to SavedModel_Checkpoint\n",
      "Epoch 7/60\n",
      "64000/64000 [==============================] - 10s 160us/step - loss: 1.9983 - val_loss: 2.1521\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.32133 to 2.15214, saving model to SavedModel_Checkpoint\n",
      "Epoch 8/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 1.7662 - val_loss: 1.9498\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.15214 to 1.94978, saving model to SavedModel_Checkpoint\n",
      "Epoch 9/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 1.5581 - val_loss: 1.7967\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.94978 to 1.79673, saving model to SavedModel_Checkpoint\n",
      "Epoch 10/60\n",
      "64000/64000 [==============================] - 10s 160us/step - loss: 1.3706 - val_loss: 1.6985\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.79673 to 1.69846, saving model to SavedModel_Checkpoint\n",
      "Epoch 11/60\n",
      "64000/64000 [==============================] - 10s 160us/step - loss: 1.2052 - val_loss: 1.5569\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.69846 to 1.55694, saving model to SavedModel_Checkpoint\n",
      "Epoch 12/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 1.0607 - val_loss: 1.4516\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.55694 to 1.45158, saving model to SavedModel_Checkpoint\n",
      "Epoch 13/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 0.9324 - val_loss: 1.3818\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.45158 to 1.38183, saving model to SavedModel_Checkpoint\n",
      "Epoch 14/60\n",
      "64000/64000 [==============================] - 10s 160us/step - loss: 0.8218 - val_loss: 1.3041\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.38183 to 1.30409, saving model to SavedModel_Checkpoint\n",
      "Epoch 15/60\n",
      "64000/64000 [==============================] - 10s 160us/step - loss: 0.7230 - val_loss: 1.2513\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.30409 to 1.25128, saving model to SavedModel_Checkpoint\n",
      "Epoch 16/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.6393 - val_loss: 1.2056\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.25128 to 1.20558, saving model to SavedModel_Checkpoint\n",
      "Epoch 17/60\n",
      "64000/64000 [==============================] - 10s 160us/step - loss: 0.5655 - val_loss: 1.1551\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.20558 to 1.15514, saving model to SavedModel_Checkpoint\n",
      "Epoch 18/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 0.5017 - val_loss: 1.1294\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.15514 to 1.12943, saving model to SavedModel_Checkpoint\n",
      "Epoch 19/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 0.4452 - val_loss: 1.0908\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.12943 to 1.09080, saving model to SavedModel_Checkpoint\n",
      "Epoch 20/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.3975 - val_loss: 1.0801\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.09080 to 1.08009, saving model to SavedModel_Checkpoint\n",
      "Epoch 21/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 0.3561 - val_loss: 1.0534\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.08009 to 1.05343, saving model to SavedModel_Checkpoint\n",
      "Epoch 22/60\n",
      "64000/64000 [==============================] - 10s 160us/step - loss: 0.3207 - val_loss: 1.0360\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.05343 to 1.03599, saving model to SavedModel_Checkpoint\n",
      "Epoch 23/60\n",
      "64000/64000 [==============================] - 10s 160us/step - loss: 0.2894 - val_loss: 1.0229\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.03599 to 1.02293, saving model to SavedModel_Checkpoint\n",
      "Epoch 24/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.2637 - val_loss: 1.0149\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.02293 to 1.01491, saving model to SavedModel_Checkpoint\n",
      "Epoch 25/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.2407 - val_loss: 1.0361\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.01491\n",
      "Epoch 26/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.2222 - val_loss: 1.0067\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.01491 to 1.00674, saving model to SavedModel_Checkpoint\n",
      "Epoch 27/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.2054 - val_loss: 1.0118\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.00674\n",
      "Epoch 28/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1916 - val_loss: 1.0041\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.00674 to 1.00407, saving model to SavedModel_Checkpoint\n",
      "Epoch 29/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 0.1803 - val_loss: 1.0171\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.00407\n",
      "Epoch 30/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 0.1701 - val_loss: 1.0185\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.00407\n",
      "Epoch 31/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 0.1618 - val_loss: 1.0130\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.00407\n",
      "Epoch 32/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1547 - val_loss: 1.0217\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.00407\n",
      "Epoch 33/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1481 - val_loss: 1.0215\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.00407\n",
      "Epoch 34/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1431 - val_loss: 1.0299\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.00407\n",
      "Epoch 35/60\n",
      "64000/64000 [==============================] - 10s 161us/step - loss: 0.1380 - val_loss: 1.0343\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.00407\n",
      "Epoch 36/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1336 - val_loss: 1.0412\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.00407\n",
      "Epoch 37/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1300 - val_loss: 1.0424\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.00407\n",
      "Epoch 38/60\n",
      "64000/64000 [==============================] - 10s 160us/step - loss: 0.1268 - val_loss: 1.0568\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.00407\n",
      "Epoch 39/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1245 - val_loss: 1.0546\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.00407\n",
      "Epoch 40/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1207 - val_loss: 1.0656\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.00407\n",
      "Epoch 41/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1189 - val_loss: 1.0688\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.00407\n",
      "Epoch 42/60\n",
      "64000/64000 [==============================] - 10s 157us/step - loss: 0.1170 - val_loss: 1.0686\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.00407\n",
      "Epoch 43/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1152 - val_loss: 1.0749\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.00407\n",
      "Epoch 44/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1139 - val_loss: 1.0843\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.00407\n",
      "Epoch 45/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1120 - val_loss: 1.0870\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.00407\n",
      "Epoch 46/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 0.1101 - val_loss: 1.0933\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.00407\n",
      "Epoch 47/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 0.1093 - val_loss: 1.0982\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.00407\n",
      "Epoch 48/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1078 - val_loss: 1.1049\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.00407\n",
      "Epoch 49/60\n",
      "64000/64000 [==============================] - 10s 157us/step - loss: 0.1064 - val_loss: 1.1011\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.00407\n",
      "Epoch 50/60\n",
      "64000/64000 [==============================] - 10s 157us/step - loss: 0.1054 - val_loss: 1.1096\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.00407\n",
      "Epoch 51/60\n",
      "64000/64000 [==============================] - 10s 157us/step - loss: 0.1047 - val_loss: 1.1179\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.00407\n",
      "Epoch 52/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.1033 - val_loss: 1.1177\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.00407\n",
      "Epoch 53/60\n",
      "64000/64000 [==============================] - 10s 157us/step - loss: 0.1026 - val_loss: 1.1245\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.00407\n",
      "Epoch 54/60\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 0.1017 - val_loss: 1.1271\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.00407\n",
      "Epoch 55/60\n",
      "64000/64000 [==============================] - 10s 157us/step - loss: 0.1015 - val_loss: 1.1227\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.00407\n",
      "Epoch 56/60\n",
      "64000/64000 [==============================] - 10s 157us/step - loss: 0.1005 - val_loss: 1.1390\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.00407\n",
      "Epoch 57/60\n",
      "64000/64000 [==============================] - 10s 157us/step - loss: 0.0996 - val_loss: 1.1405\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.00407\n",
      "Epoch 58/60\n",
      "64000/64000 [==============================] - 10s 158us/step - loss: 0.0989 - val_loss: 1.1518\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.00407\n",
      "Epoch 59/60\n",
      "64000/64000 [==============================] - 10s 157us/step - loss: 0.0984 - val_loss: 1.1561\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.00407\n",
      "Epoch 60/60\n",
      "64000/64000 [==============================] - 10s 157us/step - loss: 0.0975 - val_loss: 1.1530\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.00407\n"
     ]
    }
   ],
   "source": [
    "filename = 'SavedModel_Checkpoint'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(x_train, y_train.reshape(y_train.shape[0], y_train.shape[1], 1), \n",
    "          epochs=60, batch_size=512,\n",
    "          validation_split = 0.2,\n",
    "          callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ADlZQZZCa3A"
   },
   "source": [
    "**plotting the graph** Once the model is built and we also capturing the model loss and the validation loss, we can go ahead and see how the loss is affected by the each iteration\n",
    "to see that we will plot the graph which will show us the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1093
    },
    "colab_type": "code",
    "id": "qXVNTHwnCa3B",
    "outputId": "61ac5c33-6128-4354-b6c6-1c63d1cabd37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3610f264e0>"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAByYAAAQPCAYAAABV6ozAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XuQneV9J/jvowsSSAiEuAuIxEWN\naAE6xwScASciJgZkqUXLhvYk3oxTk3jXlSrHqWx2PdnJZXecmuxuyut1NolnvJXM5GIHzE3iZhtz\nMXYMWQsBMiAkGRAgi5tgJCR0l9794zTiqu6W1KdP65zPp0r1dvf5vc/5nffov289v6dUVRUAAAAA\nAACAZhrT6gYAAAAAAACA9ieYBAAAAAAAAJpOMAkAAAAAAAA0nWASAAAAAAAAaDrBJAAAAAAAANB0\ngkkAAAAAAACg6QSTAAAAB6GUMraUsqWUcsZw1nJgSinrSinz+n/+w1LK14ZSexDvM6+U8sTBdQkA\nAEAimAQAADpEfzD41r+9pZRt7/j91w50vaqq9lRVNbmqqueHs/ZAlVK+VEr5L8O97kgopfz7Usq9\nH/D3k0opu0op5x7IelVV/Yeqqv6HYehrXCmlKqXMeMfa91dV1X2oa3/Ae51dSqmGe10AAIDRSDAJ\nAAB0hP5gcHJVVZOTPJ9k4Tv+9o/vrS+ljBv5LjvO3yf5xVLK6e/5+79Osryqqqda0BMAAABNIpgE\nAADIvp2H15dSvllK2Zzk06WUXyilPFRK2VhKebGU8tVSyvj++nftqiul/EP/63eVUjaXUh4spcw8\n0Nr+168upawupWwqpfxFKeWfSymfOYjP1F1K+X5//z8ppXz8Ha8tKKWs7H//daWU3+3/+4mllDv7\n73m9lPLAftb+einlz97ztztKKZ/v//kPSinrSylvlFKe+qARqlVVPZfkgST/3Xte+vUkf9e/zjml\nlPv6e9lQSvn7Usox++npXbtHSymfKaU813/fF99Tu9/vtr+nJHmif0ftJ0opV5RS1g7x2Q74/Q5V\nKWVi/zovllJ+Vkr5cinliP7X9vs9DeXZAwAAtIJgEgAA4G29Sb6R5Jgk1yfZneR3khyf5NIkVyX5\n7we4/1eT/GGS49LYlfkfDrS2lHJikhuS/H7/+z6b5OID/SD9AdbtSe5IckKS301yfSnl7P6Sv03y\nb6uqOjrJBUm+3//330/yTP89Jyf59/t5i28m+VQppfS/37Qkv9z/Ht1pPKd6VVVTklzd/xk/yH/N\nO4LJ/nu7+9dPkpLkS/29nJfkzDSe22Cf//wk/08az3l6klP713jLQN/tL/Zfu/t31N70nrUHe7bJ\ngf1f2J8/SnJRGt9Prb/Pf9f/2gd+Twf47AEAAEaUYBIAAOBtP6yq6raqqvZWVbWtqqofV1X1L1VV\n7a6q6pkk/znJLw1w/41VVS2rqmpXkn9MMvcgahckebSqqiX9r/1fSTYcxGe5NMkRSf7Pqqp2VVX1\nvSR3JflU/+u7kpxXSjm6qqrXq6pa/o6/n5rkjKqqdlZV9YE7JpPcn2R8kl/o//26JD+oqurlNEK/\niUm6Synjqqp6tv/5fZCbkpxeSnkrfP31JLdXVfV6klRVtbqqqnv6e3kljecx0HfwlmuT3FpV1T9X\nVbUjyR+kEXKmf90D/W7fabBnmxzY/4X9+bUkf1JV1av9n/1/y9sh7v6+pwN59gAAACNKMAkAAPC2\nF975Synl3P7xpC+VUt5IIxg6foD7X3rHz1uTTD6I2lPf2UdVVVWSdUPo/b1OTfJ8//1veS6N3YNJ\nY3doT5LnSyn3l1Iu6f/7n/XX3VNKebqU8vsftHhVVXvT2FX6r/v/9KtpBHCpqmpVkt9L43m9Uhrj\ncU/ezzpb0ggnf72UMiaNMO7v3nq9lHJyKeWG/lGmbyT5Lxn4O3jn53/nc9yS5PV3rHug3+171x7o\n2SYH9n9hoPd5bj/v8YHf04E8ewAAgJEmmAQAAHhb9Z7f/1OSx5Oc3T8W84/yjl13TfJiktPe+qV/\nVOr0/Zfv1/o0diK+s98zkvwsSfp3C/YkOTGNsaT/1P/3N6qq+t2qqmYkuSbJ/1xK2d9Owm8mubb/\n/MR6kpvfeqGqqn+oqurSJDOTjE3yHwfo9b+msdvwyiQTktz5jtf+9yQ7kpzf/x18JkP7Dl5Mcvpb\nv5RSJqcxVvUtA3237/1/8F4DPtthtD7Jz33Qewz0PR3gswcAABgxgkkAAID9OzrJpiRvllJmZ+Dz\nJYfL7UnqpZSFpZRxaZyDeMIg94wtpUx8x78JSX6UxljP3yuljC+l/HKS+WmchXhkKeVXSylT+keN\nbk6yN0n63/es/tBtU5I9b732XlVV/TjJG2mMQb2zqqrN/WvMLqVc3t/Htv5/H7hGv/uSvJnkr5N8\no7+ntxzd/9qmUsrpSf7HQZ7FW76VZFEp5Rf6+/hS3h047ve7rapqT5LX0jjP8oPs99kOsbf3ec/3\nN7F/9+g3k/xRKeX4UsoJaZxZ+Q/99R/4PR3EswcAABgxgkkAAID9+70k/yaN4O4/5RCCp6HqP6Ox\nL8mX0wjHzkrySBq7Bvfn03k7hNqWZFX/uYoLkyxK44zKryb51aqq1vTf82+SPNc/xvTf9q+RJF1J\n7k2yJck/J/m/q6r6wQDv/c0kVyT5xjv+NiHJ/9H/vi8lmZrkfxngM1dJ/j6N3YF/956X/zjJxWmE\nb0vTGPs6qKqqVqQR6t6Qxi7Dl/Lu8aqDfbd/nOQbpZSNpZTF71l7sGd7MLa9598vJvlfkzyWxs7O\nFUn+JW/vftzf93RAzx4AAGAklXcfiQEAAMBoUkoZm8ZIz08OEhACAADAqGbHJAAAwChTSrmqlHJs\n/zjOP0yyK8n/1+K2AAAA4JAIJgEAAEafy5I8k+TVJFcm6e0fHwoAAACHLaNcAQAAAAAAgKazYxIA\nAAAAAABounGtbuCdjj/++GrGjBmtbgMAAAAAAAAYoocffnhDVVUnDFY3qoLJGTNmZNmyZa1uAwAA\nAAAAABiiUspzQ6kzyhUAAAAAAABoOsEkAAAAAAAA0HSCSQAAAAAAAKDpRtUZkwAAAAAAADBcdu3a\nlXXr1mX79u2tbqUtTJw4MaeddlrGjx9/UPcLJgEAAAAAAGhL69aty9FHH50ZM2aklNLqdg5rVVXl\ntddey7p16zJz5syDWsMoVwAAAAAAANrS9u3bM23aNKHkMCilZNq0aYe0+1QwCQAAAAAAQNsSSg6f\nQ32WgkkAAAAAAACg6QSTAAAAAAAA0AQbN27MX/3VXx3wffPnz8/GjRub0FFrCSYBAAAAAACgCfYX\nTO7evXvA++68884ce+yxzWqrZca1ugEAAAAAAABoR1/84hfz9NNPZ+7cuRk/fnwmTpyYqVOn5qmn\nnsrq1atzzTXX5IUXXsj27dvzO7/zO/nsZz+bJJkxY0aWLVuWLVu25Oqrr85ll12WH/3oR5k+fXqW\nLFmSI488ssWf7OAIJgEAAAAAAGh/X/hC8uijw7vm3LnJV76y35f/7M/+LI8//ngeffTR3H///fn4\nxz+exx9/PDNnzkyS/M3f/E2OO+64bNu2LT//8z+fT3ziE5k2bdq71lizZk2++c1v5utf/3quu+66\n3HTTTfn0pz89vJ9jhAgmAQAAAAAAYARcfPHF+0LJJPnqV7+aW265JUnywgsvZM2aNe8LJmfOnJm5\nc+cmST70oQ9l7dq1I9bvcBNMAgAAAAAA0P4G2Nk4UiZNmrTv5/vvvz/f+9738uCDD+aoo47KvHnz\nsn379vfdM2HChH0/jx07Ntu2bRuRXpthTKsbAAAAAAAAgHZ09NFHZ/PmzR/42qZNmzJ16tQcddRR\neeqpp/LQQw+NcHcjz45JAAAAAAAAaIJp06bl0ksvzZw5c3LkkUfmpJNO2vfaVVddla997WuZPXt2\nurq68uEPf7iFnY6MUlVVq3vY56KLLqqWLVvW6jYAAAAAAABoAytXrszs2bNb3UZb+aBnWkp5uKqq\niwa71yhXAAAAAAAAoOkEkwAAAAAAAEDTCSYBAAAAAACAphNMAgAAAAAAAE0nmAQAAAAAAACaTjAJ\nAAAAAAAANJ1gEgAAAAAAAEaByZMnJ0nWr1+fT37ykx9YM2/evCxbtmzAdb7yla9k69at+36fP39+\nNm7cOHyNHiTBJAAAAAAAAIwip556am688caDvv+9weSdd96ZY489djhaOySCSQAAAAAAAGiCL37x\ni/nLv/zLfb//yZ/8Sb70pS/lox/9aOr1es4///wsWbLkffetXbs2c+bMSZJs27Ytn/rUpzJ79uz0\n9vZm27Zt++o+97nP5aKLLkp3d3f++I//OEny1a9+NevXr8/ll1+eyy+/PEkyY8aMbNiwIUny5S9/\nOXPmzMmcOXPyla98Zd/7zZ49O7/1W7+V7u7ufOxjH3vX+wyXccO+IgAAAAAAAIwyX/j2F/LoS48O\n65pzT56br1z1lf2+3tfXly984Qv57d/+7STJDTfckO985zv5/Oc/nylTpmTDhg358Ic/nJ6enpRS\nPnCNv/7rv85RRx2VlStXZsWKFanX6/te+9M//dMcd9xx2bNnTz760Y9mxYoV+fznP58vf/nLue++\n+3L88ce/a62HH344f/u3f5t/+Zd/SVVVueSSS/JLv/RLmTp1atasWZNvfvOb+frXv57rrrsuN910\nUz796U8Pw1N6mx2TAAAAAAAA0AS1Wi2vvPJK1q9fn8ceeyxTp07NySefnD/4gz/IBRdckCuuuCI/\n+9nP8vLLL+93jQceeGBfQHjBBRfkggsu2PfaDTfckHq9nlqtlieeeCJPPvnkgP388Ic/TG9vbyZN\nmpTJkydn8eLF+cEPfpAkmTlzZubOnZsk+dCHPpS1a9ce4qd/PzsmAQAAAAAAaHsD7WxspmuvvTY3\n3nhjXnrppfT19eUf//Ef8+qrr+bhhx/O+PHjM2PGjGzfvv2A13322Wfz53/+5/nxj3+cqVOn5jOf\n+cxBrfOWCRMm7Pt57NixTRnlasckAAAAAAAANElfX1/+6Z/+KTfeeGOuvfbabNq0KSeeeGLGjx+f\n++67L88999yA9//iL/5ivvGNbyRJHn/88axYsSJJ8sYbb2TSpEk55phj8vLLL+euu+7ad8/RRx+d\nzZs3v2+tj3zkI7n11luzdevWvPnmm7nlllvykY98ZBg/7cDsmAQAAAAAAIAm6e7uzubNmzN9+vSc\ncsop+bVf+7UsXLgw559/fi666KKce+65A97/uc99Lr/xG7+R2bNnZ/bs2fnQhz6UJLnwwgtTq9Vy\n7rnn5vTTT8+ll166757Pfvazueqqq3Lqqafmvvvu2/f3er2ez3zmM7n44ouTJL/5m7+ZWq3WlLGt\nH6RUVTUibzQUF110UbVs2bJWtwEAAAAAAEAbWLlyZWbPnt3qNtrKBz3TUsrDVVVdNNi9RrkCAAAA\nAAAATSeYBAAAAAAAAJpOMAkAAAAAAEDbGk3HGh7uDvVZCiYBAAAAAABoSxMnTsxrr70mnBwGVVXl\ntddey8SJEw96jXHD2A8AAAAAAACMGqeddlrWrVuXV199tdWttIWJEyfmtNNOO+j7BZMAAAAAAAC0\npfHjx2fmzJmtboN+RrkCAAAAAAAATSeYBAAAAAAAAJpOMAkAAAAAAAA0nWCynVRVsmtXq7sAAAAA\nAACA9xFMtos33khOOCH5i79odScAAAAAAADwPoLJdjFlSjJhQvLII63uBAAAAAAAAN5HMNlO6nXB\nJAAAAAAAAKOSYLKd1GrJypXJ1q2t7gQAAAAAAADeRTDZTur1ZO/e5Cc/aXUnAAAAAAAA8C6CyXZS\nqzWuy5e3tg8AAAAAAAB4D8FkOznjjOS445wzCQAAAAAAwKgjmGwnpTR2TdoxCQAAAAAAwCgjmGw3\ntVrjjMldu1rdCQAAAAAAAOwjmGw39Xqyc2eycmWrOwEAAAAAAIB9BJPtplZrXI1zBQAAAAAAYBQR\nTLabc85JJk1KHnmk1Z0AAAAAAADAPoLJdjN2bHLhhXZMAgAAAAAAMKoIJttRvZ48+miyd2+rOwEA\nAAAAAIAkgsn2VKslW7YkP/1pqzsBAAAAAACAJILJ9lSrNa7OmQQAAAAAAGCUEEy2o+7uZPx450wC\nAAAAAAAwaggm29ERRyRz5tgxCQAAAAAAwKghmGxX9XojmKyqVncCAAAAAAAAgsm2VaslGzYk69a1\nuhMAAAAAAAAQTLater1xNc4VAAAAAACAUUAw2a4uuCApJVm+vNWdAAAAAAAAgGCybU2alHR12TEJ\nAAAAAADAqCCYbGf1uh2TAAAAAAAAjAqCyXZWqyXr1iUbNrS6EwAAAAAAADqcYLKd1euNq3GuAAAA\nAAAAtJhgsp3Nndu4GucKAAAAAABAiwkm29lxxyUzZtgxCQAAAAAAQMsJJttdrWbHJAAAAAAAAC0n\nmGx39XqyZk3yxhut7gQAAAAAAIAOJphsd7Va4/rYY63tAwAAAAAAgI4mmGx3bwWTzpkEAAAAAACg\nhQST7e6UU5KTTnLOJAAAAAAAAC0lmGx3pTR2TdoxCQAAAAAAQAsJJjtBvZ48+WSyfXurOwEAAAAA\nAKBDCSY7Qa2W7N6dPP54qzsBAAAAAACgQwkmO0G93rga5woAAAAAAECLCCY7wcyZyTHHJMuXt7oT\nAAAAAAAAOpRgshOUksyda8ckAAAAAAAALSOY7BT1evLYY42zJgEAAAAAAGCECSY7Ra2WbN+erFrV\n6k4AAAAAAADoQILJTlGvN67GuQIAAAAAANACgslO0dWVTJyYLF/e6k4AAAAAAADoQILJTjFuXHLh\nhXZMAgAAAAAA0BKCyU5SqzWCyapqdScAAAAAAAB0GMFkJ6nXk02bkmefbXUnAAAAAAAAdBjBZCep\n1RpX50wCAAAAAAAwwgSTnWTOnGTsWOdMAgAAAAAAMOIEk51k4sSku9uOSQAAAAAAAEacYLLT1Gp2\nTAIAAAAAADDiBJOdpl5PXn45efHFVncCAAAAAABABxFMdpparXE1zhUAAAAAAIARJJjsNHPnNq7G\nuQIAAAAAADCCBJOd5uijk3POsWMSAAAAAACAESWY7ES1mh2TAAAAAAAAjCjBZCeq15O1a5PXX291\nJwAAAAAAAHQIwWQnqtUa10cfbW0fAAAAAAAAdAzBZCd6K5g0zhUAAAAAAIARIpjsRCeckJx2WrJ8\neas7AQAAAAAAoEMIJjtVvW7HJAAAAAAAACNGMNmparXkqaeSN99sdScAAAAAAAB0AMFkp6rXk6pK\nVqxodScAAAAAAAB0AMFkp6rVGlfnTAIAAAAAADACBJOd6rTTkmnTnDMJAAAAAADAiBBMdqpSGuNc\n7ZgEAAAAAABgBAgmO1mtljz+eLJzZ6s7AQAAAAAAoM0JJjtZvZ7s2pU8+WSrOwEAAAAAAKDNCSY7\nWa3WuBrnCgAAAAAAQJMJJjvZ2WcnkycnjzzS6k4AAAAAAABoc4LJTjZmTDJ3rh2TAAAAAAAANJ1g\nstPVasljjyV79rS6EwAAAAAAANqYYLLT1evJm28ma9a0uhMAAAAAAADamGCy09VqjatzJgEAAAAA\nAGgiwWSnO++85IgjBJMAAAAAAAA0lWCy040fn5x/frJ8eas7AQAAAAAAoI0JJmmcM/nII0lVtboT\nAAAAAAAA2pRgksY5k6+/njz/fKs7AQAAAAAAoE0JJmkEk4lzJgEAAAAAAGgawSTJBRckY8Y4ZxIA\nAAAAAICmEUySHHVUcu65dkwCAAAAAADQNIJJGup1OyYBAAAAAABoGsEkDbVasn598sorre4EAAAA\nAACANiSYpKFeb1yNcwUAAAAAAKAJBJM0zJ3buBrnCgAAAAAAQBMIJmk49tjkzDPtmAQAAAAAAKAp\nBJO8rVazYxIAAAAAAICmEEzytlotefrpZNOmVncCAAAAAABAmxFM8rZ6vXF99NHW9gEAAAAAAEDb\nEUzytlqtcXXOJAAAAAAAAMNMMMnbTj45OeUUwSQAAAAAAADDTjDJu9VqyfLlre4CAAAAAACANiOY\n5N3q9WTlymTbtlZ3AgAAAAAAQBsRTPJutVqyZ0/yk5+0uhMAAAAAAADaiGCSd6vVGlfnTAIAAAAA\nADCMBJNtYvfe3bn76bvz09d/emgLzZiRHHuscyYBAAAAAAAYVoLJNrFl55Z8/Bsfz9eWfe3QFiql\nsWvSjkkAAAAAAACGkWCyTRw78dhcefaVueGJG7K32ntoi9XryYoVya5dw9McAAAAAAAAHU8w2Ub6\nuvvywhsv5KF1Dx3aQrVasmNH8tRTw9MYAAAAAAAAHU8w2UZ6unoyYeyEXP/49Ye2UL3euBrnCgAA\nAAAAwDARTLaRKROmZP458/OtJ7+VPXv3HPxCs2YlRx2VLF8+fM0BAAAAAADQ0QSTbaavuy8vbnkx\nP3z+hwe/yNixyYUX2jEJAAAAAADAsBFMtpkFsxbkqPFH5fonDnGca63WCCb37h2exgAAAAAAAOho\ngsk2M+mISVkwa0FufPLG7N67++AXqtWSzZuTZ54ZvuYAAAAAAADoWILJNtTX3ZdXt76a+9fef/CL\n1OuNq3MmAQAAAAAAGAaCyTZ09dlXZ/IRk3P944cwzrW7Oxk3zjmTAAAAAAAADAvBZBs6cvyRWdS1\nKDc/dXN27dl1cItMmJDMmSOYBAAAAAAAYFgIJttUX3dfXt/2eu559p6DX6RWa4xyrarhawwAAAAA\nAICOJJhsUx8762M5ZsIxuf6JQxjnWq8nr76arF8/fI0BAAAAAADQkQSTbWrCuAm55txrcsvKW7Jj\n946DW6RWa1yXLx++xgAAAAAAAOhIgsk21tfdl007NuW7T3/34Ba48MKkFOdMAgAAAAAAcMgEk23s\nijOvyHFHHnfw41wnT05mzbJjEgAAAAAAgEMmmGxj48eOz+JzF2fJqiXZtmvbwS1Sq9kxCQAAAAAA\nwCETTLa5vjl92bJzS+766V0Ht0C9njz/fPLaa8PbGAAAAAAAAB1FMNnm5s2YlxOOOuHgx7nWao2r\nXZMAAAAAAAAcgqYHk6WUsaWUR0optzf7vXi/cWPG5ZPnfTK3r749b+5888AXEEwCAAAAAAAwDEZi\nx+TvJFk5Au/DfvR192Xrrq25ffVBZMPTpiVnnJEsXz78jQEAAAAAANAxmhpMllJOS/LxJP9vM9+H\ngV12xmU5ZfIphzbO1Y5JAAAAAAAADkGzd0x+Jcn/lGTv/gpKKZ8tpSwrpSx79dVXm9xOZxo7Zmyu\nPe/a3Lnmzryx440DX6BeT1avTrZsGf7mAAAAAAAA6AhNCyZLKQuSvFJV1cMD1VVV9Z+rqrqoqqqL\nTjjhhGa10/H65vRlx54duW3VbQd+c62WVFXy2GPD3xgAAAAAAAAdoZk7Ji9N0lNKWZvkn5L8cinl\nH5r4fgzgw6d9OKdPOf3gxrnW642rcyYBAAAAAAA4SE0LJquq+ndVVZ1WVdWMJJ9Kcm9VVZ9u1vsx\nsDFlTK7rvi7f/um3s3H7xgO7+dRTkxNOcM4kAAAAAAAAB63ZZ0wyilzXfV127d2VW5+69cBuLKWx\na1IwCQAAAAAAwEEakWCyqqr7q6paMBLvxf79/Kk/n5nHzjy4ca61WvL448mOHcPfGAAAAAAAAG3P\njskOUkrJdd3X5XvPfC+vbX3twG6u15Pdu5MnnmhOcwAAAAAAALQ1wWSH6evuy+69u3PzypsP7MZa\nrXFdvnz4mwIAAAAAAKDtCSY7zNyT5+ac48458HGuZ56ZHH20cyYBAAAAAAA4KILJDlNKSV93X+5b\ne19e3vLy0G8cM6axa9KOSQAAAAAAAA6CYLID9c3py95qb25aedOB3VirJY89luzZ05zGAAAAAAAA\naFuCyQ4058Q5Oe+E8w58nGu9nmzblqxa1ZzGAAAAAAAAaFuCyQ7V192XHzz3g6zfvH7oN9Vqjatz\nJgEAAAAAADhAgskO1dfdlypVvvXEt4Z+0+zZycSJgkkAAAAAAAAOmGCyQ3Ud35ULT7owNzx5w9Bv\nGjcuOf/8ZPny5jUGAAAAAABAWxJMdrC+7r786IUf5YVNLwz9plqtsWOyqprXGAAAAAAAAG1HMNnB\nruu+LklywxMHsGuyXk82bkzWrm1OUwAAAAAAALQlwWQHO+u4s/KhUz6U65+4fug31WqNq3MmAQAA\nAAAAOACCyQ7X192XH6//cZ75b88M7Ybzz0/GjnXOJAAAAAAAAAdEMNnhDnic65FHJrNn2zEJAAAA\nAADAARFMdrifO/bn8uHTPnxg41zrdcEkAAAAAAAAB0QwSfq6+/LoS49m9Wurh3ZDrZa8+GLy0kvN\nbQwAAAAAAIC2IZgk1553bUpKrn98iLsm6/XG1a5JAAAAAAAAhkgwSaZPmZ7Lzrhs6ONc585tXJcv\nb15TAAAAAAAAtBXBJEka41yfePWJPPHKE4MXT5mSnHWWHZMAAAAAAAAMmWCSJMknz/tkxpQxQ981\nWa/bMQkAAAAAAMCQCSZJkpw0+aTMmzEv1z9xfaqqGvyGiy9Onn02eeGF5jcHAAAAAADAYU8wyT59\n3X1Z/drqrHh5xeDFCxc2rrfe2tymAAAAAAAAaAuCSfZZPHtxxpaxQxvn2tWVzJ6d3Hxz8xsDAAAA\nAADgsCeYZJ/jjzo+Hz3zo0Mf59rbmzzwQLJhQ/ObAwAAAAAA4LAmmORd+rr78sx/eyYPv/jw4MWL\nFyd79ya33db8xgAAAAAAADisCSZ5l95zezN+zPhc//gQxrnW68kZZyS33NL8xgAAAAAAADisCSZ5\nl6lHTs3HzvpYbnjyhsHHuZaSXHNN8t3vJlu2jEyDAAAAAAAAHJYEk7xPX3dfnt/0fB5a99Dgxb29\nyY4dybe/3fzGAAAAAAAAOGwJJnmfRecuyoSxE3L9E0MY53rZZcm0acnNNze/MQAAAAAAAA5bgkne\nZ8qEKbn6nKvzrSe/lb3V3oGLx41LenqSO+5Idu4cmQYBAAAAAAA47Agm+UB93X1Zv3l9fvj8Dwcv\nXrw4eeON5N57m98YAAAAAAAAhyXBJB9owawFOXLckbn+8SGMc73iimTy5OSWW5rfGAAAAAAAAIcl\nwSQfaPIRk7Ng1oLcuPLG7N5hPAw7AAAgAElEQVS7e+DiiROTq69OlixJ9uwZmQYBAAAAAAA4rAgm\n2a++7r688uYr+f7a7w9e3NubvPxy8tBDzW8MAAAAAACAw45gkv2af878TBo/KTc8ccMQiucn48cn\nN9/c/MYAAAAAAAA47Agm2a8jxx+Znq6e3LTypuzas2vg4mOOaZw1ecstSVWNTIMAAAAAAAAcNgST\nDKivuy+vbXst9z577+DFvb3Js88mK1Y0vzEAAAAAAAAOK4JJBnTV2VdlyoQpuf6J6wcv7ulJSmns\nmgQAAAAAAIB3EEwyoAnjJuSac6/JLU/dkp17dg5cfNJJyaWXCiYBAAAAAAB4H8Ekg+rr7svG7Rvz\n3ae/O3hxb29jlOvTTze/MQAAAAAAAA4bgkkGdcWZV2TqxKlDG+fa29u42jUJAAAAAADAOwgmGdQR\nY4/I4tmLs+SpJdm+e/vAxTNnJnPnCiYBAAAAAAB4F8EkQ9LX3ZfNOzfnrjV3DV7c25s8+GDy0kvN\nbwwAAAAAAIDDgmCSIbl85uU54agThj7OtaqSJUua3xgAAAAAAACHBcEkQzJuzLh8YvYnctvq2/Lm\nzjcHLp4zJznrLONcAQAAAAAA2EcwyZD1zenL1l1bc8eaOwYuLKWxa/Kee5KNG0emOQAAAAAAAEY1\nwSRD9pEzPpKTJ588tHGuixcnu3cndwwSYgIAAAAAANARBJMM2dgxY3PtedfmzjV3ZvOOzQMXX3JJ\ncsopxrkCAAAAAACQRDDJAbqu+7ps3709t62+beDCMWOSRYuSu+5Ktm0bmeYAAAAAAAAYtQSTHJB/\ndfq/yvSjpw9tnGtvb7J1a3L33c1vDAAAAAAAgFFNMMkBGVPG5Lru6/Ltn347G7dvHLh43rzkmGOM\ncwUAAAAAAEAwyYHr6+7Lzj07s+SpJQMXHnFEsmBBsnRpsnv3yDQHAAAAAADAqCSY5IBdPP3izDh2\nxtDGuS5enLz+evLAA81vDAAAAAAAgFFLMMkBK6XkuvOuy93P3D34ONcrr0wmTjTOFQAAAAAAoMMJ\nJjko15x7TXbv3Z271tw1cOGkSY1w8tZbk6oameYAAAAAAAAYdQSTHJRLTrskJ046MUtXLx28uLc3\nWbcuWbas+Y0BAAAAAAAwKgkmOShjypgsnLUwd625Kzv37By4eOHCZOxY41wBAAAAAAA6mGCSg9bT\n1ZNNOzblB8/9YODC445L5s1Lbr55RPoCAAAAAABg9BFMctCuOPOKTBw3MUtWLRm8uLc3WbUqWbmy\n+Y0BAAAAAAAw6ggmOWhHjT8qv3Lmr2TpqqWpqmrg4muuaVyNcwUAAAAAAOhIgkkOyaKuRXlu03P5\nySs/Gbhw+vTk4osFkwAAAAAAAB1KMMkhWTBrQUpKlq5aOnhxb2+ybFny/PPNbwwAAAAAAIBRRTDJ\nITlp8km55LRLhh5MJsmttza3KQAAAAAAAEYdwSSHrGdWT368/sdZv3n9wIVdXcl55xnnCgAAAAAA\n0IEEkxyynq6eJMltq24bvLi3N3nggWTDhiZ3BQAAAAAAwGgimOSQnXfCeTlr6llZunqI41z37k1u\nG0KICQAAAAAAQNsQTHLISinp6erJPc/cky07twxcXK8nZ5xhnCsAAAAAAECHEUwyLHq6erJjz47c\n/fTdAxeWklxzTfLd7yZbBgkxAQAAAAAAaBuCSYbFpadfmqkTp2bJqiWDFy9enOzYkdx1V/MbAwAA\nAAAAYFQQTDIsxo8dn/nnzM/tq2/Pnr17Bi6+7LLk+OONcwUAAAAAAOgggkmGzaKuRXlt22t5cN2D\nAxeOHZv09CR33JHs3DkyzQEAAAAAANBSgkmGzZVnX5nxY8Zn6aqlgxf39iZvvJHce2/zGwMAAAAA\nAKDlBJMMmykTpuTymZcPLZi84opk8mTjXAEAAAAAADqEYJJh1TOrJ6teW5VVG1YNXDhxYjJ/frJk\nSbJnkDMpAQAAAAAAOOwJJhlWC7sWJsnQx7m+/HLy4CBnUgIAAAAAAHDYE0wyrM445ozUTq5l6eoh\nBJPz5ydHHGGcKwAAAAAAQAcQTDLserp68qMXfpRX33x14MIpU5KPfrQRTFbVyDQHAAAAAABASwgm\nGXY9XT3ZW+3NHWvuGLy4tzd59tlkxYrmNwYAAAAAAEDLCCYZdrWTa5l+9PShnTPZ05OUYpwrAAAA\nAABAmxNMMuxKKenp6sl3nv5Otu/ePnDxSScll12W3HzzyDQHAAAAAABASwgmaYpFXYuyddfW3Pvs\nvYMX9/YmP/lJ8vTTzW8MAAAAAACAlhBM0hTzZszL5CMmD22ca29v42qcKwAAAAAAQNsSTNIUE8ZN\nyFVnX5Wlq5Zmb7V34OIZM5K5cwWTAAAAAAAAbUwwSdP0zOrJi1tezMPrHx68uLc3efDB5KWXmt8Y\nAAAAAAAAI04wSdPMP2d+xpaxQxvnunhxUlXJkiXNbwwAAAAAAIARJ5ikaaYdNS2XnXFZlq4eQjDZ\n3Z2cfXZy883NbwwAAAAAAIARJ5ikqXq6erLi5RVZu3HtwIWlNMa53ntvsnHjiPQGAAAAAADAyBFM\n0lQLZy1MkqGNc+3tTXbvTu64o8ldAQAAAAAAMNIEkzTVOdPOyezjZw8tmLzkkuSUU5Jbbml+YwAA\nAAAAAIwowSRN19PVk+8/9/1s3D7IiNYxY5JFi5K77kq2bRuZ5gAAAAAAABgRgkmablHXouzeuzvf\n/um3By9evDjZujW5++7mNwYAAAAAAMCIEUzSdBdPvzgnTjpxaONc581Ljj02ufnmpvcFAAAAAADA\nyBFM0nRjx4zNgnMW5M41d2bXnl0DF48fnyxYkNx2W7J798g0CAAAAAAAQNMJJhkRPV092bRjUx54\n7oHBi3t7k9dfTx4YQi0AAAAAAACHBcEkI+KKM6/IxHEThzbO9cork4kTk1tuaX5jAAAAAAAAjAjB\nJCNi0hGT8itn/kqWrl6aqqoGKZ6UXHVVcuutyWC1AAAAAAAAHBYEk4yYnq6erN24Nj955SeDF/f2\nJuvWJcuWNb8xAAAAAAAAmk4wyYhZMGtBkgxtnOuCBcnYscnNNze5KwAAAAAAAEaCYJIRc/Lkk3PJ\n9EuGFkwed1wyb55zJgEAAAAAANqEYJIRtahrUX68/sdZv3n94MW9vcmqVcnKlc1vDAAAAAAAgKYS\nTDKierp6kiS3r7598OJrrmlc7ZoEAAAAAAA47AkmGVHnnXBezpx6ZpasWjJ48fTpySWXCCYBAAAA\nAADagGCSEVVKSc+sntzzzD3ZsnPL4Df09ibLliXPP9/85gAAAAAAAGgawSQjrqerJzv27MjdT989\neHFvb+N6663NbQoAAAAAAICmEkwy4i4747JMnTg1S1cvHbx41qzkvPOMcwUAAAAAADjMCSYZcePH\njs/8c+bn9tW3Z8/ePYPf0NubPPBAsmFD85sDAAAAAACgKQSTtERPV082bN2QB9c9OHjx4sXJ3r3J\nbbc1vzEAAAAAAACaQjBJS1x51pUZP2Z8lq4awjjXWi05/fRkyZLmNwYAAAAAAEBTCCZpiWMmHpN5\nM+YNLZgsJVm4MLn77mT79uY3BwAAAAAAwLATTNIyi7oWZdVrq7Jqw6rBixcuTLZuTe69t/mNAQAA\nAAAAMOwEk7TMwq6FSTK0XZOXX55MnuycSQAAAAAAgMOUYJKWOeOYMzL35LlZunoIweSECcnHPtYI\nJquq+c0BAAAAAAAwrASTtFTPrJ786IUf5dU3Xx28eOHC5Gc/Sx55pPmNAQAAAAAAMKwEk7RUT1dP\n9lZ7c+eaOwcvnj8/KcU4VwAAAAAAgMOQYJKWqp9Sz/Sjpw9tnOuJJya/8AuCSQAAAAAAgMOQYJKW\nKqWkp6sn3/npd7J99/bBb1i4MHn44cZIVwAAAAAAAA4bgklarqerJ2/uejP3Pnvv4MULFzaut9/e\n3KYAAAAAAAAYVoJJWu7yGZdn8hGTs3TVEMa5nndeMnOmca4AAAAAAACHGcEkLTdh3IRcedaVuW31\nbdlb7R24uJSkpye5557kzTdHpkEAAAAAAAAOmWCSUWFR16Ks37w+y19cPnjxwoXJ9u3J977X/MYA\nAAAAAAAYFoJJRoX558zPmDImS55aMnjxRz6STJlinCsAAAAAAMBhRDDJqDDtqGm57IzLsnT1EM6Z\nPOKI5KqrkttvT/YOMvoVAAAAAACAUUEwyajRM6snK15ekbUb1w6huCd5+eVk2bKm9wUAAAAAAMCh\nE0wyavR09SRJbls1hBGtV1+djB2bLB3CDksAAAAAAABaTjDJqHHOtHMy+/jZQxvnetxxyaWXOmcS\nAAAAAADgMCGYZFTp6erJ/Wvvz8btGwcvXrgwWbEiee655jcGAAAAAADAIRFMMqr0dPVk997d+fZP\nvz2E4sbo19x+e3ObAgAAAAAA4JAJJhlVLpl+SU446oQsXTWEca6zZjX+OWcSAAAAAABg1BNMMqqM\nHTM2C2YtyJ1r7syuPbsGv2HhwuT++5PNm5veGwAAAAAAAAdPMMmos6hrUTbt2JQHnntg8OKFC5Od\nO5Pvfrf5jQEAAAAAAHDQBJOMOleceUUmjps4tHGul16aTJ2a3HZb8xsDAAAAAADgoAkmGXUmHTEp\nV5x5RZauXpqqqgYuHjcumT8/ueOOZM+ekWkQAAAAAACAAyaYZFTqmdWTtRvX5vFXHh+8eOHCZMOG\n5KGHmt8YAAAAAAAA/z979x6uZVWgj/9+NhtkOIkGg2dTTAxPqKSoZWYppm48FKaBJqRlSQqV2WRZ\naupXcwbJNHMKVBCZPKUinsrQ1LAwETyVo5YaaKAoGAICz++P7W8cRoQN7He/+/D5XNd7vfCs9a51\n/8F/N2s960QxSbN02PaHJUnDrnM9+OD6k5OucwUAAAAAAGi2FJM0S5t23TR7bb5XbvnzLWuevOGG\nycc/rpgEAAAAAABoxhSTNFuD+gzKH2f/MbMXzl7z5Lq65Mknk2efrXwwAAAAAAAA1ppikmZrUJ9B\nSZLJf5m85sl1dfXfTk0CAAAAAAA0S4pJmq0de+6Ybbpv07D3TG67bdK3r2ISAAAAAACgmVJM0mwV\nRZFBfQbl18/9Ov9c+s81/2DQoOT++5PXX698OAAAAAAAANaKYpJm7fA+h2fJ8iW5+9m71zy5ri5Z\ntiy5887KBwMAAAAAAGCtKCZp1j661UfTvWP33PqXBlznutdeSY8ernMFAAAAAABohhSTNGvt27XP\nIR86JJP/MjnLVyxf/eR27ZJDD03uuKP+5CQAAAAAAADNhmKSZm/Q9oMyb9G8THtpWgMmD0rmz08e\nfLDywQAAAAAAAGgwxSTN3sHbHZz2Ne1zw5M3rHnyQQclHToktzbg6lcAAAAAAACajGKSZm/Djhum\nrk9drp11bZYuX7r6yV26JJ/4hPdMAgAAAAAANDOKSVqE4f2GZ+6iubn9L7eveXJdXfLMM8mf/1z5\nYAAAAAAAADSIYpIWYeB2A7Npl00zbsa4NU+uq6v/dmoSAAAAAACg2VBM0iLU1tTm+F2Pz5RnpuTl\nN19e/eSttkp23dV7JgEAAAAAAJoRxSQtxrB+w7K8XJ7xj41f8+S6uuTBB5NXX618MAAAAAAAANZI\nMUmL0adHn+yz5T4ZO2NsyrJc/eS6umTFiuSOO5omHAAAAAAAAKulmKRFGd5veJ6e93Qe/vvDq5/Y\nv3+yySbeMwkAAAAAANBMKCZpUY7e8eh0at8pYx8du/qJNTXJYYfVn5hcurRpwgEAAAAAAPC+FJO0\nKF036JrBfQdn0uOTsujtRaufXFeXLFyY3H9/04QDAAAAAADgfSkmaXGG9RuWhUsX5sYnb1z9xE99\nKunY0XWuAAAAAAAAzYBikhZnv633S++NemfcjHGrn9ipU305edttSVk2TTgAAAAAAABWSTFJi1MU\nRU7od0J++9ff5rn5z61+cl1d8vzzyRNPNE04AAAAAAAAVkkxSYv0hV2/kCJFrp5x9eonHnZY/bfr\nXAEAAAAAAKpKMUmLtOWGW+bA3gdm3IxxWb5i+ftP3GyzZI89FJMAAAAAAABVppikxRreb3heXPBi\n7n3+3tVPHDQomTYt+cc/miYYAAAAAAAA76GYpMU6fIfD071j94ybMW71E+vqkrJMbr+9aYIBAAAA\nAADwHopJWqyOtR0zZOchuempmzL/rfnvP7Ffv2SLLVznCgAAAAAAUEWKSVq0Yf2GZcnyJZn0+KT3\nn1QUyWGHJXffnSxe3HThAAAAAAAA+B+KSVq03TfdPbv02iVjZ4xd/cS6uuSf/0ymTm2SXAAAAAAA\nAKxMMUmLVhRFhvUblumzp2fWK7Pef+IBBySdOiW33tp04QAAAAAAAPgfiklavCE7D0n7mvYZN2Pc\n+0/q2DE56KBk8uSkLJsuHAAAAAAAAEkUk7QCPTv3TF2fukyYOSFLly99/4l1dcmLLyaPPdZ04QAA\nAAAAAEiimKSVGN5veOYumpvb/3L7+0869NCkKJLbbmu6YAAAAAAAACRRTNJKDNxuYDbtsunqr3Pt\n1SvZay/vmQQAAAAAAKgCxSStQm1NbY7f9fhMeWZKXn7z5fefWFeXTJ+ezJ7ddOEAAAAAAABQTNJ6\nDOs3LMvL5Rn/2Pj3n1RXV/99+2qufAUAAAAAAKDRKSZpNfr06JN9ttwnY2eMTVmWq560007J1lt7\nzyQAAAAAAEATU0zSqgzvNzxPz3s6D//94VVPKIpk0KDknnuSRYuaNhwAAAAAAEAbppikVTl6x6PT\nqX2njH107PtPqqtLFi9OfvObpgsGAAAAAADQxikmaVW6btA1g/sOzqTHJ2XR2+9zIvLjH0+6dnWd\nKwAAAAAAQBNSTNLqDOs3LAuXLsyNT9646gkdOiQDByaTJycrVjRtOAAAAAAAgDZKMUmrs9/W+6X3\nRr0zdsZqrnMdNCiZMyd55JGmCwYAAAAAANCGKSZpdYqiyAn9TsjUv07Nc/OfW/WkQw5Jampc5woA\nAAAAANBEFJO0Sl/Y9QspUuSqGVetesIHPpDss49iEgAAAAAAoIkoJmmVttxwyxzY+8BcNeOqLF+x\nfNWT6uqSGTOSF19s2nAAAAAAAABtkGKSVmt4v+F5ccGLuff5e1c9YdCg+m+nJgEAAAAAACpOMUmr\ndfgOh6d7x+4ZN2Pcqif06ZNst51iEgAAAAAAoAkoJmm1OtZ2zJCdh+Smp27K/Lfmv3dCUdRf53rv\nvcmbbzZ9QAAAAAAAgDZEMUmrNqzfsCxZviSTHp+06gl1dcnSpck99zRtMAAAAAAAgDZGMUmrtvum\nu2eXXrtk7Iyxq57w0Y8m3bsnt97atMEAAAAAAADaGMUkrVpRFBnWb1imz56eWa/Meu+E9u2TT386\nuf32ZPnypg8IAAAAAADQRigmafWG7Dwk7WvaZ9yMcaueUFeXzJ2b/OEPTRsMAAAAAACgDVFM0ur1\n7NwzdX3qMmHmhCxdvvS9Ew4+OGnXLrnttqYPBwAAAAAA0EYoJmkThvcbnrmL5ub2v9z+3sGNNkr2\n2897JgEAAAAAACpIMUmbMHC7gdm0y6arv871iSeS559v2mAAAAAAAABtRMWKyaIoOhZF8YeiKB4r\niuKJoijOrtResCa1NbU5ftfjM+WZKZmzcM57J9TV1X+7zhUAAAAAAKAiKnlickmSA8qy3DVJvyQH\nF0UxoIL7wWoN6zcsy8vlGT9z/HsHt9su2WEHxSQAAAAAAECFVKyYLOu9+c5f27/zKSu1H6xJnx59\nss+W+2TcjHEpy1X8Uxw0KJk6NXnjjSbPBgAAAAAA0NpV9B2TRVG0K4piRpJ/JLmnLMuHVzHnS0VR\nTC+KYvrcuXMrGQcyvN/wPD3v6Ux7adp7B+vqkmXLkrvuavpgAAAAAAAArVxFi8myLJeXZdkvyRZJ\n9iyKYqdVzLmyLMv+ZVn279mzZyXjQI7e8eh0at8p42aMe+/g3nsnH/iA61wBAAAAAAAqoKLF5P+v\nLMvXk/w2ycFNsR+8n64bdM3gvoMz6fFJ+efSf6482K5dcsghyZQp9ScnAQAAAAAAaDQVKyaLouhZ\nFEX3d/78L0kOTPJ0pfaDhhrWb1gWLl2Ym5666b2DgwYlr72WPPRQ0wcDAAAAAABoxSp5YnLTJL8t\nimJmkj+m/h2Tkyu4HzTIflvvl94b9c7YGWPfO3jQQUn79q5zBQAAAAAAaGQVKybLspxZluVuZVnu\nUpblTmVZnlOpvWBtFEWRE/qdkKl/nZrn5j+38mC3bsn++ysmAQAAAAAAGlmTvGMSmpsv7PqFFCly\n1Yyr3jt4xBHJn/+czJrV5LkAAAAAAABaK8UkbdKWG26ZA3sfmKtmXJXlK5avPDh4cNKuXXLttdUJ\nBwAAAAAA0AopJmmzhvcbnhcXvJh7n7935YGePZOBA5OJE5MVK6oTDgAAAAAAoJVRTNJmHb7D4ene\nsXvGzRj33sGhQ5MXX0x+97umDwYAAAAAANAKKSZpszrWdsyQnYfkpqduyvy35q88OGhQ0rmz61wB\nAAAAAAAaiWKSNm1Yv2FZsnxJJj0+aeWBzp2TI49Mrr8+WbKkOuEAAAAAAABaEcUkbdrum+6eXXrt\nkrEzxr53cOjQ5PXXkylTmj4YAAAAAABAK6OYpE0riiLD+g3L9NnTM+uVWSsPfvKTyb/+azJhQnXC\nAQAAAAAAtCKKSdq8ITsPSfua9hk3Y9zKA7W1ybHHJpMn15+cBAAAAAAAYJ0pJmnzenbumbo+dRk/\nc3yWLl+68uCQIcnSpckNN1QnHAAAAAAAQCuhmIQkw/sNz7xF83L7X25feaB//2T77ZNrr61OMAAA\nAAAAgFZCMQlJBm43MJt22TRjZ4xdeaAo6k9NTp2avPhiVbIBAAAAAAC0BopJSFJbU5vjdz0+dzxz\nR+YsnLPy4JAh9d/XXdf0wQAAAAAAAFoJxSS8Y1i/YVleLs/4meNXHujdOxkwwHWuAAAAAAAA60Ex\nCe/o06NP9tlyn4ybMS5lWa48OHRoMnNmMmtWdcIBAAAAAAC0cIpJ+F+G9xuep+c9nWkvTVt54Oij\nk3btnJoEAAAAAABYR4pJ+F+O3vHodGrfKeNmjFt5oGfPZODAZOLEZMWK6oQDAAAAAABowRST8L90\n3aBrBvcdnEmPT8rCJQtXHhw6NHnxxeR3v6tOOAAAAAAAgBZMMQn/x8n9T87CpQtz1YyrVh4YNCjp\n3DmZMKEquQAAAAAAAFoyxST8HwO2GJABWwzImIfHZPmK5e8OdO6cHHVUcv31yeLF1QsIAAAAAADQ\nAikmYRVGDRiVZ+c/m8l/mbzywJAhyRtvJFOmVCcYAAAAAABAC6WYhFU46sNHZctuW+aShy9ZeeCT\nn0x69UquvbY6wQAAAAAAAFooxSSsQm1Nbb6259cy9a9TM+PlGf9roDY55phk8uRk/vzqBQQAAAAA\nAGhhFJPwPk7a46R0bt85o6eNXnlg6NBk6dLkxhurEwwAAAAAAKAFUkzC++jesXuG9RuW62Zdl5ff\nfPndgT32SLbf3nWuAAAAAAAAa0ExCatx6l6nZtmKZbn8j5e/+7Ao6k9NTp2avPhi1bIBAAAAAAC0\nJIpJWI0PfeBDOWz7w/LT6T/NW2+/9e7A5z9f/33dddUJBgAAAAAA0MIoJmENRg0YlXmL5uXaWf/r\n6tbevZMBA5IJE6oXDAAAAAAAoAVRTMIa7P/B/bNrr11zybRLUpbluwNDhyazZiUzZ1YvHAAAAAAA\nQAuhmIQ1KIoiIweMzBNzn8ivn/v1uwNHH520a5dce+37/xgAAAAAAIAkiklokGN3Oja9OvfK6Gmj\n333Ys2dy8MHJxInJihXVCwcAAAAAANACKCahATao3SBf/chXc8d/35Gn5z397sCQIclLLyX331+9\ncAAAAAAAAC2AYhIa6OT+J2eDdhtkzLQx7z48/PCkSxfXuQIAAAAAAKyBYhIa6F87/2uG7DwkVz92\ndV5d9Gr9w06dkiOPTK6/Plm8uLoBAQAAAAAAmjHFJKyFkQNG5q1lb+XKR6589+HQockbbyRTplQv\nGAAAAAAAQDOnmIS1sHOvnfOpbT+Vn/zxJ3l7+dv1Dw84IOnVy3WuAAAAAAAAq6GYhLU0cq+Rmb1w\ndq5/8vr6B7W1ybHHJpMnJ/PnVzccAAAAAABAM6WYhLX06Q99On0+0Cejp41OWZb1D4cMSZYuTW68\nsbrhAAAAAAAAminFJKylmqImp+11WqbPnp6HXnyo/uEeeyTbb59MmFDdcAAAAAAAAM2UYhLWwfG7\nHp+NOm6U0dNG1z8oimTo0OS++5IXXqhuOAAAAAAAgGZIMQnroHOHzvnSHl/KzU/fnOfnP1//8POf\nr/++7rrqBQMAAAAAAGimFJOwjkbsOSI1RU0u/cOl9Q9690723ju59trqBgMAAAAAAGiGFJOwjrbo\ntkUG9x2cn//p51mwZEH9wyFDklmzkpkzqxsOAAAAAACgmVFMwnoYOWBkFi5dmHGPjqt/cPTRSW2t\nU5MAAAAAAAD/h2IS1sOem++ZfbbcJ2MeHpPlK5YnPXsmAwcmEycmK1ZUOx4AAAAAAECzoZiE9TRq\nwKg8//rzufXPt9Y/GDo0eeml5P77qxsMAAAAAACgGVFMwno6YocjsvWGW+eShy+pfzBoUNKli+tc\nAQAAAAAA/hfFJKyn2pranLrXqbn/b/fnT3P+lHTqlBx1VHL99cnixdWOBwAAAAAA0CwoJqERfHG3\nL6ZLhy4ZPW10/YMhQ5I33kimTKluMAAAAAAAgGZCMQmNYMOOG2Z4v+H5r8f/K7MXzk4OOCDp1SuZ\nMKHa0QAAAAAAAJoFxSQ0klP3OjXLVizL5X+8PKmtTY49Nrn99mT+/GpHAwAAAAAAqDrFJDSS3hv3\nzuE7HJ4rpl+Rt95+q/4616VLkxtuqHY0AAAAAACAqlNMQiMaudfIvPrWqxk/c3yyxx5Jnz7JtddW\nOxYAAAAAAEDVKSahERkwVZwAACAASURBVO239X7ZbZPdcsm0S1Im9acm77sveeGFakcDAAAAAACo\nKsUkNKKiKDJqwKg8Ne+p3P3s3fXFZJJcd111gwEAAAAAAFSZYhIa2ed2+lw26bJJRk8bnWy7bbL3\n3q5zBQAAAAAA2jzFJDSyDu065JSPnJK7nr0rT859Mhk6NJk1K5k5s9rRAAAAAAAAqkYxCRVwcv+T\n07G2Y8ZMG5McfXRSW+vUJAAAAAAA0KYpJqECenTqkeN2OS7XzLwm8zolOfjgZOLEZMWKakcDAAAA\nAACoCsUkVMjIASOzeNni/Gz6z5IhQ5KXXkruv7/asQAAAAAAAKpCMQkV0rdn3xzU+6Bc9sfLsvTQ\ng5MuXZIJE6odCwAAAAAAoCoUk1BBowaMypw35+SXz09OjjoqueGGZPHiascCAAAAAABocopJqKCB\nvQfmwz0+nNHTRqf8/OeTN95Ibr+92rEAAAAAAACanGISKqgoiowcMDJ/mvOnPPChDZJNNkmuvbba\nsQAAAAAAAJqcYhIqbOguQ7Pxv2yc0X/8cXLMMfUnJufPr3YsAAAAAACAJqWYhArr1L5TTt7j5Pzq\n6V/luSP3T5YurX/XJAAAAAAAQBuimIQmcMqep6S2pjY/XnRv0qeP61wBAAAAAIA2RzEJTWCzrpvl\nczt9LmMfHZcFQz6b3Hdf8sIL1Y4FAAAAAADQZBST0ERG7jUyC5cuzC92e+fBdddVNQ8AAAAAAEBT\nUkxCE9ljsz3ysa0+lh8/e22W77N3MmFCtSMBAAAAAAA0GcUkNKFRA0blr6//Nbd8dqfk8ceTmTOr\nHQkAAAAAAKBJKCahCQ3qMyjbdN8mozvPTGprnZoEAAAAAADaDMUkNKF2Ne1y6l6n5oE5D2f6UQOS\niROTFSuqHQsAAAAAAKDiFJPQxIbvNjxdO3TN6L3K5O9/T+67r9qRAAAAAAAAKk4xCU2s2wbdcuLu\nJ+aX/3w4f9+kU3LttdWOBAAAAAAAUHGKSaiCr+35tawoV+Syz22bXH99snhxtSMBAAAAAABUlGIS\nqmCbjbbJETsckZ/1/FsWvbUguf32akcCAAAAAACoKMUkVMmoAaPy2rKFuebj3ZOf/azacQAAAAAA\nACpKMQlVsu+W+6b/Zv0z5qPts+LX9yRPPFHtSAAAAAAAABWjmIQqKYoiI/camaczN3d9uH0yZky1\nIwEAAAAAAFSMYhKqaPCOg7Nlty3zvSM2zIrx1yTz5lU7EgAAAAAAQEUoJqGKOrTrkAs+eUEe6TAv\n4/ss8a5JAAAAAACg1VJMQpUdu/Ox2WvzvfKdQzfImz+7NFm6tNqRAAAAAAAAGp1iEqqspqjJ6IGj\nM7vDkly03SvJL39Z7UgAAAAAAACNTjEJzcDeW+6dY3c6Nj/at8gLV1yYlGW1IwEAAAAAADQqxSQ0\nE//vU/8vqa3Nv/V6PHnggWrHAQAAAAAAaFSKSWgmttpwq3xz769n4i7JtCvPqnYcAAAAAACARqWY\nhGbkjP2/m03LLhnVcWrK556rdhwAAAAAAIBGo5iEZqRLhy45/+PnZNoWyaSfjah2HAAAAAAAgEaj\nmIRm5vj9T8vuizfKGcvuzKJXX652HAAAAAAAgEahmIRmpqaoyeiPX5AXu5X5j59/sdpxAAAAAAAA\nGoViEpqh/Q7+cj7zysa5YOEdmf36i9WOAwAAAAAAsN4Uk9BMXfTRc7KsKHPm+BOqHQUAAAAAAGC9\nKSahmdr26C9n5JNdc9Vr9+aR2Y9UOw4AAAAAAMB6UUxCc1VbmzMHfCs9/5mMuvGklGVZ7UQAAAAA\nAADrTDEJzVi3k0bkhw90yO9eezQ3PnVjteMAAAAAAACsM8UkNGfdu+eLe5yYnf9R5Ft3fiOLly2u\ndiIAAAAAAIB1opiEZq7dqSMz+s4yzy98IWOmjal2HAAAAAAAgHWimITm7kMfyid3rEvd8x1y3u/O\nyytvvlLtRAAAAAAAAGtNMQktwciRuXjy0ry1dFHO+u1Z1U4DAAAAAACw1hST0BJ84hPZfvNdMuKZ\n7vn5oz/PzFdmVjsRAAAAAADAWlFMQktQFMnIkTnrxlfTvV3nfP2ur6csy2qnAgAAAAAAaDDFJLQU\nxx6bjbr9a85+dqv85vnf5La/3FbtRAAAAAAAAA2mmISWomPH5CtfyZevfiIf7tY737z7m1m6fGm1\nUwEAAAAAADSIYhJakq98Je1rO+TfX/xwnnntmVz2h8uqnQgAAAAAAKBBFJPQkvTqlXz+8/n0z+7N\nwK0OyDn3n5N5i+ZVOxUAAAAAAMAaKSahpTnttGTRovz73N2ycMnC/GDqD6qdCAAAAAAAYI0Uk9DS\n9OuX7L9/drzs+nx595NyxfQr8uTcJ6udCgAAAAAAYLUUk9ASjRqVvPBCzl7YP106dMk37v5GtRMB\nAAAAAACslmISWqJDD016906PS3+Rsz5+Vu787ztzxzN3VDsVAAAAAADA+1JMQkvUrl1y6qnJ73+f\nEdkz2228Xb5x9zfy9vK3q50MAAAAAABglRST0FING5Z065YOl16eiw+8OE/NeypXPnJltVMBAAAA\nAACskmISWqquXZMTT0yuvz6DOu+eA7Y5IGdNPSvz35pf7WQAAAAAAADvoZiEluxrX0tWrEhx+eX5\nj4P+I/Pfmp9z7z+32qkAAAAAAADeQzEJLdkHP5gceWTys59l124fyom7n5hL/3Bp/vLqX6qdDAAA\nAAAAYCWKSWjpRo5M5s9Prrkm537i3PxL7b/k9HtOr3YqAAAAAACAlTSomCyKondRFBu88+f9i6I4\ntSiK7pWNBjTIvvsm/fsnY8akV6eeOfNjZ+bWP9+a3zz3m2onAwAAAAAA+B8NPTF5Y5LlRVFsl+TK\nJFsmmVixVEDDFUX9qcmnn07uvjunDTgtH+z+wYy6a1SWr1he7XQAAAAAAABJGl5MrijLclmSI5Nc\nWpbl6Uk2rVwsYK0MHpxsumkyenQ61nbMRZ+6KLP+MSu/ePQX1U4GAAAAAACQpOHF5NtFURyb5AtJ\nJr/zrH1lIgFrrUOHZMSI5O67kyeeyGf7fjYf3eqj+e69380bi9+odjoAAAAAAIAGF5PDkuyd5Lyy\nLJ8vimKbJOMrFwtYa1/6UtKxYzJmTIqiyOiBozN30dyc/7vzq50MAAAAAACgYcVkWZZPlmV5almW\n1xVFsVGSrmVZXljhbMDa6NEjOf74ZPz4ZN689N+sf76w6xdyycOX5Ln5z1U7HQAAAAAA0MY1qJgs\nimJqURTdiqLYOMmfkvxnURT/UdlowFo77bRk8eLkyiuTJOd/8vzU1tTmW/d8q8rBAAAAAACAtq6h\nV7luWJblgiRHJbmmLMu9knyqcrGAddK3b3LQQclPfpIsXZrNum6Wb+/77dz41I25/2/3VzsdAAAA\nAADQhjW0mKwtimLTJEcnmVzBPMD6GjUqmTMnuf76JMk39vlGtui2RUbdNSoryhVVDgcAAAAAALRV\nDS0mz0lyV5Jny7L8Y1EU2yZ5pnKxgHV20EHJDjskl1ySlGU6te+UCz91Yf4050+55rFrqp0OAAAA\nAABooxpUTJZleX1ZlruUZfmVd/7+XFmWn6lsNGCd1NTUv2ty+vTkwQeTJMfudGz22nyv/Ntv/i1v\nLn2zygEBAAAAAIC2qEHFZFEUWxRFcXNRFP9453NjURRbVDocsI6OPz7ZaKP6U5NJiqLIJQdfkpff\nfDkXPnBhlcMBAAAAAABtUUOvch2X5NYkm73zue2dZ0Bz1KlT8uUvJzffnDz/fJJkwBYDcuxOx+ZH\nD/0oj855tMoBAQAAAACAtqahxWTPsizHlWW57J3PVUl6VjAXsL5OOaX+Wtef/OR/Ho0eODo9O/fM\n4ZMOzytvvlLFcAAAAAAAQFvT0GLy1aIohhZF0e6dz9Akr1YyGLCettgiGTw4+fnPk4ULkyS9uvTK\nLcfcknmL5uWoXx6VJcuWVDkkAAAAAADQVjS0mBye5OgkLyeZk+SzSU6oUCagsYwcmSxYkIx79+bl\n3TfdPVcdcVUeevGhfPX2r6YsyyoGBAAAAAAA2ooGFZNlWf6tLMtBZVn2LMvyX8uyPCLJZyqcDVhf\ne+6Z7LNP8uMfJ8uX/8/jo3c8Ot/92HczdsbYXPqHS6sYEAAAAAAAaCsaemJyVb7eaCmAyhk5Mnn2\n2eT221d6fPYnzs7hfQ7PqLtG5Z5n76lSOAAAAAAAoK1Yn2KyaLQUQOUceWSy1VbJ6NErPa4pajL+\nyPHp27NvPnfD5/LMq89UKSAAAAAAANAWrE8x6cV00BLU1iZf+1oydWoyY8ZKQ1036Jpbj7k1NUVN\nDp90eN5Y/EZ1MgIAAAAAAK3eaovJoigWFkWxYBWfhUk2a6KMwPo68cSkc+dkzJj3DG2z0Ta54egb\n8sxrz2TITUOyfMXyVSwAAAAAAACwflZbTJZl2bUsy26r+HQty7K2qUIC66l792TYsGTixOTll98z\nvP8H98+PD/5xbn/m9nznN9+pQkAAAAAAAKC1W5+rXIGW5NRTk6VLkyuuWOXwVz7ylZy8x8m56KGL\nMmHmhCYOBwAAAAAAtHaKSWgrPvSh5LDDkssvTxYtWuWUMZ8ek49v/fGceOuJ+cPf/9DEAQEAAAAA\ngNZMMQltyRlnJHPn1peTq9ChXYfccPQN2bTrpjli0hGZvXB2EwcEAAAAAABaK8UktCUf/Why8MHJ\nBRckCxasckqPTj1y6zG3ZsGSBTli0hF56+23mjgkAAAAAADQGikmoa354Q+T115LRo9+3yk799o5\nE46akD/O/mO+NPlLKcuyCQMCAAAAAACtkWIS2po99kg+85nk3/89efXV9512xA5H5NxPnJsJMyfk\n4ocubsKAAAAAAABAa6SYhLbonHOSN99MLrxwtdPO/NiZGdx3cM749RmZ8syUJgoHAAAAAAC0RopJ\naIv69k2OOy659NJk9uz3nVYURcYdPi79NumXY288Nk/NfaoJQwIAAAAAAK2JYhLaqu9/P1m2LDnv\nvNVO69yhc351zK/SsbZjBk0alPlvzW+igAAAAAAAQGuimIS2atttk5NOSq68Mnn++dVO3WrDrXLT\n0Tflb6//LZ+74XNZtmJZE4UEAAAAAABaC8UktGXf/W5SW5ucffYap+671b654rArcs9z9+T0u09v\ngnAAAAAAAEBropiEtmyzzZIRI5Lx45On1vz+yOG7Dc9pe52WSx6+JGMfHdsEAQEAAAAAgNZCMQlt\n3RlnJJ07J2ed1aDpFx90cQ7c9sCcPPnkPPjCgxUOBwAAAAAAtBaKSWjrevRIvv715IYbkj/9aY3T\na2tq81+f/a9s3X3rHPXLo/LCGy80QUgAAAAAAKClU0wC9cXkxhvXv3OyATb6l41y6zG3ZvGyxTli\n0hH559J/VjggAAAAAADQ0ikmgaRbt+Tb307uuCN54IEG/eTDPT+c6z5zXWa8PCPDbhmWsiwrHBIA\nAAAAAGjJFJNAvVNOSTbZJPnOd5IGloyHfOiQXPipC3P9k9fnvN+dV+GAAAAAAABAS6aYBOp16pR8\n73vJ736X3H13g3/2zX2+maG7DM33fvu93PzUzRUMCAAAAAAAtGSKSeBdJ56YfPCDyZlnNvjUZFEU\n+c+6/8yem++Z424+LrNemVXZjAAAAAAAQIukmATe1aFD8oMfJI88ktzc8NOPHWs75ubP3ZxuG3TL\noEmDMm/RvMplBAAAAAAAWiTFJLCyoUOTHXaov9Z1+fIG/2yzrpvlV8f8KnMWzslnf/nZvL387QqG\nBAAAAAAAWhrFJLCydu2Sc89NnnwymThxrX665+Z75ueDfp77/nZfTrvztAoFBAAAAAAAWiLFJPBe\nRx2V7LZb/bWuS5eu1U+H7jI039rnW/np9J/mp3/8aWXyAQAAAAAALY5iEnivmprkvPOS555Lxo5d\n65+f/8nzc+iHDs2pd56a+/56XwUCAgAAAAAALY1iEli1gw9O9t23/lrXt95aq5+2q2mXiZ+ZmG03\n2jZDbx6a1xe/XqGQAAAAAABAS6GYBFatKJLzz09mz04uv3ytf95tg26ZcOSEzFk4J6fecWoFAgIA\nAAAAAC2JYhJ4f/vtlxx0UHLBBcmCBWv9849s/pGc+bEzM37m+Nz01E0VCAgAAAAAALQUiklg9c47\nL3n11eSSS9bp59/d77vZfdPd8+XJX84rb77SyOEAAAAAAICWQjEJrF7//smRRyb//u/1BeVaat+u\nfcYfOT4LlyzMlyZ/KWVZViAkAAAAAADQ3CkmgTU799xk4cLkoovW6ed9e/bN+Z88P7f++dZc/djV\njRwOAAAAAABoCRSTwJrtuGMyZEhy6aXJnDnrtMTIASPz8a0/nlPvODV/e/1vjRwQAAAAAABo7hST\nQMP84AfJ22/Xv3NyHdQUNRl3+LiUKXPCLSdkRbmicfMBAAAAAADNmmISaJjevZMvfjG58srkr39d\npyW22WibXDLwkkz969Rc+vCljZsPAAAAAABo1hSTQMN973tJTU1y9tnrvMTw3YbnsO0Py7d/8+08\nPe/pRgwHAAAAAAA0Z4pJoOE23zw55ZTkmmuSp9etVCyKIv9Z95/p3L5zjrv5uLy9/O1GDgkAAAAA\nADRHiklg7Xz720mnTslZZ63zEpt02SRXHHZFps+engseuKARwwEAAAAAAM2VYhJYOz17JqNGJddf\nnzz66Dov89m+n82QnYfk3PvPzSOzH2nEgAAAAAAAQHOkmATW3je+kWy0UfLd767XMpd++tL06twr\nx918XN56+61GCgcAAAAAADRHiklg7W24YXLGGcmUKcmDD67zMhv9y0YZe/jYPDXvqXz33vUrOQEA\nAAAAgOZNMQmsmxEjkk02Sc48MynLdV7moN4H5av9v5rR00bnvr/e14gBAQAAAACA5kQxCaybzp3r\nS8n77kt+/ev1WuqiAy9K741754RbTsiCJQsaKSAAAAAAANCcKCaBdXfSScnWWyff+c56nZrs3KFz\nrj7i6rzwxgv5+l1fb8SAAAAAAABAc6GYBNbdBhsk3/9+Mn16csst67XUPlvukzP2PSO/ePQXue3P\ntzVSQAAAAAAAoLkoyvU45dTY+vfvX06fPr3aMYC1sWxZstNOSW1t8thjSbt267zUkmVLsufP98wr\nb76Sx7/6eHp06tGIQQEAAAAAgEooiuKRsiz7r2meE5PA+qmtTc45J3niiWTSpPVaaoPaDTL+yPF5\n7a3XcvLkk9Oc/uMEAAAAAACwfhSTwPr77GeTfv2Ss85K3n57vZbapdcuOecT5+TGp27MxFkTGykg\nAAAAAABQbYpJYP3V1CQ//GHy3HPJuHHrvdzp+5yefbbcJyPuGJGXFrzUCAEBAAAAAIBqU0wCjeOQ\nQ5J99qm/1nXx4vVaql1Nu1x9xNVZunxpht8y3JWuAAAAAADQCigmgcZRFMl55yV//3vy05+u93Lb\nbbxdLj7w4tzz3D356fT1Xw8AAAAAAKguxSTQePbfPznwwOT885OFC9d7uZP7n5yBvQfm9HtOzzOv\nPrP++QAAAAAAgKpRTAKN64c/TObNS8aMWe+liqLILwb9Ih3adcgXfvWFLFuxrBECAgAAAAAA1VCx\nYrIoii2LovhtURRPFkXxRFEUp1VqL6AZ2XPP5Igjkh/9KHnttfVebvNum+eyQy7L71/6fX704I8a\nISAAAAAAAFANlTwxuSzJN8qy7JtkQJJTiqLoW8H9gObi3HPrr3L9UeMUicfudGwG9x2c70/9fh57\n+bFGWRMAAAAAAGhaFSsmy7KcU5bln97588IkTyXZvFL7Ac3ITjsln/98/XWuL7+83ssVRZHLD708\nH+j0gRx383FZsmxJI4QEAAAAAACaUpO8Y7Ioig8m2S3Jw6sY+1JRFNOLopg+d+7cpogDNIUf/CBZ\nujQ5++xGWa5Hpx75ed3PM+sfs/L9qd9vlDUBAAAAAICmU/FisiiKLkluTDKyLMsF/3e8LMsry7Ls\nX5Zl/549e1Y6DtBUttsuGTEi+dnPkkceaZQlD93+0Jy424n50UM/yoMvPNgoawIAAAAAAE2jKMuy\ncosXRfskk5PcVZblf6xpfv/+/cvp06dXLA/QxN54I+nTJ/ngB5OHHkpq1v//QixcsjC7XLFL2hXt\nMuPkGenSocv65wQAAAAAANZZURSPlGXZf03zKnZisiiKIskvkjzVkFISaIU23DC56KLk4YeTq65q\nlCW7btA1Vx9xdZ6b/1xOv/v0RlkTAAAAAACovEpe5bpvkuOSHFAUxYx3PodUcD+gOTruuGTffZMz\nzkjmz2+UJffber98fe+v54pHrshd/31Xo6wJAAAAAABUVsWKybIsHyjLsijLcpeyLPu985lSqf2A\nZqookssuS157Lfne9xpt2R8e8MP07dk3w28dntfeeq3R1gUAAAAAACqjkicmAertumtyyinJT3+a\nPPpooyzZsbZjrjnimvzjn//IiCkjGmVNAAAAAACgchSTQNM455ykR4/6gnLFikZZco/N9shZ+52V\n6x6/Lr984peNsiYAAAAAAFAZikmgaXTvnlx4YfL73yfXXNNoy/7bx/4tH9nsI/nK7V/JnIVzGm1d\nAAAAAACgcSkmgaZz/PHJ3nsn3/pW8vrrjbJkbU1trjnymix6e1FOvO3ErCgb5zQmAAAAAADQuBST\nQNOpqUkuuyx59dXkrLMabdkdeuyQiz51UaY8MyVn3HNGo60LAAAAAAA0HsUk0LR22y05+eT6gnLG\njEZbdsSeI3LKR07Jxb+/OBc/dHGjrQsAAAAAADQOxSTQ9H74w2TjjZMRI5KybJQli6LImIPHZHDf\nwTn9ntNzzWON9x5LAAAAAABg/Skmgaa30UbJhRcmDz6YjB/faMu2q2mX8UeOzwHbHJDhtwzPlGem\nNNraAAAAAADA+lFMAtVxwgnJXnsl3/pW8sYbjbbsBrUb5ObP3Zyde+2cwdcPzrSXpjXa2gAAAAAA\nwLpTTALVUVNT/57Jf/wj+f73G3Xpbht0yx1D7sgmXTbJoRMPzVNzn2rU9QEAAAAAgLWnmASqZ489\nki9/Obn00mTmzEZdepMum+TuoXentqY2AycMzEsLXmrU9QEAAAAAgLWjmASq67zz6t85ecopSVk2\n6tK9N+6dO4fcmdcXv56BEwbmtbdea9T1AQAAAACAhlNMAtW18cbJ//t/yQMPJNde2+jL77bpbvnV\nMb/Kf7/23xl03aAsentRo+8BAAAAAACsmWISqL7hw5M990xOPz1ZsKDRlz9gmwMy4cgJeejFh3LM\nDcdk2Ypljb4HAAAAAACweopJoPpqapLLLkteeSX5wQ8qssXgHQfnJ4f8JLf95bZ8+bYvp2zka2MB\nAAAAAIDVU0wCzUP//slJJyU//nEya1ZFtvjqR76a7+33vYydMTZn3ntmRfYAAAAAAABWTTEJNB/n\nn59suGEyYkRSoRONZ+9/dr60+5dywQMXZMy0MRXZAwAAAAAAeC/FJNB8fOADyQUXJPffn1x3XUW2\nKIoilx96eY7c4ciMvGtkJj0+qSL7AAAAAAAAK1NMAs3LF79Yf63rN7+ZLFhQkS3a1bTLxM9MzH5b\n75fjbz4+9zx7T0X2AQAAAAAA3qWYBJqXdu2Syy5LXn45Oeecim3TsbZjbjnmluzQY4cc9cujMn32\n9IrtBQAAAAAAKCaB5mjPPetPTl5ySfLEExXbpnvH7rlz6J3p0alHDrn2kDzz6jMV2wsAAAAAANo6\nxSTQPF1wQdKtWzJiRFKWFdtms66b5a6hd6VMmYMmHJQ5C+dUbC8AAAAAAGjLFJNA89SjR3L++cnU\nqcl//VdFt9r+A9tnyuenZO4/5+bgaw/OG4vfqOh+AAAAAADQFikmgebrpJOS3XdPvvGNZOHCim71\nkc0/kps+d1OenPtkDp90eBYvW1zR/QAAAAAAoK1RTALNV7t2yWWXJbNnJ+eeW/HtDup9UK4+4urc\n97f/j737jo6qTPw//rnTkkkPhKoiiIigVLGAoIBIURBFBCy4wFqwYNuv7v50d8W1Y90VVFgBBRFx\nERFQQbCAIgooRVRQutIEJL1NZu7vjyFDQgKEkjwzk/frnHtumTvcT0bhnOST53kW6voZ18sf8Ff6\nMwEAAAAAAAAAqC4oJgGEtwsukIYNk154Qfrxx0p/3HUtrtOLPV7UjJ9m6PYPbpddietbAgAAAAAA\nAABQnVBMAgh/Tz0lJSRII0ZIVVAU3n3B3frbhX/TuO/G6ZGFj1T68wAAAAAAAAAAqA4oJgGEv1q1\npMcekz79VPrf/6rkkU9c8oSGth6qRxY+oleWvVIlzwQAAAAAAAAAIJpRTAKIDMOHS23aSPfdJ2Vn\nV/rjLMvSuD7j1PuM3rrjwzs0/cfplf5MAAAAAAAAAACiGcUkgMjgdEpjxkjbtkmPPlolj3Q5XJrW\nf5ran9Je18+4Xp9t+qxKngsAAAAAAAAAQDSimAQQOdq3l4YMkZ5/Xlq7tkoeGeeO0+xrZ+v0Gqer\n79t9tWLHiip5LgAAAAAAAAAA0YZiEkBkefppKT5eGjFCsu0qeWQNbw3Nu2GeUmJT1GtKL23ct7FK\nngsAAAAAAAAAQDShmAQQWWrXDk7lumCB9O67VfbYk5NO1rwb5skX8Kn75O7alb2ryp4NAAAAAAAA\nAEA0oJgEEHluu01q2VK6914pJ6fKHtusVjN9cN0H2p61XZe9dZkyCzKr7NkAAAAAAAAAAEQ6ikkA\nkcflksaMkX77TXrssSp99AUnX6DpA6Zr1c5V6jiho77f9X2VPh8AAAAAAAAAgEhFMQkgMnXsKN14\no/Tcc9K6dVX66MuaXKY5183RrpxdOve/5+rfX/9bATtQpRkAAAAAAAAAAIg0FJMAIteoUZLXK911\nl2TbVfronqf31Pe3fa9LG1+qe+bdo8umXKYdWTuqNAMAAAAAAAAAAJGEYhJA5KpTR/rXv6SPP5be\ne6/KH187vrZmNPCQVwAAIABJREFUDZqlVy5/RYu2LFKLV1po5tqZVZ4DAAAAAAAAAIBIQDEJILLd\ncYfUooV0771STk6VP96yLA1vN1zf3fqdTk05VVdNu0q3zL5FOYVVnwUAAAAAAAAAgHBGMQkgsrlc\n0pgx0tat0hNPGItxZtqZWvLnJfrrhX/Va9+9pjZj22jZtmXG8gAAAAAAAAAAEG4oJgFEvk6dpBtu\nkJ59VvrxR2MxPE6Pnur2lD7906fKL8pXhwkd9Piix+UP+I1lAgAAAAAAAAAgXFBMAogOzz0nJSZK\nQ4ZIRUVGo3Ru2Fmrhq/S1c2u1t8/+7u6vNFFW9K3GM0EAAAAAAAAAIBpFJMAokPt2sEpXZctC46c\nNCzVm6qpV0/VpCsnaeXOlWr5aktNWT3FdCwAAAAAAAAAAIyhmAQQPQYMkPr1kx5+2OiUrsUsy9Lg\nVoO1avgqtajdQje8d4Oue/c6peenm44GAAAAAAAAAECVo5gEED0sS3r55bCZ0rVYo9RG+nzI53q0\ny6N654d31OrVVlq0ZZHpWAAAAAAAAAAAVCmKSQDRpU6dsJrStZjL4dLfL/q7Fg9bLI/To86vd9aD\nnzyoQn+h6WgAAAAAAAAAAFQJikkA0WfAAOnqq4NTuv7wg+k0pZx/8vlacesKDWszTE9++aQ6jO+g\ndXvWmY4FAAAAAAAAAEClo5gEEH0sKzhqMjFRGjo0bKZ0LZbgSdBrV7ymGQNmaFP6JrUd11Zjl4+V\nbdumowEAAAAAAAAAUGkoJgFEpzCd0rWkq5pdpe9v+14XnnKhhn8wXFdOu1K7c3abjgUAAAAAAAAA\nQKWgmAQQvcJ4Stdi9RPra+4Nc/VCjxc0d/1ctXy1peaun2s6FgAAAAAAAAAAJxzFJIDoZVnSyy9L\nSUnSkCFhN6VrMYfl0D0X3KNlNy9TWlyaek3ppbs+ukt5vjzT0QAAAAAAAAAAOGEoJgFEt9q1g1O6\nLl8etlO6FmtZp6WW3bxMd59/t15a+pLO/e+5WrVzlelYAAAAAAAAAACcEBSTAKLfNdeE/ZSuxWJd\nsXqx54uae/1c7c3bq/NeO0/PL3leATtgOhoAAAAAAAAAAMeFYhJA9IuQKV1L6nF6D31/2/e6rMll\n+svHf1HPN3sqsyDTdCwAAAAAAAAAAI4ZxSSA6qHklK7PPGM6TYWkxaVpxoAZGtd7nD7b/Jl6Teml\nrIIs07EAAAAAAAAAADgmFJMAqo8BA6T+/aWRI8N+StdilmXp5nNu1ttXv61vfvtGl791uXIKc0zH\nAgAAAAAAAADgqFFMAqhexoyJqCldi13d/GpN6TdFi39drN5TeyvXl2s6EgAAAAAAAAAAR4ViEkD1\nEoFTuhYbePZATbpykhZuXqi+b/dVni/PdCQAAAAAAAAAACqMYhJA9VNyStc1a0ynOSrXt7xeE/tO\n1CcbP1G/d/opvyjfdCQAAAAAAAAAACqEYhJA9VQ8pevQoRE1pask/an1n/TfPv/V3PVz1f+d/ir0\nF5qOBAAAAAAAAADAEVFMAqieInhKV0n6c9s/69XLX9UHv3yggdMHyuf3mY4EAAAAAAAAAMBhUUwC\nqL4ieEpXSbq13a0a3Wu0Zq6dqetmXKeiQGSN/AQAAAAAAAAAVC8UkwCqtwie0lWS7jjvDr3Q4wVN\n/3G6Br83mHISAAAAAAAAABC2KCYBVG+1a0svvxyxU7pK0j0X3KNR3Ubp7TVva8jMIfIH/KYjAQAA\nAAAAAABQhst0AAAw7pprgtvIkVKfPtLZZ5tOdNTuv/B++QI+PfTpQ3I73Rp/xXg5LH73BAAAAAAA\nAAAQPigmAUCSRo+WPvssOKXrkiWSK/L+eXyw04Py+X0auXCkXJZLY/uMpZwEAAAAAAAAAIQNfmIN\nAFLpKV1HjTKd5pj98+J/6u+d/q7XVrymOz+8U7Ztm44EAAAAAAAAAIAkRkwCwAElp3S94oqInNLV\nsiz9q8u/5Av49PTip+VyuPTvnv+WZVmmowEAAAAAAAAAqjmKSQAoacyYiJ/S1bIsPXnJk/L5fXr+\n6+flcrj0XPfnKCcBAAAAAAAAAEYxlSsAlFSrVlRM6WpZlp7t/qzuOu8uvfD1C/rbgr8xrSsAAAAA\nAAAAwKjIGwoEAJUtCqZ0lYLl5Is9X5Qv4NOor0bJ7XTr0S6PMnISAAAAAAAAAGAExSQAlGfMGOnz\nz6UhQ6Svv47IKV2lYDk5+rLR8vl9evyLx+V2uPVw54dNxwIAAAAAAAAAVENM5QoA5Sme0vXbbyN6\nSldJclgOje0zVkNaD9HIhSP1xBdPmI4EAAAAAAAAAKiGInMIEABUhf79pQEDIn5KVylYTr7W5zUV\nBYr00KcPye1w6/4L7zcdCwAAAAAAAABQjTBiEgAOZ/RoKSUlOKWrz2c6zXFxOpx6ve/rGnT2ID2w\n4AG9sOQF05EAAAAAAAAAANUIxSQAHE7JKV2fecZ0muPmdDg1+arJ6t+8v+77+D6NXjradCQAAAAA\nAAAAQDXBVK4AcCRRNKWrJLkcLr3V7y0VBYo04qMRcjlcGt5uuOlYAAAAAAAAAIAox4hJAKiIKJrS\nVZLcTrem9Z+m3mf01m0f3KbXvnvNdCQAAAAAAAAAQJSjmASAiig5peuoUabTnBAep0fTr5munqf3\n1C2zb9EbK98wHQkAAAAAAAAAEMUoJgGgooqndH3kEWnNGtNpTogYV4xmDJihS067REPfH6opq6eY\njgQAAAAAAAAAiFIUkwBwNKJsSldJ8rq9en/Q++rcsLNunHmjpq2ZZjoSAAAAAAAAACAKUUwCwNGo\nVUt65ZXglK5PPmk6zQkT547T7Gtnq2ODjrp+xvWMnAQAAAAAAAAAnHAUkwBwtK6+Wrr++uCUrl98\nYTrNCRPvideca+eoY4OOuuG9G3Tnh3eqoKjAdCwAAAAAAAAAQJSgmASAY/HKK9Jpp0nXXivt2WM6\nzQmTGJOo+YPn6y/t/6Ixy8ao48SO2rRvk+lYAAAAAAAAAIAoQDEJAMciMVGaNk3avTu43qRtm050\nwridbj3b/VnNHDhT6/9Yr7bj2mrWulmmYwEAAAAAAAAAIhzFJAAcq7Ztpeeekz74QHrhBdNpTri+\nZ/bVd7d8p8apjdX37b66/+P75fP7TMcCAAAAAAAAAEQoikkAOB533CFddZX0t79JS5eaTnPCNUpt\npMXDFuv2drfr2SXPqvMbnfVb5m+mYwEAAAAAAAAAIhDFJAAcD8uSxo+X6teXBg2SMjJMJzrhYlwx\nGnP5GE29eqpW71qtNmPb6OMNH5uOBQAAAAAAAACIMBSTAHC8UlOlqVOlrVulm26KqvUmSxp09iAt\nv3m56iXUU883e+qfn/1T/oDfdCwAAAAAAAAAQISgmASAE6F9e+mJJ6Tp06WxY02nqTRN05rq65u+\n1pDWQ/TookfV/c3u2pW9y3QsAAAAAAAAAEAEoJgEgBPl//5P6tFDuuceafVq02kqTZw7ThP6TtCE\nKyZoya9L1Hpsay3cvNB0LAAAAAAAAABAmKOYBIATxeGQJk2SatSQBgyQsrNNJ6pUQ9sM1Tc3faPk\nmGR1ndRVT37xpAJ2wHQsAAAAAAAAAECYopgEgBOpdm1pyhTp55+lO+80nabStajTQstuXqYBZw3Q\ng58+qD5T+2hv7l7TsQAAAAAAAAAAYYhiEgBOtC5dpH/+U3rjjeAW5RJjEvVWv7f08mUva8HGBWoz\nto2+/u1r07EAAAAAAAAAAGGGYhIAKsM//iFdfLF0++3S2rWm01Q6y7J027m36athX8nlcKnTxE56\n8esXZdu26WgAAAAAAAAAgDBBMQkAlcHpDE7pGhcnDRwo5eWZTlQlzql/jr695Vtd3uRy3TvvXvX/\nX39l5GeYjgUAAAAAAAAACAMUkwBQWU46SZo0SVq9WrrvPtNpqkyqN1XvDXxPz3V/TrPWzVLbcW21\nYscK07EAAAAAAAAAAIZRTAJAZerVS7r/funVV6X//c90mipjWZbua3+fFg5ZqEJ/odqPb6+xy8cy\ntSsAAAAAAAAAVGMUkwBQ2R5/XLrgAummm6SNG02nqVIdTumgFbeuUOeGnTX8g+Ea/N5gZRdmm44F\nAAAAAAAAADCAYhIAKpvbLU2dKjkc0qBBUmGh6URVKi0uTR9e/6Ee6/KYpq6ZqnP/e65++P0H07EA\nAAAAAAAAAFWMYhIAqkLDhtL48dKyZdL/+3+m01Q5h+XQQxc9pAWDF2hf3j6d99p5mrxqsulYAAAA\nAAAAAIAqRDEJAFWlXz/pjjuk55+X5swxncaILo26aMWtK3Ru/XN148wbdfOsm5XnyzMdCwAAAAAA\nAABQBSgmAaAqPfus1Lq19Kc/Sb/9ZjqNEfUS62nBjQv0UKeH9NqK13T+a+fr4w0fy7Zt09EAAAAA\nAAAAAJWIYhIAqlJsrDRtmlRQIF13nVRUZDqRES6HS491fUwfXveh0vPT1ePNHuo4saPmb5hPQQkA\nAAAAAAAAUYpiEgCq2hlnSGPHSl98IT3yiOk0RvVq0ku/jPhFr1z+irZmbFX3N7ur08ROWrBxAQUl\nAAAAAAAAAEQZikkAMOH666Vhw6THH5cWLDCdxqgYV4yGtxuu9SPW6+XLXtaWjC26dPKluuj1i/TJ\nxk8oKAEAAAAAAAAgSlBMAoAp//mPdOaZ0g03SLt2mU5jXIwrRrede5vWj1ivMZeN0aZ9m9Rtcjdd\n/PrF+nTTpxSUAAAAAAAAABDhKCYBwJT4eOmdd6SMDGnwYCkQMJ0oLMS4YnT7ubdr/V3r9VKvl7Rh\n3wZdMukSdX6jsz7f/LnpeAAAAAAAAACAY0QxCQAmnX12cOTk/PnS00+bThNWYl2xuvO8O7Xhrg36\nT8//6Je9v6jLG13U+fXOWrh5oel4AAAAAAAAAICjRDEJAKbddJM0aJD0j39IixebThN2Yl2xGnH+\nCG28e6P+3fPfWrd3nTq/0Vld3uiiRVsWmY4HAAAAAAAAAKggikkAMM2ypLFjpYYNpWuvlfbuNZ0o\nLMW6YnXX+Xdp410b9WKPF7V2z1pd/PrFumTSJfpiyxem4wEAAAAAAAAAjoBiEgDCQVKSNG2atHOn\nNGyYZNumE4Utr9uruy+4Wxvv2qgXerygH37/QRe9fpG6TeqmL7d+aToeAAAAAAAAAOAQKCYBIFyc\nc470zDPSrFnBdSdxWF63V/dccI823r1Rz3V/Tt///r06TeykSydfqsVbmRIXAAAAAAAAAMINxSQA\nhJO77pKuuEK6/35p+XLTaSJCnDtO97W/T5vu3qRnL31Wq3etVseJHdV9cnd99etXpuMBAAAAAAAA\nAPajmASAcGJZ0sSJUt260sCBUkaG6UQRI84dp790+Is23rVRz1z6jFbuXKkLJ1yoHm/20JJfl5iO\nBwAAAAAAAADVHsUkAISbGjWkt9+WtmyRbrmF9SaPUrwnXv/X4f+06e5NGtVtlL7b8Z06TOignm/2\n1Ne/fW06HgAAAAAAAABUWxSTABCOOnSQHntMeucd6b//NZ0mIsV74nX/hfdr092b9HS3p/Xtjm/V\nfnx79ZnaR2v3rDUdDwAAAAAAAACqHcsOo5E47dq1s5ezphoABAUCUq9e0qJF0tKlUosWphNFtOzC\nbL30zUt6avFTyinM0fB2w/XwxQ+rVnwt09EAAAAAAAAAIKJZlvWtbdvtjnQfIyYBIFw5HNKkSVJK\nijRggJSVZTpRREvwJOj/dfp/Wj9ivW4951a9uvxVnf7S6Rq1eJTyi/JNxwMAAAAAAACAqEcxCQDh\nrE4d6a23pF9+ka69VvL7TSeKeLXia2nM5WP0/W3fq1ODTvrrgr+q2ZhmmrZmmsJpFgEAAAAAAAAA\niDYUkwAQ7rp0kV56SfrgA+mBB0yniRrNajXTnOvmaP7g+UqKSdKgdwepw4QOWvLrEtPRAAAAAAAA\nACAqUUwCQCS47TZpxAjp+eel114znSaqdDutm7675TuNv2K8tqRvUYcJHTRw+kBt2rfJdDQAAAAA\nAAAAiCoUkwAQKZ5/XurRI1hSfv656TRRxelwalibYfp5xM/650X/1Ox1s3XmmDP1wPwHlJ6fbjoe\nAAAAAAAAAEQFikkAiBQulzRtmtSkiXT11dL69aYTRZ0ET4Ie6fKIfhnxi65rcZ2e/epZnf6f0zVm\n6Rj5/D7T8QAAAAAAAAAgolFMAkAkSU6WZs+WLEvq3Vvat890oqh0UtJJmth3or695Vu1rNNSd350\np1q80kJzfp4j27ZNxwMAAAAAAACAiEQxCQCRpnFj6b33pI0bpQEDJB8j+SpLm3pt9MmNn2jWoFmy\nZavP1D7qNrmbVu5caToaAAAAAAAAAEQcikkAiESdOknjxkkLFkh33y0xiq/SWJalPk37aM1ta/RS\nr5e0aucqtR3bVsPeH6btWdtNxwMAAAAAAACAiEExCQCRasgQ6YEHpFdekUaPNp0m6rmdbt153p1a\nf9d6/aX9XzTl+ylq8lITPfL5I8opzDEdDwAAAAAAAADCHsUkAESyJ5+U+vaV7rlHmjvXdJpqISU2\nRc90f0Zr71ir3mf01siFI3XG6DM0ccVE+QN+0/EAAAAAAAAAIGxRTAJAJHM4pDfflFq0kAYOlH78\n0XSiaqNRaiNN6z9Ni4ctVoPkBho2a5jOGXeOPtn4ieloAAAAAAAAABCWKCYBINIlJEizZ0txcVLv\n3tLu3aYTVSsdTumgr4Z9pbevflvp+enqNrmb+kzto7V71pqOBgAAAAAAAABhhWISAKLBKadI778v\n7dgh9esnFRSYTlStWJalgWcP1No71+rpbk9r0ZZFOvvls3X7B7frp90/mY4HAAAAAAAAAGGBYhIA\nosV550mvvy59+aV0662SbZtOVO3EumL1wIUPaP2I9Rrebrj++91/1fzl5mo/vr3GfTtOGfkZpiMC\nAAAAAAAAgDEUkwAQTQYOlEaOlN54Qxo1ynSaaqtWfC2Nvmy0tt23Tc91f05ZBVm6dc6tqvdcPQ1+\nb7A+2/SZAnbAdEwAAAAAAAAAqFKWHUYjatq1a2cvX77cdAwAiGy2LV17rfTOO9KMGdKVV5pOVO3Z\ntq3l25dr4sqJeuv7t5RRkKGGKQ01pNUQDWk9RKemnGo6IgAAAAAAAAAcM8uyvrVtu90R76OYBIAo\nlJcnde4srVkTnNq1TRvTibBfni9PM9fO1ISVE/TJxk8kSV0bddXQ1kPVr1k/ed1ewwkBAAAAAAAA\n4OhQTAJAdbdjR3DdSUlaulSqV89sHpSxNWOr3lj5hiaunKhN6ZuUHJOsQWcP0tDWQ3XeSefJsizT\nEQEAAAAAAADgiCgmAQDSypVSx45S8+bSwoWSl9F44ShgB7RoyyJNXDlR//vhf8orylPzWs01tPVQ\nDW45WHUS6piOCAAAAAAAAACHRDEJAAh6/33pqquka66Rpk6VHA7TiXAYmQWZeueHdzRhxQQt+W2J\nnJZTl59xuYa2HqrLm1wut9NtOiIAAAAAAAAAlEIxCQA4YNQo6a9/lR5+WBo50nQaVNDaPWv1+srX\n9caqN7Qze6dqxdXS4JaDNbTNUJ1d+2zT8QAAAAAAAABAEsUkAKAk25b+/Gdp4sTgqMlBg0wnwlEo\nChRp3vp5mrBygmavmy1fwKdz65+roa2H6toW1yolNsV0RAAAAAAAAADVGMUkAKC0wkKpWzdp6dLg\nepPnn286EY7Bntw9mrJ6iiasnKDVu1Yrxhmjfs36aWjroeraqKucDqfpiAAAAAAAAACqGYpJAEBZ\ne/YEC8mcnGBB2aCB6UQ4RrZta8XOFZq4YqKmfD9F+/L3qV5CPfVr1k/XNL9GHRt0pKQEAAAAAAAA\nUCUoJgEA5fvxR6l9e6lRI+nLL6WEBNOJcJzyi/I1a90sTfthmj785UPlF+Wrdnxt9Tuzn6456xpd\ndOpFcjlcpmMCAAAAAAAAiFIUkwCAQ5s3T7rsMql3b2nGDMnJyLpokV2YrY9++UjTf5quOT/PUa4v\nV2lxabrqzKvUv3l/dWnYRW6n23RMAAAAAAAAAFGEYhIAcHijR0sjRkj33y+NGmU6DSpBri9Xc9fP\n1fQfp2v2z7OVXZitGt4aurLplerfvL8uOe0SeZwe0zEBAAAAAAAARDiKSQDA4dm2dMcd0iuvSBMm\nSEOHmk6ESpRflK956+dp+k/TNWvdLGUWZColNkV9m/ZV/+b9delplyrGFWM6JgAAAAAAAIAIRDEJ\nADgyny84pevChdL8+dLFF5tOhCpQUFSg+Rvna/qP0/X+uveVnp+upJgkXdH0CvVv1l/dG3eX1+01\nHRMAAAAAAABAhKCYBABUTHq6dMEF0u7d0tKlUuPGphOhChX6C/Xppk/1vx/+p5nrZuqPvD+U4ElQ\n7zN6q3+z/urVpJfi3HGmYwIAAAAAAAAIYxSTAICKW79eOv98qXZtackSKSXFdCIY4PP79PnmzzX9\nx+masXaG9uTuUZw7Tpc3uVz9m/fX5U0uV7wn3nRMAAAAAAAAAGGGYhIAcHQ+/1y69FKpa1fpgw8k\nl8t0IhhUFCjSoi2LgiXlTzO0K2eXvC6vejXppf7N+qv3Gb2VGJNoOiYAAAAAAACAMEAxCQA4euPH\nSzfdJN18szR2rGRZphMhDPgDfn259UtN/3G63v3pXe3I3qEYZ4yuaHqFBrccrJ6n95Tb6TYdEwAA\nAAAAAIAhFJMAgGPz0EPSE09Id98tvfAC5SRKCdgBLfl1id5e87be/uFt7cndo7S4NA06a5AGtxqs\nc+ufK4v/ZwAAAAAAAIBqhWISAHBsbFu6917p3/+WHnxQevxx04kQpnx+n+aun6vJqydr1rpZKvAX\nqGnNphrccrCub3m9GqY0NB0RAAAAAAAAQBWgmAQAHDvbloYPl8aNkx57LDiKEjiM9Px0Tf9xuiav\nnqxFWxZJki469SINbjlY/Zv3V0psiuGEAAAAAAAAACoLxSQA4PgEAtKQIdLkydJzz0n33Wc6ESLE\n5vTNmrJ6iiavnqx1e9cpxhmjPk37hNaj9Dg9piMCAAAAAAAAOIEoJgEAx6+oSLr2Wmn6dOnll6Xb\nbjOdCBHEtm0t375ck1dP1ttr3tbu3N2q6a2pQWcP0uCWg3XeSeexHiUAAAAAAAAQBSgmAQAnRmGh\ndPXV0pw50uuvS3/6k+lEiEA+v0/zNszTm6vf1Pvr3ld+Ub7OqHmGbmhxg25oeYMapTYyHREAAAAA\nAADAMaKYBACcOPn5Up8+0qefSm+9JQ0caDoRIlhGfkZoPcqFWxZKkjo26KjBLQfrmubXKNWbajgh\nAAAAAAAAgKNBMQkAOLFycqRevaQlS4JTu/btazoRosCW9C2a8n1wPcq1e9bK4/SozxnB9Sh7NenF\nepQAAAAAAABABKCYBACceJmZ0qWXSitXSrNmST16mE6EKGHbtr7d8a0mr5qsqWumhtajHHjWQA1u\nNVjnn3Q+61ECAAAAAABEEdu2VRQoUn5Rfpmt0F8ol8Mlj9Mjj9Mjt9MdOvY4PXI73HI73XJYDtNf\nBvajmAQAVI59+6SuXaW1a6WPPpI6dzadCFHG5/dp/sb5mrx6smaunan8onylxaWpVZ1Wal23dWh/\nZtqZcjvdpuMCAAAAAABEnYAdUHp+unbn7Nbu3N3anbNbWYVZ5ZaIJbcCf8ER7ym5BezAceV0OVxy\nOw4qLcspMY/0WtOaTfWXDn85QZ9e9UQxCQCoPLt3SxdfLG3dKs2fL7VvbzoRolRmQaZm/DRDX279\nUit3rtSa39eowF8gSfI4PTqr1llqVbdVqdKSNSoBAAAAAABK8/l92pu3t1TRuDt3t/bk7jlwrcT1\nvbl75bf9R/xzXQ6XYl2xFd+cFbvP7XTLH/Cr0F8Y2nwBX+lzv+/Qrx3m3oNf9/l9ale/nWZdO6sK\n/ktEL4pJAEDl2rFDuuiiYEn56adS27amE6EaKAoUad2edVq1a5VW7lwZ2v+e83vongbJDdSqTomy\nsm4rnZZ6GlN7AAAAAACAiGDbtvy2XwE7IH/AL7/tL7UP2AH57WBptzd3b4WKxvT89EM+r4a3hmrF\n1VJaXJpqxddSrbj9W/z+a/uPk2KS5HV5Q+VhjCtGLoerCj8ZhDOKSQBA5du6VerUScrJkT7/XDr7\nbNOJUE3tzN6pVTsPlJWrdq3S2j1rQ9OBJHgS1LJOy1IjK1vUaaE4d5zh5AAAAAAAINJk5Gdoa8ZW\nbc3Yql8zfw0db83YqsyCzDJF4sGF4sGvHVxA2jr23sblcJUqE0PH+88PLiBrxtWkXMQJQTEJAKga\nGzYEy8lAQFq0SDrjDNOJAElSni9PP+z+IVhW7lwVKiwzCzIlSQ7LoSY1moSKylZ1g6VlvYR6sizL\ncHoAAAAAAGCCz+/T9qztpcrGrRlbtTWzdPlYksvh0slJJ6tBcgOlxKbIaTnldDhL7R2Wo9zrTseh\nX3NYjsPe73a6VdNbs1QBmRKbws81YATFJACg6vz0U3DNyZiYYDnZqJHpREC5bNvW5vTNpaaBXbVr\nlTanbw7dUzu+tro26qoejXuoR+MeqpdYz1xgAAAAAAAMCNgB+fw+FQWK5Av45PP7Su2LAkVlrh3q\n/vKuOR3Oo1uXsHjdQYf7uEo327aVnp9+2NJxe9b20AxMxWp6a6pBcoMy2ylJp6hBcgPVTagrp8N5\nvB87ENEoJgEAVWvVKqlLFyklJVhOnnyy6URAhaXnp2v1rtVatXOVlm5fqvkb5mtXzi5JUss6LUMl\nZccGHRXjijGcFgAAAACAYHmYXZit7MJsZRVkBfeFWWXOy7xWzj05hTmlysODi7lwYck66jLTkqXt\n2QdGQGYXZpf6Mz1OT6hgPFT5GO+JN/QVA5GDYhIAUPWWLZMuuUSqVy9YTtapYzoRcEwCdkCrd63W\nvPXzNHfDXC3euli+gE9x7jh1adglWFSe3kNNajRhehQAAAAAiGC2bSu/KF/p+enKKMgI7vMzQucl\nj7MKs0KT9yo9AAAgAElEQVTvsxT8XrDk94Sha4d7zSp9T3nXis8LigoOWybm+nIr/HV6XV4leBKU\nGJMY3HsSS53Hu+PlcXrkdrjldrpDe5fDVeaa27H/+kHXjub+gB1QflF+lWxFgSKdlHTSIcvH2vG1\n5bAcFf4sAZSPYhIAYMaXX0o9ekinnSZ9/rlUs6bpRMBxyy7M1mebPtO8DfM0b8M8rf9jvSSpUUqj\nUEnZtVFXJcUkGU4KAAAAANVLUaBIGfkZZUrEcgvGgvRy7/EFfId9htNyKjk2WQmeBDksh4p/pm7r\nwM/WD75W8ufuB1+ryPts2YpxxpRfJLoPXTCWdx7viZfL4Tr2DxkAKoBiEgBgziefSJdfLp11VvA4\nJcV0IuCE2vDHhlBJ+emmT5VdmC2Xw6X2J7dXz9N7qkfjHmpTrw2/cQkAAADAKNu2lVeUJ0mKccaE\n3Rp4tm0r15d7yDKx3PODruf4co74nARPgpJjkpUSm6Lk2P37mORyrxWflzyOd8czWw4AHAHFJADA\nrA8/lK68UmrXTvr4YykhwXQioFIU+gv11a9fad76YFG5YucKSVKtuFq6tPGl6tG4h7o37q66CXUN\nJwUAAAAQ7gr9hWXWAyw5fWd5U3pm+8quL1jy9ZKj85yWUzGuGHmcHsU4YxTjiqnY/ijudTqcyizI\nVHp++oEC8RAjFTMKMlQUKDrsZ+J2uMsvD2OSQ9cOPi9ZKibFJDFaEACqAMUkAMC8d9+VBg6UOnUK\nFpVer+lEQKXblb1L8zfO19z1c/Xxho+1O3e3JKl13dbBaV8b99CFDS6Ux+kxnBQAAABARdi2rUJ/\nofKK8pTnyzumfa4vt8z18krGI00pWsySpQRPQqkpO0tN4+k5cC3BkyDLslRQVKACf0HZfXnXjrA/\nUplYUqIn8ZDF4qFGK5Y8j3XFMloRACIAxSQAIDxMmSINHhxcd3LmTCkmxnQioMoE7IBW7lwZGk25\n+NfFKgoUKcGToC4Nu6hH4x46p/45SotLU1pcmpJjkvmGGwAAADgG/oBfOb6c0GjBnMISxxW57ssJ\nloclisPiMjG/KF8BO3BMuZyWU163V16Xt8w+MSax3CLx4LUCy7vmdXuNLh0RsAOHLC39AX9oKtSk\nmKSwmz4WAFA5KCYBAOFj/HjpppuCU7u+847kdptOBBiRWZCpzzZ9pnkb5mnu+rnalL6p1OtOy6ma\ncTVDRWVN74Hjcs/jalJmAgAAoMrZtq2iQJF8AZ98fp98AV/wfP/xidoXFBUox5cTLBN9ZYvFkuVi\nflF+hfNbshTviQ+VfvHueMV74hXvji9bIpZTKB68j3PHHfI1t5PvfwEA1QPFJAAgvLz0knTXXdKg\nQdKbb0pOfmMS1Ztt29qwb4N+2fuL9uTu0Z7cPdqbtzd0fPC1Q02V5HK4QoVlqNT0ppU+37/Vjq+t\nBskNjP5mNQAAAMzzB/zKKMjQvrx92pe/T3/k/RE63pe3/zy/nPO8fcoryjuqaTyPR8kCMd5dokg8\nqFQs9/hQ93ji5XV5+eU+AABOsIoWk6z6CwCoGiNGSHl50l//KsXGBkdROihHUH1ZlqXTa5yu02uc\nfsR7bdtWZkFmueXl3tz953nB87V71oau+W1/mT8r0ZOoVnVbqU3dNmpTt43a1mur5rWa85vcAAAA\nEaR4zcPswmxlFmSGSsPyisRQ8VjiPCM/Q7YOPVjB6/Iq1Zuq1NhU1fDW0Kkpp6p1bGulxqbK6/bK\n7XDL7XQf9d7lcB3Ve1wOFwUiAABRhmISAFB1HnhAys2VHnlEiouTRo+W+CYTOCLLsoJrtMQmq7Ea\nV+g9tm0royCjVHm5PWu7Vu1apRU7V2jCignK8eVIkjxOj86ufXaorGxTr41a1WmleE98ZX5ZAAAA\n1UKhv/CQ6xoebs3Dw62NmF2YXe4voZXkcXqUGpsaKhjrJdRT81rNQ2VjyddqeGuEjlO9qYp1xVbR\npwMAAKobikkAQNV6+OFgOfnMM5LXG9xTTgInnGVZSolNUUpsSrmjMv0Bv9b/sV4rdq7Qdzu+04qd\nKzRz7UyNXzE++H5ZaprWtFRZ2aZuG9WMq1nVXwoAAIgSPr+v1OwPeb48FfoLD7v5Ar4j3lOR+0tO\nPWop+P1H8Ui8ipwfzb2SlF+UHyoQfQFfhT8jl8OlRE9iqWlIEzwJqpdQr9xpSYu3VG/ZsjHOHcdo\nQwAAEHZYYxIAUPVsOzi165gx0j/+If3rX6YTAVBwlOVvmb9pxc4VWrFjhb7b+Z1W7FihXzN/Dd1z\nStIpalOvjdrWbRsqK09OOpkfegEAUM2UnGp+d+7uUNm4O2d32Wv7j9Pz04/pWU7LKbfTLY/Tc8TN\n7Sj/PqfllGVZKv45WPE0pmXOD7p+2HsPc+51ecsUiIda87Dkax6n55g+IwAAANNYYxIAEL4sS/rP\nf6T8fOnRR6WCAumppxg5CRhmWZZOST5FpySfoiuaXhG6vid3j1buXKkVO1aERljOXjc79EO4mt6a\noZKybb22alO3jZrUbCKHxTqyAABUVMAOaHfObm3L2qZtmdu0PWu7dmTvkD/gl8vhKncrXrOvzHVH\n+dcP9x6XwyV/wF+mTAyVjXkHSsfi7VAjAT1Oj2rF1VJaXJrS4tLUrn47pXmDx7Xig9dremuGirjD\nlY5uh1tOh7OK/2sAAACgsjBiEgBgjt8fHDn5yivSTTdJr74qOfmhAxAJsguztXrX6lJl5Zrf14R+\nQBnvjlezWs3UMKWhGiY3DO5LbKxfCQCoTrIKsrQtK1g2bsvcduD4oBKy5HSj0oEpRAN2wFDyoBre\nGqWKxlLH8WWvJ3gSmE0BAACgmqnoiEmKSQCAWbYdXHfy0Uelfv2kt96SYmJMpwJwDAr9hfpx94+h\nsvLnvT9rU/ombUnfogJ/Qal7a8XVKlNWNkxpqEYpjXRqyqmKc8cZ+ioAAKg4n9+nndk7SxWM27K2\nlSoht2dtV1ZhVpn3JsUk6aTEk3RS0kmqn1g/eJy4/zgpeFwnoY5cDpcCdkD+gF9FgaLQ5gv4Sp2X\nes1f/mtHeo/T4QyVjMVFY6o3VS4HE24BAADg8CgmAQCR5cUXpXvvlS65RHrvPSkx0XQiACdIwA5o\nV/YubU7fXHrL2KxN+zZpS8YWFfoLS72ndnztA4Xl/hGXjVIbqWFKQ52afKq8bq+hrwYAUNUK/YXK\nLsxWVkGWsgqzlFWQFTwvcVwUKJLf9itgB8ps/kDZ6xW+V2Wv5fhyQqXj7zm/h6Y2L+Z2uFU/sX6p\ngjFUPO4vIesn1leCJ8HQJwoAAACceBSTAIDIM2mSNGyY1Lat9OGHUlqa6UQAqkDADmhn9s6yxWX6\n5tCIy4PXsKoTX6fUSMtTk09V/cT6qptQV/US66lOfB3FuBh9XVG5vlz9svcXrdu7Tg7LoXPrn6sG\nyQ2Yhg/AUQvYARUUFSjXlxsqDrMKsw5bLIZeP8T9B//yyrFyWI4ym9Nylr3mKHut5L2xrtgyRWPJ\n47S4NNZZBgAAQLVDMQkAiEyzZkkDBkinnSZ9/LF08smmEwEwLGAHtCNrxyFHXG7N2FqmuJSk1NhU\n1U2oe8StuvwAOWAH9Fvmb1q3Z53W7V13YL93nbZmbC1zf534OjrvpPNCW7v67VTDW8NAcgDHKmAH\nlF2YrYz8DGUUZCjXl6v8ovxytzxfXvmv+Q/zWlG+8opKv3Y0JaLL4VKiJ1GJMYlK8CSEjhM9hzgv\n5zgxJlHx7nh5nJ4jFosAAAAAKg/FJAAgci1cKF1xhZSSEiwnmzY1nQhAGPMH/NqZvbPMtiN7R5nz\nXF9umfc7LafqJNQ5UFbGH7rETPAkhP0owqyCrDLF47o96/Tz3p+VV5QXui/Rk6imaU11Rs0z1LRm\n0+CW1lQ+v0/Lti/T0m1LtXTbUv2056fQe5rUaFKqrGxdt7ViXbEmvkygWsgvyldGfobS89OVUZBR\n6jg9P730a+VcyyzIVMAOHPVzPU6PYl2xpTavy1vmWqwrVl63V7HOcq65YksVi+WVjx6nJ+z/TQUA\nAABQMRSTAIDItmKF1KNH8Hju3OD0rgBwnLILs8stMQ8uM3dl75Lf9pd5f5w7LjTKMjkmWcmxycF9\nTLKSYpIOnMeWf+1ElXj+gF+b0zeXW0DuyN4Rus9hOdQopZGapjUtVT42rdlUdRPqVqgQyMjP0Lc7\nvg0Vld9s+0bbs7ZLCo52alWnVamy8sy0MxmZhLBk27ZyfDlKz08vs+3L2xcq8w4u8iwd+HtS8u9M\nyevH+lqhv/CQpWJGfoYK/AWH/ZosWaF/Y1JiU5Qcu38fU/ZaUkyS4t3x5RaIB2/8HQYAAABwtCgm\nAQCR7+efpUsvlfbtk2bPli6+2HQiANVEwA5ob+7eQ5aXe/P2KiM/OBqpuEDI8eUc8c/1OD3BsrJk\nqRmbfOBaOaWm1+XVpvRNpQrI9X+sLzVdYg1vjVKlY/Fx49TGlbLW5rbMbaGicun2pVq2bZmyCrMk\nBUditqvfrlRZeVLiSYyKOgFyCnMOOSK4uFDzB/zBve2v1PNYV6ziPfGKc8eV2uLd8Yc9j3PHHfF9\nbqe73K//cMViRbfyfuGgJK/LK5fDdeCZOvD9csnvnUteP57XXA7XgSKxRKl4yGsHlZAJngRKRAAA\nAABhwXgxaVnWBEm9Jf1u2/bZFXkPxSQAoIzffguOnNywQXrnneAUrwAQhooCRcosyAyWlfvXczu4\nvAxdKyz/nsNNu+h2uNW4RuMyIx+bpjVVWlxaFX+1pQXsgNbtWVeqrFy1c1Vo7c96CfVCJeX5J52v\ndvXbKTk2+aieYdu28ovylevLVV5RnvJ8ecorygueH+E4zxc8tyxLSTFJoSK4+Dh0LfbANY/TUxkf\nVRlFgSL9nvN72QI8a4d25pS+ll2YXeb9DsuhOvF1lBKbElpXz2k5S62zd8LO9+8ty1JBUYFyi3KV\n6wtuOYU5oeNcX65yfDmh9QyPlsvhKlVUSqpwsRjnjlNKbErZLebAcao3tdx7kmOSD1mKAgAAAAAO\nLxyKyYskZUuaRDEJADgue/dKl10mffutNGGCdOONphMBQKWwbVvZhdmhkjIjP0O5vlw1SG6gRqmN\nSo3kCnf5RflatXNVqKhcum2pft77c+j1M9POVJu6beR0OEPF4eEKx2MpuIrFuePkdXkVsAPKLMg8\nYrklSTHOmFJFZXllZpnzEvfHu+P1R94fZUfd5uwvHfef78ndU2YUnSSlxKaUXuP0oLVP6yXWU92E\nuqrprSmnw3nMn01lC9iB0H/f4rKyVIF5iEKz5BawA0qNLb9MLFUsxiZXWaEMAAAAACjNeDG5P0RD\nSXMoJgEAxy07W7rySumTT6Tnn5fuvdd0IgDAUdqXt0/Lty8vNarSYTnkdXvldXmDBWLJY5f30K9V\n8DjGGVNqGtnikZclR6mWHOla6vyg10tey8jPqFDBWZLH6TlQLCbUK108ltjqxNeR1+090R8/AAAA\nAACVJmKKScuybpF0iyQ1aNDgnC1btlRaHgBAhCsokK6/Xnr3Xemhh6RHH5VYswwAYEBxwVlueZmf\noezCbNXw1ihVOKbEprDWJgAAAAAgKlW0mDQ+F5Rt2+MkjZOCIyYNxwEAhLOYGGnaNGn4cOnxx4NT\nvI4eLTnDdwo7AEB0siwrODrT7VXdhLqm4wAAAAAAEBGMF5MAABwVp1MaN06qWVN6+mlp3z5p0iTJ\nw5pSAAAAAAAAABDOKCYBAJHHsqSnngqWkw88ECwnZ8yQ4uNNJwMAAAAAAAAAHIKjsv5gy7KmSloi\nqallWb9ZlvXnynoWAKCauv9+afx4acECqVs36Y8/TCcCAAAAAAAAABxCpY2YtG372sr6swEACBk2\nTEpNlQYNki6+WJo3T6pf33QqAAAAAAAAAMBBKm3EJAAAVeaqq6SPPpI2b5Y6dpTWrzedCAAAAAAA\nAABwEIpJAEB06NpV+vRTKTMzWE6uWmU6EQAAAAAAAACgBIpJAED0OPdc6YsvJLc7OK3rl1+aTgQA\nAAAAAAAA2I9iEgAQXZo1kxYvlurUkbp3lz780HQiAAAAAAAAAIAoJgEA0ahBg+BoyWbNpL59pSlT\nTCcCAAAAAAAAgGqPYhIAEJ1q1ZI++yy43uQNN0ijR5tOBAAAAAAAAADVGsUkACB6JSVJH30UHDU5\nYoT0yCOSbZtOBQAAAAAAAADVEsUkACC6xcZK06dLQ4ZII0dKw4dLhYWmUwEAAAAAAABAteMyHQAA\ngErncknjx0t160pPPSWtWRMsK+vVM50MAAAAAAAAAKoNRkwCAKoHh0N68klp2jRp5UrpnHOkJUtM\npwIAAAAAAACAaoNiEgBQvQwYIH39teT1ShdfLI0dazoRAAAAAAAAAFQLFJMAgOqnRQtp+XLpkkuC\na07efLNUUGA6FQAAAAAAAABENYpJAED1lJoqzZkjPfig9NprwdGT27aZTgUAAAAAAAAAUYtiEgBQ\nfTmd0uOPS+++K/3wQ3DdyS++MJ0KAAAAAAAAAKISxSQAAP36Sd98IyUlSV27SmPGSLZtOhUAAAAA\nAAAARBWKSQAAJKl5c2nZMqlnT+nOO6Vhw6T8fNOpAAAAAAAAACBqUEwCAFAsOVl6/33p4Yel11+X\nOnWStm41nQoAAAAAAAAAogLFJAAAJTkc0siRwYLy55+D605+/rnpVAAAAAAAAAAQ8SgmAQAozxVX\nSEuXSmlpUrdu0osvsu4kAAAAAAAAABwHikkAAA6laVPpm2+kPn2ke++VBg+WcnNNpwIAAAAAAACA\niEQxCQDA4SQlSe++Kz32mPTWW9KFF0qbN5tOBQAAAAAAAAARh2ISAIAjcTikhx6S5syRNm0Krju5\nYIHpVAAAAAAAAAAQUSgmAQCoqMsuk5Yvl+rXl3r0kJ55hnUnAQAAAAAAAKCCKCYBADgap58uLVki\nXX219MAD0qBBUk6O6VQAAAAAAAAAEPYoJgEAOFoJCdK0adLTT0vTp0vt20sbNphOBQAAAAAAAABh\njWISAIBjYVnBEZMffST99pvUrp00d67pVAAAAAAAAAAQtigmAQA4Ht27B9edPPXU4BqUTz7JupMA\nAAAAAAAAUA6KSQAAjtdpp0lffRVcb/LBB6VrrpGyskynAgAAAAAAAICwQjEJAMCJEBcnTZkiPf+8\nNHOmdMEF0i+/mE4FAAAAAAAAAGGDYhIAgBPFsqR775U+/lj6/ffgupNvv206FQAAAAAAAACEBYpJ\nAABOtK5dg+tOnnWWdO210p/+JGVmmk4FAAAAAAAAAEZRTAIAUBlOPVVatEgaOVJ6802pdWtpyRLT\nqQAAAAAAAADAGIpJAAAqi8slPfyw9MUXwfNOnaRHHpGKiszmAgAAAAAAAAADKCYBAKhsHTpIK1dK\n110XHEF50UXSpk2mUwEAAAAAAABAlaKYBACgKiQlSZMmSW+9Jf34o9SqVXCKV9s2nQwAAOD/t3fn\nYZJV9f3432dWhk1WRRZZRTZZzIAoi4DGhaiIGjdiFmI0foNb4oLRREw0P9SYqImJu4lxiVERUVxw\nAUSD7DuMwCD7IoQdxhmYub8/brXdM1NV3TNTp2u65/V6nvvUrVvV9T6nuvp03fupcwsAAGBSKEwC\nwGR65SuTSy5pv3Py1a9OjjkmuffeYbcKAAAAAKA6hUkAmGzbb5+cfnry/vcnX/taO3ty5HsoAQAA\nAACmKYVJABiGmTOTv/7r5Oc/T+bMSQ47LHn3u5NHHhl2ywAAAAAAqlCYBIBhOuCA5KKLkj/+43YG\n5UEHJddeO+xWAQAAAAAMnMIkAAzbhhsmn/1se1rXa69tv3/y859PmmbYLQMAAAAAGBiFSQBYW7z0\npcmll7azKI89NnnZy5K77x52qwAAAAAABkJhEgDWJttum/zoR8kHP5h861vJ3nsnp58+7FYBAAAA\nAKwxhUkAWNvMmJG87W3JL37Rnub1mc9M3vGOZMmSYbcMAAAAAGC1KUwCwNrqKU9JLrwwee1r2xmU\nT3tasmDBsFsFAAAAALBaFCYBYG22/vrJJz6RnHxycsMNbbHyU59KmmbYLQMAAAAAWCUKkwAwFRx1\nVHLZZckhhySve11y9NHJXXcNu1UAAAAAABOmMAkAU8XjH59873vJP/9ze/nkJyennTbsVgEAAAAA\nTIjCJABMJTNmJG9+c3LeeclmmyXPeU7yl3+Z/OY3w24ZAAAAAEBfCpMAMBXtvXdy/vnJcce1Myif\n+tT2VK8AAAAAAGsphUkAmKrmzUv+5V+SU09Nbr892W+/5K1vTR54YNgtAwAAAABYicIkAEx1Rx6Z\nXHllcuyxyT/9U7LbbslXv5o0zbBbBgAAAADwWwqTADAdbL558qlPJWefnWy1VfKKVyS/+7vJggXD\nbhkAAAAAQBKFSQCYXp761OTcc5N/+7fkggva76I8/vjkoYeG3TIAAAAAYB2nMAkA083MmcnrX59c\nfXXyB3+QfOADye67J9/4htO7AgAAAABDozAJANPVllsmn/tc8rOfJZttlrz0pclzn5tcc82wWwYA\nAAAArIMUJgFgujvooOT885OPfSz5xS+SvfZK3v3u5OGHh90yAAAAAGAdojAJAOuCWbOSN7wh+eUv\nk5e/PHn/+5M99ki+9S2ndwUAAAAAJoXCJACsS7baKvnCF5Izz0w23DB50YuS5z8/Wbhw2C0DAAAA\nAKY5hUkAWBcdemhy0UXJP/1T8tOfJnvumZxwQrJo0bBbBgAAAABMUwqTALCumj07ectb2tO7vvjF\nyXvf237/5KmnDrtlAAAAAMA0pDAJAOu6rbdOvvzl5Mc/TubMaU/t+qIXJddfP+yWAQAAAADTiMIk\nANA64ojkkkuSD3wg+eEPk913T973vmTx4mG3DAAAAACYBhQmAYBRc+Ykb397smBBO3Pyb/6mPb3r\nD34w7JYBAAAAAFOcwiQAsLLttku+9rW2IFlK8tznJi95SXLjjcNuGQAAAAAwRSlMAgC9PfvZyWWX\nJe9/f/K977Wndz3xxGTJkmG3DAAAAACYYhQmAYD+5s5N/vqvkyuvbAuV73xnsvfeycknJ00z7NYB\nAAAAAFOEwiQAMDE77JB885vJqae2Bcmjj06e/vTkzDOH3TIAAAAAYApQmAQAVs2RRyZXXJF8+tPJ\nTTclhx2WPO95yUUXDbtlAAAAAMBaTGESAFh1s2Ylr3lNcs01yYc+lJxzTvKUpySvfGVy7bXDbh0A\nAAAAsBZSmAQAVt+8eclb35pcd13yrnclp5yS7L578vrXJ7feOuzWAQAAAABrEYVJAGDNbbJJ8r73\nJQsXJq97XfKZzyS77JK8853JPfcMu3UAAAAAwFpAYRIAGJyttkr+9V+TBQuSo49OTjwx2Wmn5AMf\nSB5+eNitAwAAAACGSGESABi8nXdOvvSl5KKLkqc/PTn++OSJT0w+9ankkUeG3ToAAAAAYAgUJgGA\nevbdNzn11OTMM5MddmhP87rHHslXv5osWzbs1gEAAAAAk0hhEgCo79BDk5/9LDnllGS99ZJXvCLZ\nf//ktNOSphl26wAAAACASaAwCQBMjlKSF7wgufji5AtfSO6+O3nOc5JnPjM555xhtw4AAAAAqExh\nEgCYXDNnJq9+dbJgQfKxjyWXX54ceGDy4hcnV1017NYBAAAAAJUoTAIAwzF3bvKGNyQLFyZ/93fJ\nj36U7LVXcuyxyY03Drt1AAAAAMCAKUwCAMO10UbJ3/xNct11yZvfnHzpS8kTn5j85V8md9017NYB\nAAAAAAOiMAkArB222CL58IeTa65Jjjkm+ehHk512amdTPvDAsFsHAAAAAKwhhUkAYO3yhCckn/tc\nctllybOelbznPcn22yfvfndyxx3Dbh0AAAAAsJoUJgGAtdMeeyQnnZScc05y2GHJP/xDW6B83euS\nq68edusAAAAAgFWkMAkArN0OOKAtUC5YkPzRHyX/+Z/JbrslL35xcvbZw24dAAAAADBBCpMAwNSw\n667JJz+Z3HBD8q53JWeckTz96ckhhySnnJIsWzbsFgIAAAAAfShMAgBTy+Mel/z93yc33ph89KPt\n5VFHJXvumXz2s8nixcNuIQAAAADQhcIkADA1bbhh8sY3Jtdem3zpS8l66yWveU2y447JiScm9947\n7BYCAAAAAGMoTAIAU9vs2cmrXpVceGFy2mnJXnsl73xnst12yV/9VXLTTcNuIQAAAAAQhUkAYLoo\nJfnd322LkxdemLzwhe2pXnfaKfnDP0wuu2zYLQQAAACAdZrCJAAw/ey3X3t614ULk7/4i+Skk5K9\n906OPDI5/fSkaYbdQgAAAABY5yhMAgDT1/bbJx/5SHLjjcn73pdccEFyxBHJ/vsn//M/yaOPDruF\nAAAAALDOUJgEAKa/zTZL3vWu5IYbkk9+MnnggeTlL0+e9KTk4x9PHn542C0EAAAAgGlPYRIAWHes\nt17y2tcmV17Znt71cY9LjjsuecITkhNOSO68c9gtBAAAAIBpS2ESAFj3zJyZHH108r//m/zsZ8lB\nByXvfW976te/+Iu2cAkAAAAADJTCJACwbjvooORb32qLka96VfKZzyR77pk84xnJV76SLF487BYC\nAAAAwLSgMAkAkCS7794WJW++OfngB5NbbmkLldttlxx/fHLddcNuIQAAAABMaQqTAABjbbll8ra3\nJVdfnfzgB8nBByf/+I/JLrskz3teO7vy0UeH3UoAAAAAmHIUJgEAupkxI3n2s5OTTkpuuCF5z3uS\nyy5LXvSiZIcd2u+kvOWWYbcSAAAAAKYMhUkAgPFss01bmLz++uTkk5O99kpOOCHZfvvkxS9OTjst\nWbZs2K0EAAAAgLWawiQAwETNmpUcdVTy/e8nCxcmb31rctZZyXOek+y6a/KhDyV33jnsVgIAAADA\nWklhEgBgdey0U3LiicnNNydf/nI7q/Ltb0+23TY55pi2YNk0w24lAAAAAKw1FCYBANbE3LnJK1+Z\nnAQdmf8AACAASURBVHlmcsUVyetel5x6anLoocmTn5z8678m99037FYCAAAAwNApTAIADMoeeyQf\n+1hyyy3JZz+bzJuXvOENydZbJ695TXLBBcNuIQAAAAAMjcIkAMCgbbBBcuyxyXnntcurXpV85SvJ\n/PnJ/vu3RcuHHhp2KwEAAABgUilMAgDUNH9+8ulPJ7femvzLvySLFrWzJ7fZJnnjG5NLLvFdlAAA\nAACsExQmAQAmw2Mekxx3XHLZZclZZyXPf37yyU8m++7bngL2ve9NfvnLYbcSAAAAAKpRmAQAmEyl\nJAcfnHzxi+13Uf77vyePe1xbmNxtt2S//ZIPfCC5/vphtxQAAAAABkphEgBgWLbYIvnzP0/OOCO5\n+ebkIx9J1lsvOf74ZMcdkwMPbLfdcsuwWwoAAAAAa0xhEgBgbbD11smb3pScfXZy3XXJiScmixcn\nb3lLst12yWGHJZ/4RHLnncNuKQAAAACsFoVJAIC1zY47Ju94R3LRRcmCBckJJyR33JG8/vXJ4x+f\nPOc5yec/n9x777BbCgAAAAATpjAJALA2e9KTkr/92+TKK5NLLkne/vbkmmuSY49tv5vyqKOSr3wl\nefDBYbcUAAAAAPpSmAQAmApKSfbeO/mHf0gWLkzOPTc57rjkgguSV70qeexjk5e9LDnppGTRomG3\nFgAAAABWojAJADDVlJLsv3/y4Q8nN96Y/PSnyZ/8SXLmmclLXtLOpPzDP0xOPTVZsmTYrQUAAACA\nJAqTAABT24wZySGHJB//eHLLLckPf9jOnPz2t5PnPz/Zaqvkz/4s+fGPk6VLh91aAAAAANZhCpMA\nANPFrFnJs56VfOYzyR13tMXJI49M/vu/2+1bb5386Z8mJ5/sOykBAAAAmHSlaZpht+G35s+f35x/\n/vnDbgYAwPSyaFHy3e8mX/ta8v3vJ/fdl8ydmxx+eDur8vnPT7bfftitBAAAAGCKKqVc0DTN/HHv\npzAJALAOeeSR5Gc/S77znXZG5TXXtNuf/OS2QPmCFyQHHJDMnDncdgIAAAAwZShMAgAwvquvbguU\n3/lOctZZ7fdQbrFFewrYF7wgefazk403HnYrAQAAAFiLKUwCALBq7r23PdXrd77Tnvr1nnuS2bOT\nZzxjdDblTjsNu5UAAAAArGUUJgEAWH2PPpqcffbobMqrrmq37777aJHyaU9LZs0abjsBAAAAGDqF\nSQAABmfhwrZA+Z3vJGee2X5X5WabJc97XluofM5zkk03HXYrAQAAABgChUkAAOq4//7ktNPaIuWp\npyZ33ZXMnJkccsjobMpddx12KwEAAACYJAqTAADUt3Rpcu65bZHy299OLrus3f7EJ7azKQ8/vP2O\nSrMpAQAAAKYthUkAACbfDTe0syi//e32lK+LFiWlJPvt1xYpDz+8nVm58cbDbikAAAAAA6IwCQDA\ncC1e3M6mPP305Cc/Sc4+O1mypD3t6/z5bZHyiCOSgw5K1l9/2K0FAAAAYDUpTAIAsHZZtKgtTo4U\nKs89N3n00WT27OSpT22LlIcfnhx4YLLeesNuLQAAAAATpDAJAMDa7cEHk5//vC1Snn56csEFybJl\nbVHyaU8bLVTuv38yZ86wWwsAAABADwqTAABMLffdl5x11mih8pJLkqZpT/N6yCGj31H5lKcks2YN\nu7UAAAAAdChMAgAwtf3f/yVnntkWKU8/Pbniinb7xhsnhx46WqjcZ59kxozhthUAAABgHaYwCQDA\n9HLHHckZZ4wWKq++ut2+2WbJM56RHHRQ8vSntzMq584dalMBAAAA1iUKkwAATG+33DJapDzjjOS6\n69rtc+Yk8+e3RcqnPa293GqroTYVAAAAYDpTmAQAYN1y++3J2We3y//+b3L++cnixe1tO+64fKHy\nyU/2PZUAAAAAA6IwCQDAum3x4uSii0YLlT//eXLbbe1tG2yQPPWpo4XKAw9sTwkLAAAAwCpTmAQA\ngLGaJrnxxrZIOVKsvPjiZOnS9vbdd19+VuWTnpTMmDHcNgMAAABMAQqTAAAwnoceSs47b/li5d13\nt7dtumlbpBwpVB5wQLLhhsNtLwAAAMBaaKKFSV+sAwDAumuDDZLDDmuXpJ1VefXVyxcqv/vd9rYZ\nM5J99mkLlU99aru+++7JnDnDaj0AAADAlGLGJAAA9HPPPck554wWKn/xi+TBB9vbZs9O9tijLVLu\ns0+y777t5eabD7fNAAAAAJPIqVwBAKCGpUuTa65pv5/ykktGL2+7bfQ+22wzWqQcudxlF99ZCQAA\nAExLTuUKAAA1zJyZ7LZbu7ziFaPbf/3rtkA5slx8cfL977eFzCRZf/1k772Xn1355Cf73koAAABg\nnWHGJAAA1LJ4cXLllaOzKkcKlvfe295eSrLzzivPrtx22/Y2AAAAgCnAjEkAABi2uXOT/fZrlxFN\nk9x00/LFyosuSr7+9dH7bLrpaJFyn32SvfZqZ2iaXQkAAABMYQqTAAAwmUpJnvCEdnnhC0e3P/BA\nctlly3935Sc/mSxaNHqf7bdP9twz2WOP5ZeNNpr8fgAAAACsIoVJAABYG2y0UfL0p7fLiKVLk4UL\nkyuuaE8Je+WV7fqPf9yeJnbEdtu1BcoVi5aPeczk9wMAAACgB4VJAABYW82cmey6a7scffTo9qVL\nk1/9auWC5ZlnJr/5zej9ttlmtEg5tmi56aaT3xcAAABgnVeaphl2G35r/vz5zfnnnz/sZgAAwNS0\ndGlyww0rFyyvuip5+OHR+z3+8cvPrBwpWm6++fDaDgAAAExZpZQLmqaZP979zJgEAIDpYubMZKed\n2uUFLxjdvmxZcuONyxcsr7wy+fznkwcfHL3fYx+b7Lbb6GPsvPPo+pZbtt+PCQAAALCaFCYBAGC6\nmzEj2WGHdvm93xvd3jTJTTeNzqy84orkmmuS005Lbr11+cfYcMPRIuXYZeedk+23T+bOncweAQAA\nAFOQwiQAAKyrSkme8IR2ee5zl79t0aLk+uuThQuT664bXa6+Ovn+95f/LstSkm23XXmW5ciyxRZm\nWwIAAAAKkwAAQBfz5iW7794uK2qa5PbbR4uVY4uX3/tecttty99/o41WnmU5sv6EJ5htCQAAAOsI\nhUkAAGDVlJI8/vHtctBBK9/+8MPJr361/EzLhQuTBQvawuXY2ZZJstVW7elgey0bbzw5/QIAAACq\nUpgEAAAGa/31kz33bJcVLVs2Otty4cLkhhtGlwsvTE4+OVmyZPmf2WST/oXLLbd0qlgAAACYAhQm\nAQCAyTNjRrL11u1y8MEr375sWXLHHcsXLG+8sb381a+SM85I7r9/+Z+ZN689JWyvwuXWWyez7PoA\nAADAsNk7BwAA1h4zZoyeJvbAA7vf5957ly9cjl0uvjj59a+Xv//Mmcm22ybbbdc+7tZbL385sr7J\nJmZeAgAAQEUKkwAAwNSyySbtss8+3W9ftGh0luXY5eabk0svTX7wg5VnXSbJ3Lm9i5ZjLzfbTAET\nAAAAVoPCJAAAML3Mm5c86Unt0stDDyW33ZbceuvylyPrV1yR/PCHyX33rfyzc+asXLTsVsDcfPN2\nBigAAACQRGESAABYF22wQbLLLu3Sz8MPL1+wXHF9wYLk9NOTe+5Z+WdnzGhnV2655eiyxRa9r2+x\nRTtrEwAAAKYphUkAAIBe1l8/2Xnnduln0aLk9tuXL1reeefyy1VXtZf/93/JsmXdH2ejjZYvXI5X\nzNxwQ6eVBQAAYMpQmAQAAFhT8+YlO+7YLuNZurSdYXnXXSsXL8duu/nm5KKL2vUlS7o/1ty5baFy\niy3aU8dOZNlkE6eYBQAAYCgUJgEAACbTzJmjxcTddhv//k2TPPhg9+Ll2G13351cemk7I/Puu3vP\nypwxI9l005ULlptt1r+gOW/eYJ8HAAAA1jkKkwAAAGuzUtpTvG60UbLTThP7mWXLkvvua4uU4y23\n3DJa0Hzood6POW/e8rMuH/OYdhm7vuL1sevrree0swAAAOs4hUkAAIDpZmRW5KabJrvsMvGf+81v\n2tmW4xUz77svueGG5N572/X77+89Q3PE7NkTL2KOvb7xxqOF2fXXV9wEAACYwhQmAQAAaK23XrL1\n1u2yKpYta083e999o8tI0bLf+i9/OXr9wQfHz5kxI9lww9FC5Zouc+eu3vMEAADAalGYBAAAYM3M\nmNHObNx442S77VbvMR59tJ15uWIB8/77kwce6L/ceefy15csmVjm7NkrFytHCp8bbrjy+ni3bbhh\n+1wAAADQlcIkAAAAwzdrVrLZZu2yppYsaWdgjlfQ7LXcdlv78yOPsXjxxLPXX3/iBc0NNmi/u7Pb\nsv763bcrfAIAAFOYwiQAAADTy5w5gytyJskjjyQPPdQWKUcKliNFy27rK16/557kppuWv+2RR1a/\nb6tSyOx2n16XK26bO9d3egIAAAOlMAkAAAD9zJ6dbLJJuwzKkiVtsXPRouThh9vLXstEb7/vvuT2\n27vfvjpK6V74HK/AOXK53nrjLyveTzEUAACmNYVJAAAAmGxz5rTLppvWz2qa9nS0KxYyV7zsd1u3\n+95zT/fbli1bs/bOnbtqRc25c1de5szpvj7e9RVvmzlzML8DAAAgicIkAAAATG+ljBbzahdCm6ad\nDbpoUVsM/c1v2mXRotH1VVm6/dw996x8nyVL2rzFi9s2DMqMGd2LmCOF5Tlz2hm1Y6+v6W0rbp89\nu/0O1rHLitu63cf3kQIAsBZSmAQAAAAGo5TRIt4wNE3y6KPLFyrHro93faK3PfJIe33s8vDDK28b\nWUbuP+jCaT8zZqx6QXP27O4zUGsts2e3s1KdvhcAYJ2hMAkAAABMD6W0xa7Zs5MNNhh2a7pburR7\n0bLX8uijo8sjjyx/vdu2idyn18898khbPL3nnuULtCsujzwy2OeklLYwOnPm6DL2+kTWJ3K/fper\ne9t49xn0uiIuADDFKUwCAAAATJaZM9vvx5w3b9gtWX3Llq08u3R1lpGi6NKl7dJrvd9t3daXLOl9\nW7fLbtvW9LtSaymlewF0xozRy4msr8l9uxWDJ1IIXt379yoAr8m6Ai8ADI3CJAAAAAATN2PG6PeW\nTldNs3xRc1ULm6taTF3V9RW3LVs2uixd2n99vNtHHrvb7SveZ6L9XtuMFFlXLFjOmNEWLUcue62P\nd/tEH6NbsXdsQXjQ28de77Y+0W0TuX1sH8cu3bav7n0VmAGmJIVJAAAAABhr5PSys2YN7ztTp4um\nWb6wOZFC5kQLwYNcHynwNs1om/utr8p9u62PLfiOzPIdWxBecVnV7ZP1fbbD1qsAvKYF5IkUlGsW\nd8de9mrfeG1e3esrFuBrbhsx3vqa3rdbW2ouY59TYCUKkwAAAABAHSOnn505c9gtWbesWBBecRbs\nRLat7s+MFEZXLMKOLN22r+59x2b1KwavTgG5X0F5vOdjbMF9TZ/3Xu3pdn1dKUhPFb0KvoNer1WI\n77U+tm/jLWt6326F7V6Xq3LfbpfbbJO89KXDea2sYxQmAQAAAACmEwXhddeKhcpVLW6uWACusW3s\nKZ7HFlO7rY93+0Tu26stNZZuhfnJWl/dQvyyZRObNb5sWffXWK9lUPft9prqdTm23avq4IMVJieJ\nwiQAAAAAAEwHTiEKrVUtavogx6RRmAQAAAAAAGD6GJk5zlpnxrAbAAAAAAAAAEx/CpMAAAAAAABA\ndQqTAAAAAAAAQHUKkwAAAAAAAEB1CpMAAAAAAABAdQqTAAAAAAAAQHUKkwAAAAAAAEB1CpMAAAAA\nAABAdQqTAAAAAAAAQHUKkwAAAAAAAEB1CpMAAAAAAABAdQqTAAAAAAAAQHUKkwAAAAAAAEB1CpMA\nAAAAAABAdVULk6WU55ZSfllKubaUcnzNLAAAAAAAAGDtVa0wWUqZmeTjSZ6XZI8kryyl7FErDwAA\nAAAAAFh71ZwxeUCSa5umua5pmiVJ/jvJURXzAAAAAAAAgLVUzcLkNkluGnP95s625ZRSXltKOb+U\ncv6dd95ZsTkAAAAAAADAsFT9jsmJaJrmU03TzG+aZv6WW2457OYAAAAAAAAAFdQsTN6SZLsx17ft\nbAMAAAAAAADWMTULk+cleWIpZcdSypwkr0hySsU8AAAAAAAAYC01q9YDN03zaCnluCQ/SDIzyeea\nprmiVh4AAAAAAACw9qpWmEySpmm+m+S7NTMAAAAAAACAtV/NU7kCAAAAAAAAJFGYBAAAAAAAACaB\nwiQAAAAAAABQncIkAAAAAAAAUJ3CJAAAAAAAAFCdwiQAAAAAAABQncIkAAAAAAAAUJ3CJAAAAAAA\nAFCdwiQAAAAAAABQncIkAAAAAAAAUJ3CJAAAAAAAAFCdwiQAAAAAAABQncIkAAAAAAAAUJ3CJAAA\nAAAAAFCdwiQAAAAAAABQncIkAAAAAAAAUJ3CJAAAAAAAAFCdwiQAAAAAAABQncIkAAAAAAAAUF1p\nmmbYbfitUsqdSW4YdjumuC2S3DUNsyY7T9+mZp6+Tc08fZuaefo2NfOmc98mO0/fpmaevk3NPH2b\nmnn6NjXz9G1q5unb1MzTt6mZp29TM0/fpmbedO7bMPImw/ZN02w53p3WqsIka66Ucn7TNPOnW9Zk\n5+nb1MzTt6mZp29TM0/fpmbedO7bZOfp29TM07epmadvUzNP36Zmnr5NzTx9m5p5+jY18/Rtaubp\n29TMm859G0be2sSpXAEAAAAAAIDqFCYBAAAAAACA6hQmp59PTdOsyc7Tt6mZp29TM0/fpmaevk3N\nvOnct8nO07epmadvUzNP36Zmnr5NzTx9m5p5+jY18/Rtaubp29TM07epmTed+zaMvLWG75gEAAAA\nAAAAqjNjEgAAAAAAAKhOYRIAAAAAAACoTmFymiilPLeU8stSyrWllOMrZ32ulPLrUsrlNXM6WduV\nUk4vpVxZSrmilPKmynnrlVLOLaVc0sl7b828TubMUspFpZTvTELW9aWUy0opF5dSzq+ctUkp5eul\nlAWllKtKKU+rmPWkTp9GlvtLKW+umPeWzuvj8lLKV0op69XK6uS9qZN1RY1+dfubLqVsVkr5YSnl\nms7lphWzfr/Tt2WllPmDyBkn70Od1+WlpZRvllI2qZj1952ci0spp5VSth5EVq+8Mbf9VSmlKaVs\nUSurlHJCKeWWMX93Rw4iq1deZ/sbOr+7K0opH6yVVUr56ph+XV9KuXgQWX3y9i2l/GJkbC6lHFAx\na59Sytmd/wXfLqVsPKCsrv+vK44lvfIGPp70yao1lvTKG/h40itrzO2DHkt69W3g40m/vlUaS3r1\nrcp40idv4ONJn6xa40nX9+OllB1LKeeUdn/nq6WUORWzjuvkDOz1P07el0q7L3d5acfu2RWzPtvZ\ndmlp36tvuKZZ/fLG3P6xUsqDNbNKKf9RSvnVmL+5fSvnlVLK+0spV5d2f+eNFbPOGtOvW0spJ69p\n1jh5zyylXNjJ+1kpZZeKWUd0si4vpfxnKWXWmmaNyVxuX7vGODJOXpWxpEfWwMeRcfKqjCW98sZs\nH9hY0iur1ljSI2vg48g4eVXGkj55Ax9L+mTVHEtWOpZW6u3ndMuqecykW16t/ZxuWTWPmfQ8BloG\nv5/TrW81j5l07Vups5/TrW81j5l0y6t1zKRbVpV9nM5jr3SsvNZYMiU0TWOZ4kuSmUkWJtkpyZwk\nlyTZo2LeoUmekuTySejb45M8pbO+UZKrK/etJNmwsz47yTlJDqzcx79M8uUk35mE5/P6JFvUzulk\n/WeS13TW5yTZZJJyZya5Pcn2lR5/myS/SjKvc/1/kvxxxf7sleTyJOsnmZXkR0l2GXDGSn/TST6Y\n5PjO+vFJPlAxa/ckT0pyRpL5k9C3ZyeZ1Vn/QOW+bTxm/Y1JPlGzb53t2yX5QZIbBvX33qNvJyR5\n6yB/X+PkHd55/c/tXH9szedxzO0fTvK3lft2WpLnddaPTHJGxazzkjyjs35skr8fUFbX/9cVx5Je\neQMfT/pk1RpLeuUNfDzpldW5XmMs6dW3gY8nfbJqjSXjvmcd5HjSp38DH0/6ZNUaT7q+H0/7nusV\nne2fSPL6iln7JdkhA37v3CfvyM5tJclXKvdt7FjyT+mM0bXyOtfnJ/mvJA9Wfh7/I8lLB/X7mkDe\nnyT5QpIZndvWeDzp9zyOuc83kvxh5b5dnWT3zvb/l+Q/KmU9PclNSXbtbP+7JH86wN/dcvvaNcaR\ncfKqjCU9sgY+joyTV2Us6ZXX2TbQsaRP36qMJT2yBj6OjPc8jrltYGNJn/4NfCzplpV24k3NsWSl\nv+HU28/pllXzmEm3vFr7Od2yah4z6Tr2ps5+Tre+nZB6x0y65dXaz+n6PI65fdDHTLr1rdYxk25Z\nVfZxOo+30rHyWmPJVFjMmJweDkhybdM01zVNsyTJfyc5qlZY0zQ/TXJ3rcdfIeu2pmku7Kw/kOSq\ntIWhWnlN0zQjn76b3VmaWnmllG2T/F6Sz9TKGIZSymPSHhD/bJI0TbOkaZp7Jyn+mUkWNk1zQ8WM\nWUnmdT6Bt36SWytm7Z7knKZpHm6a5tEkZyZ58SADevxNH5X2H2Y6ly+qldU0zVVN0/xyEI8/wbzT\nOs9lkvwiybYVs+4fc3WDDHA86TMW/3OSt09SVhU98l6f5MSmaRZ37vPrillJ2k8wJ3lZ2oM7A9Ej\nr0ky8im8x2RAY0qPrF2T/LSz/sMkLxlQVq//17XGkq55NcaTPlm1xpJeeQMfT8Z5n1VjLJm093V9\nsmqNJX37NujxpE/ewMeTPlm1xpNe78ePSPL1zvaBjCe9spqmuahpmuvX9PFXIe+7nduaJOdmAONJ\nn6z7k9++JudlQH/jvfJKKTOTfCjteDIQk73P1ifv9Un+rmmaZZ37rfF4Ml7fOp/aPyLJQGY59cmr\nMZZ0y1qaZEnTNFd3tg9sLFlxX7vzmh/4ONIrL0lqjSU9sgY+joyTV2Us6ZVXYyzplVVLj6yBjyPj\n5I3cNtCxpE9elf2cLlmbp9JY0keV/ZxuauzjjJNXZT+nR1a1YyZ9DHw/Zy1RZT+nnxrHTHqoMpb0\nUGUfp8+x8kkbS9Y2CpPTwzZpPxk04uZULN4NSyllh7SfODyncs7MzhT0Xyf5YdM0NfM+kvaf4bKK\nGWM1SU4rpVxQSnltxZwdk9yZ5POlPbXGZ0opG1TMG+sVqfgPsWmaW5L8Y5Ibk9yW5L6maU6rlZd2\ntuQhpZTNSynrp/1k0HYV80Y8rmma2zrrtyd53CRkDsOxSb5XM6C0p+a5KckxSf62ctZRSW5pmuaS\nmjljHNc57crnJuF0E7um/Vs4p5RyZill/8p5SXJIkjuaprmmcs6bk3yo8zr5xyTvrJh1RUY/vPT7\nqTCerPD/uvpYMlnvD8bJqjKWrJhXczwZmzUZY0mX57LaeLJCVvWxpMfrpNp4skJe1fFkhaxq48mK\n78fTnh3m3jEHyQa2vzPJ7/375pX21IuvTvL9mlmllM+nHZN3S/Ivg8jqk3dcklPG/C+omZUk7++M\nJf9cSplbOW/nJC/vnFLse6WUJ1bMGvGiJD9e4UBujbzXJPluKeXmtK/JE2tkpS2gzSqjpyZ8aQY3\nlqy4r715Ko0jPfJq6pk16HGkX16tsaRHXpWxpEdWUmcs6ZZVZRzpkzdi4GNJj7wqY0mXrLtSbyxJ\nuh9Lq7WfM1nH7SaaN8j9nK5ZFfdxVsqruJ/T63mstY/TLa/Wfk6/10iNfZxuebX2cbpl1drH6XWs\nfF05/roShUmmhNJ+X8E3krx5wG+cVtI0zdKmafZN+4mgA0ope9XIKaU8P8mvm6a5oMbj93Bw0zRP\nSfK8JH9RSjm0Us6stKcP/PemafZL8lDa6ehVlfY7Ql6Y5GsVMzZN+w9qxyRbJ9mglPIHtfKaprkq\n7akzTku7c3lx2k8WT5rOp26n2yfJUkp5V5JHk3ypZk7TNO9qmma7Ts5xtXI6heu/TuXi5xj/nnZH\net+0RfoPV86blWSztKcXe1uS/+l8Oq+mV6b+J/+S9pONb+m8Tt6SzifoKjk2yf8rpVyQ9pSMSwb5\n4P3+X9cYSybz/UGvrFpjSbe8WuPJ2Ky0fak6lnTpW7XxpEtW1bGkz2uyynjSJa/aeNIlq9p4suL7\n8bQHvauYrPf+E8z7tyQ/bZrmrJpZTdP8Sdr3sVclefkgsnrkHZr2gM4gCxa9svZKe5BqtyT7p/07\nf0flvLlJftM0zfwkn07yuYpZIwY+lvTIe0uSI5um2TbJ59OeqnPgWUn2TPvB0n8upZyb5IEMYF9n\nsve1JzNvAlkDHUf65dUYS7rllfY75wY+lvTp28DHkj5ZVcaRCbxOBjqW9Mkb+FjSLauznzHwsWSM\nvsfSBryfM1nH7cbNq7Cf0zWr4jGTbnm19nO6ZdU8ZtItr9Z+Tr/XZI19nG55tfZxumXV2scZ91j5\ndD3+2ovC5PRwS5av3m/b2TYtdD7x940kX2qa5qTJyu1Mpz49yXMrRRyU5IWllOvTnn73iFLKFytl\nJfntbL+R6fzfTLszWMPNSW4e8+ner6cdfGt7XpILm6a5o2LGs5L8qmmaO5umeSTJSWm/G6Wapmk+\n2zTN7zRNc2iSe9J+T0Ntd5RSHp8kncvqp4CYTKWUP07y/CTHdP7xT4Yvpe7pZHZOWzC/pDOubJvk\nwlLKVjXCmqa5o3NwaVnaneha48mIm5Oc1LTOTfvp2IF8UX03pT1V84uTfLVWxhh/lHYsSdoPVlR7\nLpumWdA0zbObpvmdtDsQCwf12D3+X1cbSybz/UGvrFpjyQT6NrDxpEtW1bGkW99qjSc9nsdqY0mf\n10mV8aRHXpXxpMfvrdp4MmLM+/GnJdmk81wmFfZ3JuG9f9+8Usp7kmyZ9juzqmZ1ti1Nuw8y8Pcm\nY/IOT7JLkms748n6pZRrK2U9t2lPO9w07SnMPp8K/09XeC5vzujf2zeT7F0xK6WULdL26dRB2q1P\n/gAACORJREFU5nTJe16Sfcbsy301A97fWeH3dnbTNIc0TXNA2lOnDWJfZ6V97SQfTb1xZDL37Xtm\nVRpH+vatwljS7Xd3ReqMJV37Vmks6fU81hpH+r1Oaowl3fJOTZ2xpNfvrcZYkqTnsbQq+zmTeNyu\nb16N/ZwJ9G2gx0y65D0jlfZzuvWt5jGTHs9llf2cPq+RKvs4PfKq7OP0+L3V2sfpdax8Wh9/7Udh\ncno4L8kTSyk7dmaMvSLJKUNu00B0Ptnx2SRXNU0zkE9pjpO3ZSllk876vCS/m2RBjaymad7ZNM22\nTdPskPZ39pOmaarNvCulbFBK2WhkPe2XWV9eI6tpmtuT3FRKeVJn0zOTXFkjawWTMbvpxiQHllLW\n77w+n5n2E6LVlFIe27l8Qtp/+l+umddxStp//OlcfmsSMidFKeW5aU/78sKmaR6unDX2VDxHpdJ4\nkiRN01zWNM1jm6bZoTOu3JzkKZ2/x4EbeePUcXQqjSdjnJz2AGdKKbum/aLwuyrmPSvJgqZpbq6Y\nMeLWtDtJSXvwpdqpY8eMJzOSvDvJJwb0uL3+X1cZSybz/UGvrFpjSZ+8gY8n3bJqjiV9+jbw8aTP\na6TKWDLOa3Lg40mfvIGPJ31+b7XGk27vx69KW8R4aeduAxlPJvO9f7+8UsprkjwnySs7B69qZf2y\nlLJLZ1tJe6aRgfS3R94FTdNsNWY8ebhpml0qZS0Yc1CnpD1N4UDem/R5nfx2PEn7d7fGB8HHeU2+\nNMl3mqb5zZrmjJN3VZLHdMbIjNlWI2vBmLFkbtqZaWs8lvTY1z4mFcaRPnlV9u17ZdUYR3rlJXl1\nrbGkR/82rTGW9HkuBz6W9HmNDHwcGScvqTCW9HidHJUKY0mf39vAx5LO4/U6ljbw/ZzJPG7XL6/G\nfk6frCrHTHrknVdjP6dP36ocM+nzOhn4fs44r8ka+zi98mrs4/T6vVXZx+lzrHzaHn8dV9M0lmmw\npP3euavTVvHfVTnrK2mnoD+SdhD/04pZB6edwnxp2lNYXpz2NBC18vZOclEn7/IkfztJv7/D0r4x\nrJmxU5JLOssVk/A62TfJ+Z3n8uQkm1bO2yDJ/yV5zCT8vt6b9s3S5Un+K8ncynlnpf1ndUmSZ1Z4\n/JX+ptN+B8uP0/6z/1GSzSpmHd1ZX5zkjiQ/qNy3a9N+L+/ImPKJilnf6LxOLk3y7STb1OzbCrdf\nn2SLin37rySXdfp2SpLHV/69zUnyxc7zeWGSI2o+j0n+I8mfD6pP4/Tt4CQXdP7Gz0nyOxWz3pT2\n/cLVab/jpQwoq+v/64pjSa+8gY8nfbJqjSW98gY+nvTKWuE+gxxLevVt4ONJn6xaY0nP57LGeNKn\nfwMfT/pk1RpPur4fT/te9tzO397XMoD3X32y3tgZSx5NeyDkM5X79mja/biR53eN90G6ZaX9YPLP\nO39vl6edmbBxzb6tcJ8HKz+PPxnTty8m2bBy3iZpZxxdluTstDODqj2PSc5IO8Nwjfs0gb4d3enX\nJZ3cnSpmfShtseKXaU8VPbD+dR7/sHT2tWuMI+PkVRlLemQNfBzplVdzLOnVvxW2D2Qs6fNcVhlL\nemQNfBwZ73msMZb06d/Ax5I+WVXGkvQ4lpYK+zl9sqocM+mTN/D9nD5ZVY6Z9Mpb4T7XZwD7OX36\nVuWYSZ+8ge/n9HseU2cfp1ffauzj9Mqqso/TeeyVjpXXGEumylI6TwoAAAAAAABANU7lCgAAAAAA\nAFSnMAkAAAAAAABUpzAJAAAAAAAAVKcwCQAAAAAAAFSnMAkAAAAAAABUpzAJAAAwDZVSmlLKh8dc\nf2sp5YRJzJ9bSvlRKeXiUsrLV7jtP0opv+rcdnEp5X8HnH1GKWX+IB8TAACANTdr2A0AAACgisVJ\nXlxK+f+aprlrCPn7JUnTNPv2uP1tTdN8fRLbAwAAwJCZMQkAADA9PZrkU0nesuINnRmLLx1z/cHO\n5WGllDNLKd8qpVxXSjmxlHJMKeXcUsplpZSduzzWZqWUk0spl5ZSflFK2buU8tgkX0yyf2dG5Eo/\n100p5YRSyn+VUs4upVxTSvmzzvZSSvlQKeXyTjtePuZn3tHZdkkp5cQxD/f7nXZfXUo5pHPfPTvb\nLu6094kTeiYBAAAYCDMmAQAApq+PJ7m0lPLBVfiZfZLsnuTuJNcl+UzTNAeUUt6U5A1J3rzC/d+b\n5KKmaV5USjkiyReaptm3lPKaJG9tmub5PXI+VEp5d2f9iqZpjums753kwCQbJLmolHJqkqcl2bfT\nti2SnFdK+Wln21FJnto0zcOllM3GPP6sTruPTPKeJM9K8udJPto0zZdKKXOSzFyF5wUAAIA1pDAJ\nAAAwTTVNc38p5QtJ3phk0QR/7LymaW5LklLKwiSndbZfluTwLvc/OMlLOnk/KaVsXkrZeAI5vU7l\n+q2maRYlWVRKOT3JAZ2MrzRNszTJHaWUM5Psn+QZST7fNM3Dnfy7xzzOSZ3LC5Ls0Fk/O8m7Sinb\nJjmpaZprJtBOAAAABsSpXAEAAKa3jyT507QzEEc8ms7+YCllRpI5Y25bPGZ92ZjryzI5H25txrk+\nUSPtXppOu5um+XKSF6Yt0n63M8MTAACASaIwCQAAMI11ZhH+T9ri5Ijrk/xOZ/2FSWavQcRZSY5J\n2u+oTHJX0zT3r8HjHVVKWa+UsnmSw5Kc18l4eSllZillyySHJjk3yQ+T/EkpZf1O/mY9HjOd23dK\ncl3TNB9L8q20p40FAABgkihMAgAATH8fTvvdjCM+neQZpZRL0n5/40Nr8NgnJPmdUsqlSU5M8kcT\n/LkPlVIuHrOMzNq8NMnpSX6R5O+bprk1yTc72y9J8pMkb2+a5vamab6f5JQk55dSLk7y1nEyX5bk\n8s5990ryhQn3EgAAgDVWmmZ1z4oDAAAAg1NKOSHJg03T/OOw2wIAAMDgmTEJAAAAAAAAVGfGJAAA\nAAAAAFCdGZMAAAAAAABAdQqTAAAAAAAAQHUKkwAAAAAAAEB1CpMAAAAAAABAdQqTAAAAAAAAQHX/\nP9i0qfivkGeNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2304x1296 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'],'r')\n",
    "plt.plot(history.history['val_loss'],'g')\n",
    "plt.xticks(np.arange(0, 61, 1))\n",
    "plt.rcParams['figure.figsize'] = (32, 18)\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.legend(['train','validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTclIwhOCa3F"
   },
   "source": [
    "By looking at the graph we can say that the validation loss stopped dropping after **25 epochs** or the loss dropping very slowly after 25 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QivlsbdoCa3I"
   },
   "source": [
    "<h3><a id=\"Prediction\">&#9997; Prediction</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJvPV07hCa3J"
   },
   "source": [
    "**Predicting the output**\n",
    "\n",
    "As the model is now built, we will pass the testing data and see how the built model predicts.\n",
    "\n",
    "and as the predicted data will be in the form of array we need to convert the sequence back to word which can be done by the function \"get_word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gh3QYCn_Ca3J"
   },
   "outputs": [],
   "source": [
    "preds = history.model.predict_classes(x_test.reshape((x_test.shape[0],x_test.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OiKZcDiSCa3N",
    "outputId": "42b5aa72-7405-4745-d3b5-06b3ffd764b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  78,   12,    4, 4030,    0])"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w0M_lfLACa3Q"
   },
   "source": [
    "The below function will return the text when we pass the tokenized array and as we will store the predicted text into our empty array \"predicted_text\" where we will append all the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VM3eSLPdCa3R"
   },
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "      for word, index in tokenizer.word_index.items():\n",
    "          if index == n:\n",
    "              return word\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5dXu6s6-Ca3T"
   },
   "outputs": [],
   "source": [
    "predicted_text = []\n",
    "for i in preds:\n",
    "       temp = []\n",
    "       for j in range(len(i)):\n",
    "            t = get_word(i[j], English_tokenizer)\n",
    "            if j > 0:\n",
    "                if (t == get_word(i[j-1], English_tokenizer)) or (t == None):\n",
    "                     temp.append('')\n",
    "                else:\n",
    "                     temp.append(t)\n",
    "            else:\n",
    "                   if(t == None):\n",
    "                          temp.append('')\n",
    "                   else:\n",
    "                          temp.append(t) \n",
    "\n",
    "       predicted_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SHsCEf75Ca3V"
   },
   "source": [
    "Prediction is done, predicted output is converted back to text format and now we will check how the predicted format looks like, we will pass it through the pandas dataframe  and see the Italian data with Actual data and the predicted data side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRI9VXb8Ca3Y"
   },
   "outputs": [],
   "source": [
    "pred_dframe = pd.DataFrame({'Italian' : test[:,1] ,'actual' : test[:,0], 'predicted' : predicted_text})\n",
    "#pred_df = pd.DataFrame({'Italian' : test[:,1] ,'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kf9ZRu_rCa3a"
   },
   "source": [
    "We will see how the translation is done, so to check we will check the first 50 texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1599
    },
    "colab_type": "code",
    "id": "qng488yOCa3b",
    "outputId": "8ea990b7-82ae-47cc-b2d7-f59d6b943ff0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Italian</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mi faccia un urlo</td>\n",
       "      <td>give me a holler</td>\n",
       "      <td>give me a holler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>siamo molto emozionate</td>\n",
       "      <td>were very excited</td>\n",
       "      <td>were very excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tom gioca a tennis</td>\n",
       "      <td>tom plays tennis</td>\n",
       "      <td>tom plays tennis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tom vuole camminare</td>\n",
       "      <td>tom wants to walk</td>\n",
       "      <td>tom wants to walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tom è un professionista</td>\n",
       "      <td>tom is a pro</td>\n",
       "      <td>tom is a fanatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>loro sono grassi</td>\n",
       "      <td>theyre fat</td>\n",
       "      <td>theyre fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abbiate pietà di me</td>\n",
       "      <td>show pity on me</td>\n",
       "      <td>show pity on me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a lei piace la scuola</td>\n",
       "      <td>do you like school</td>\n",
       "      <td>do you like school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a tom piace pescare</td>\n",
       "      <td>tom likes to fish</td>\n",
       "      <td>tom likes fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>la sua banca è sicura</td>\n",
       "      <td>is your bank safe</td>\n",
       "      <td>is your bank safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tom ha perso peso</td>\n",
       "      <td>tom lost weight</td>\n",
       "      <td>tom lost weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>non tornare a chiamare</td>\n",
       "      <td>dont call again</td>\n",
       "      <td>dont call to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lei è al sicuro</td>\n",
       "      <td>youre safe</td>\n",
       "      <td>youre safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>non chiedermi perché</td>\n",
       "      <td>dont ask me why</td>\n",
       "      <td>dont you want you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>labbiamo dato a loro</td>\n",
       "      <td>we gave it to them</td>\n",
       "      <td>we gave it to them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>è giovane e single</td>\n",
       "      <td>hes young and single</td>\n",
       "      <td>hes young and single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>siete ostinate</td>\n",
       "      <td>youre stubborn</td>\n",
       "      <td>youre you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>non mi piace neanche tom</td>\n",
       "      <td>i dont even like tom</td>\n",
       "      <td>i dont like  tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hai un sogno</td>\n",
       "      <td>do you have a dream</td>\n",
       "      <td>do you have a dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>scrivi a tom</td>\n",
       "      <td>write tom</td>\n",
       "      <td>write tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>noi siamo socievoli</td>\n",
       "      <td>were sociable</td>\n",
       "      <td>were sociable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>questa festa è ottima</td>\n",
       "      <td>this party is great</td>\n",
       "      <td>this car is taken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tom non si sta fermando</td>\n",
       "      <td>tom isnt stopping</td>\n",
       "      <td>tom isnt without</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vada a prendere del caffè</td>\n",
       "      <td>go get coffee</td>\n",
       "      <td>go get coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dobbiamo farlo ancora</td>\n",
       "      <td>we must do it again</td>\n",
       "      <td>we need do it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tom non è così povero</td>\n",
       "      <td>tom isnt that poor</td>\n",
       "      <td>tom isnt that good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tornate a letto ora</td>\n",
       "      <td>go back to bed now</td>\n",
       "      <td>go back to bed now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>io mi dichiaro colpevole</td>\n",
       "      <td>i plead guilty</td>\n",
       "      <td>i play me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dobbiamo andare sul serio</td>\n",
       "      <td>we really have to go</td>\n",
       "      <td>we really have to go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>chi è il vostro amico</td>\n",
       "      <td>who is your friend</td>\n",
       "      <td>whos your friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tom abita qua da solo</td>\n",
       "      <td>tom lives here alone</td>\n",
       "      <td>tom lives here alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>non è tuo</td>\n",
       "      <td>that isnt yours</td>\n",
       "      <td>it isnt yours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tom ha protetto mary</td>\n",
       "      <td>tom protected mary</td>\n",
       "      <td>tom has mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sono pronto a morire</td>\n",
       "      <td>i am ready to die</td>\n",
       "      <td>im ready to die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>non resta mai a lungo</td>\n",
       "      <td>she never stays long</td>\n",
       "      <td>he never stays long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>voi siete liberi adesso</td>\n",
       "      <td>are you free now</td>\n",
       "      <td>are you free now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>voi siete affascinanti</td>\n",
       "      <td>youre fascinating</td>\n",
       "      <td>youre charming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>noi amiamo questo posto</td>\n",
       "      <td>we love this place</td>\n",
       "      <td>we love this place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>io non sono mai piaciuta a tom</td>\n",
       "      <td>tom never liked me</td>\n",
       "      <td>tom never liked me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>quel bambino si è annoiato</td>\n",
       "      <td>that child got bored</td>\n",
       "      <td>that child got bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>dovè la stazione</td>\n",
       "      <td>where is the station</td>\n",
       "      <td>wheres the station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>smettetela di combattere</td>\n",
       "      <td>stop fighting</td>\n",
       "      <td>stop fighting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>avete il mio rispetto</td>\n",
       "      <td>you have my respect</td>\n",
       "      <td>you have my respect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>chi ha annullato</td>\n",
       "      <td>who canceled</td>\n",
       "      <td>who canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>posso uccidervi</td>\n",
       "      <td>i can kill you</td>\n",
       "      <td>i can kill you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tom ha cambiato idea</td>\n",
       "      <td>tom changed his mind</td>\n",
       "      <td>tom changed his mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tom non è noioso</td>\n",
       "      <td>tom isnt boring</td>\n",
       "      <td>tom isnt weird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>lei è una dottoressa</td>\n",
       "      <td>you are a doctor</td>\n",
       "      <td>she is a doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tom vinse una macchina</td>\n",
       "      <td>tom won a free car</td>\n",
       "      <td>tom won a free car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>vi piace correre</td>\n",
       "      <td>do you like to run</td>\n",
       "      <td>do you like to run</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Italian                actual  \\\n",
       "0                mi faccia un urlo      give me a holler   \n",
       "1           siamo molto emozionate     were very excited   \n",
       "2               tom gioca a tennis      tom plays tennis   \n",
       "3              tom vuole camminare     tom wants to walk   \n",
       "4          tom è un professionista          tom is a pro   \n",
       "5                 loro sono grassi            theyre fat   \n",
       "6              abbiate pietà di me       show pity on me   \n",
       "7            a lei piace la scuola    do you like school   \n",
       "8              a tom piace pescare     tom likes to fish   \n",
       "9            la sua banca è sicura     is your bank safe   \n",
       "10               tom ha perso peso       tom lost weight   \n",
       "11          non tornare a chiamare       dont call again   \n",
       "12                 lei è al sicuro            youre safe   \n",
       "13            non chiedermi perché       dont ask me why   \n",
       "14            labbiamo dato a loro    we gave it to them   \n",
       "15              è giovane e single  hes young and single   \n",
       "16                  siete ostinate        youre stubborn   \n",
       "17        non mi piace neanche tom  i dont even like tom   \n",
       "18                    hai un sogno   do you have a dream   \n",
       "19                    scrivi a tom             write tom   \n",
       "20             noi siamo socievoli         were sociable   \n",
       "21           questa festa è ottima   this party is great   \n",
       "22         tom non si sta fermando     tom isnt stopping   \n",
       "23       vada a prendere del caffè         go get coffee   \n",
       "24           dobbiamo farlo ancora   we must do it again   \n",
       "25           tom non è così povero    tom isnt that poor   \n",
       "26             tornate a letto ora    go back to bed now   \n",
       "27        io mi dichiaro colpevole        i plead guilty   \n",
       "28       dobbiamo andare sul serio  we really have to go   \n",
       "29           chi è il vostro amico    who is your friend   \n",
       "30           tom abita qua da solo  tom lives here alone   \n",
       "31                       non è tuo       that isnt yours   \n",
       "32            tom ha protetto mary    tom protected mary   \n",
       "33            sono pronto a morire     i am ready to die   \n",
       "34           non resta mai a lungo  she never stays long   \n",
       "35         voi siete liberi adesso      are you free now   \n",
       "36          voi siete affascinanti     youre fascinating   \n",
       "37         noi amiamo questo posto    we love this place   \n",
       "38  io non sono mai piaciuta a tom    tom never liked me   \n",
       "39      quel bambino si è annoiato  that child got bored   \n",
       "40                dovè la stazione  where is the station   \n",
       "41        smettetela di combattere         stop fighting   \n",
       "42           avete il mio rispetto   you have my respect   \n",
       "43                chi ha annullato          who canceled   \n",
       "44                 posso uccidervi        i can kill you   \n",
       "45            tom ha cambiato idea  tom changed his mind   \n",
       "46                tom non è noioso       tom isnt boring   \n",
       "47            lei è una dottoressa      you are a doctor   \n",
       "48          tom vinse una macchina    tom won a free car   \n",
       "49                vi piace correre    do you like to run   \n",
       "\n",
       "                predicted  \n",
       "0       give me a holler   \n",
       "1     were very excited    \n",
       "2      tom plays tennis    \n",
       "3      tom wants to walk   \n",
       "4       tom is a fanatic   \n",
       "5           theyre fat     \n",
       "6        show pity on me   \n",
       "7     do you like school   \n",
       "8     tom likes fishing    \n",
       "9      is your bank safe   \n",
       "10      tom lost weight    \n",
       "11         dont call to    \n",
       "12          youre safe     \n",
       "13     dont you want you   \n",
       "14     we gave it to them  \n",
       "15  hes young and single   \n",
       "16           youre you     \n",
       "17       i dont like  tom  \n",
       "18    do you have a dream  \n",
       "19           write tom     \n",
       "20       were sociable     \n",
       "21     this car is taken   \n",
       "22     tom isnt without    \n",
       "23        go get coffee    \n",
       "24         we need do it   \n",
       "25    tom isnt that good   \n",
       "26     go back to bed now  \n",
       "27            i play me    \n",
       "28   we really have to go  \n",
       "29     whos your friend    \n",
       "30  tom lives here alone   \n",
       "31        it isnt yours    \n",
       "32         tom has mary    \n",
       "33       im ready to die   \n",
       "34   he never stays long   \n",
       "35      are you free now   \n",
       "36      youre charming     \n",
       "37    we love this place   \n",
       "38    tom never liked me   \n",
       "39  that child got bored   \n",
       "40   wheres the station    \n",
       "41       stop fighting     \n",
       "42   you have my respect   \n",
       "43        who canceled     \n",
       "44        i can kill you   \n",
       "45  tom changed his mind   \n",
       "46       tom isnt weird    \n",
       "47       she is a doctor   \n",
       "48     tom won a free car  \n",
       "49     do you like to run  "
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dframe.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qD0Jae6LCa3d"
   },
   "source": [
    "<h3><a id=\"Evaluation\">&#9997; Evaluation</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CgotqgTsCa3e"
   },
   "source": [
    "\n",
    "Bilingual Evaluation Understudy Score (BLEU). The Bilingual Evaluation Understudy Score, or BLEU for short, is a metric for evaluating a generated sentence to a reference sentence. A perfect match results in a score of 1.0, whereas a perfect mismatch results in a score of 0.0.\n",
    "\n",
    "we will build the function which will makes a list of the actual output with the predicted output and then evaluates using the corpus_bleu which is a function of the nltk library \"nltk.translate.bleu_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u4fGKegSCa3e"
   },
   "outputs": [],
   "source": [
    "def predict_sequence(model, tokenizer, source):\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = get_word(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dAAskv15Ca3h"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "    actual, predicted = list(), list()\n",
    "    for i, source in enumerate(sources):\n",
    "        # translate encoded source text\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        translation = predict_sequence(model, English_tokenizer, source)\n",
    "        raw_target, raw_src = raw_dataset[i]\n",
    "        if i < 10:\n",
    "            print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
    "        actual.append(raw_target.split())\n",
    "        predicted.append(translation.split())\n",
    "    # calculate BLEU score\n",
    "    print('BLEU: %f' % corpus_bleu(actual, predicted, weights=(1, 0, 0, 0)))\n",
    "    #print('BLEU: %f' % sentence_bleu(actual, predicted))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "AyfIuXwjCa3j",
    "outputId": "5bf77f57-f344-48c8-c0c4-4737cc833c2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src=[tu sembri divertente], target=[you sound funny], predicted=[you sound funny]\n",
      "src=[non è a casa], target=[he isnt at home], predicted=[he isnt home]\n",
      "src=[ho visto il cuoco], target=[i saw the cook], predicted=[i saw the cook]\n",
      "src=[io non ho chiesto aiuto], target=[i didnt ask for help], predicted=[i didnt ask for help]\n",
      "src=[deve essere egoista], target=[he must be selfish], predicted=[he must be selfish]\n",
      "src=[lei scoppiò in lacrime], target=[she burst into tears], predicted=[she broke into tears]\n",
      "src=[datemi un po di dettagli], target=[give me some details], predicted=[give me some details]\n",
      "src=[tom non riesce ad entrare], target=[tom cant come in], predicted=[tom cant come in]\n",
      "src=[io non riesco a lavorare qui], target=[i cant work here], predicted=[i cant work here]\n",
      "src=[aiutate tom], target=[help tom out], predicted=[help tom out]\n",
      "BLEU: 0.074865\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, English_tokenizer, x_train[:50,:], train[:50,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5oLcGff_Ca3p"
   },
   "source": [
    "The evalution of the prediction gives us the corpus score of the 0.11 which can be increased by playing aroud with the data size, batch size, optimizers, loss, and epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74mJyCF3Ca3q"
   },
   "source": [
    "<h3><a id=\"Conclusion\">&#9997; Conclusion</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cm6-Mi7_Ca3q"
   },
   "source": [
    "The built model was able to translate the Italian words to the English most of the time and by this research I can conclude that GRU with attention was able to translate comparatively better than the other model, but the training time was high for the GRU.\n",
    "\n",
    "![test66](Result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxG-MgYrCa3r"
   },
   "source": [
    "<h3><a id=\"Contribution\">&#9997; Contribution</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xc-Ek80aCa3r"
   },
   "source": [
    "After reviewing a lot of references sites on the machine learning sites namely \"medium\", \"analyticsVidhya\" and various tutoriols on the LSTM and GRU, I have understood how the RNN and its enhanced Gated network works and implemented in this notebook. all the references which I have used to do this research project is all mentioned in the references below and research paper is also included which explains this research in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mVeqcP5Ca3s"
   },
   "source": [
    "<h3><a id=\"References\">&#9997; References</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ALKe89bCCa3t"
   },
   "source": [
    "\n",
    "\n",
    "**o** https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa\n",
    "\n",
    "**o** https://www.analyticsvidhya.com/blog/2018/03/microsofts-claims-language-translation-ai-reached-human-levels-accuracy/\n",
    "\n",
    "**o** https://blog.statsbot.co/machine-learning-translation-96f0ed8f19e4\n",
    "\n",
    "**o** https://www.youtube.com/watch?v=nRBnh4qbPHI&vl=en\n",
    "\n",
    "**o** http://www.manythings.org/anki/\n",
    "\n",
    "**o** https://machinelearningmastery.com/introduction-neural-machine-translation/\n",
    "\n",
    "**o** https://machinelearningmastery.com/develop-neural-machine-translation-system-keras/\n",
    "\n",
    "**o** https://www.youtube.com/watch?v=vI2Y3I-JI2Q\n",
    "\n",
    "**o** https://towardsdatascience.com/neural-machine-translator-with-less-than-50-lines-of-code-guide-1fe4fdfe6292\n",
    "\n",
    "**o** https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/text/\n",
    "\n",
    "**o** https://machinelearningmastery.com/tune-lstm-hyperparameters-keras-time-series-forecasting/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tb0MDGPpCa3t"
   },
   "source": [
    "<h3><a id=\"License\">&#9997; License</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JzY8aTTkCa3u"
   },
   "source": [
    "**MIT License**\n",
    "\n",
    "Copyright 2018 Chetan M Jadhav\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BghAH3szCa3u"
   },
   "source": [
    "**The text in the document by Chetan M Jadhav is licensed under CC BY 3.0 https://creativecommons.org/licenses/by/3.0/us/ **"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Final_BDI.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
